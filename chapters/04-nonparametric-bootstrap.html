<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-09-07">

<title>Statistics for Data Science: Lecture Notes - 4&nbsp; Nonparametric Estimation and The Bootstrap</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/05-parametric-inference-I.html" rel="next">
<link href="../chapters/03-convergence-inference.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/04-nonparametric-bootstrap.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Nonparametric Estimation and The Bootstrap</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Statistics for Data Science: Lecture Notes</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-probability-foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Probability Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-expectation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Expectation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-convergence-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Convergence and The Basics of Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-nonparametric-bootstrap.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Nonparametric Estimation and The Bootstrap</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-parametric-inference-I.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Parametric Inference I: Finding Estimators</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-parametric-inference-II.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Parametric Inference II: Properties of Estimators</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Hypothesis Testing and p-values</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-bayesian-inference-decision-theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Bayesian Inference and Statistical Decision Theory</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-linear-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Linear and Logistic Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pdf-download.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Download Complete PDF</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives"><span class="header-section-number">4.1</span> Learning Objectives</a></li>
  <li><a href="#introduction-and-motivation" id="toc-introduction-and-motivation" class="nav-link" data-scroll-target="#introduction-and-motivation"><span class="header-section-number">4.2</span> Introduction and Motivation</a>
  <ul class="collapse">
  <li><a href="#beyond-point-estimates-quantifying-uncertainty" id="toc-beyond-point-estimates-quantifying-uncertainty" class="nav-link" data-scroll-target="#beyond-point-estimates-quantifying-uncertainty"><span class="header-section-number">4.2.1</span> Beyond Point Estimates: Quantifying Uncertainty</a></li>
  </ul></li>
  <li><a href="#confidence-sets-the-foundation" id="toc-confidence-sets-the-foundation" class="nav-link" data-scroll-target="#confidence-sets-the-foundation"><span class="header-section-number">4.3</span> Confidence Sets: The Foundation</a>
  <ul class="collapse">
  <li><a href="#interpretation-of-confidence-sets" id="toc-interpretation-of-confidence-sets" class="nav-link" data-scroll-target="#interpretation-of-confidence-sets"><span class="header-section-number">4.3.1</span> Interpretation of Confidence Sets</a></li>
  <li><a href="#normal-based-confidence-intervals" id="toc-normal-based-confidence-intervals" class="nav-link" data-scroll-target="#normal-based-confidence-intervals"><span class="header-section-number">4.3.2</span> Normal-Based Confidence Intervals</a></li>
  </ul></li>
  <li><a href="#the-plug-in-principle-a-general-method-for-estimation" id="toc-the-plug-in-principle-a-general-method-for-estimation" class="nav-link" data-scroll-target="#the-plug-in-principle-a-general-method-for-estimation"><span class="header-section-number">4.4</span> The Plug-In Principle: A General Method for Estimation</a>
  <ul class="collapse">
  <li><a href="#estimating-the-entire-distribution-the-edf" id="toc-estimating-the-entire-distribution-the-edf" class="nav-link" data-scroll-target="#estimating-the-entire-distribution-the-edf"><span class="header-section-number">4.4.1</span> Estimating the Entire Distribution: The EDF</a></li>
  <li><a href="#estimating-functionals-the-plug-in-estimator" id="toc-estimating-functionals-the-plug-in-estimator" class="nav-link" data-scroll-target="#estimating-functionals-the-plug-in-estimator"><span class="header-section-number">4.4.2</span> Estimating Functionals: The Plug-In Estimator</a></li>
  </ul></li>
  <li><a href="#the-bootstrap-simulating-uncertainty" id="toc-the-bootstrap-simulating-uncertainty" class="nav-link" data-scroll-target="#the-bootstrap-simulating-uncertainty"><span class="header-section-number">4.5</span> The Bootstrap: Simulating Uncertainty</a>
  <ul class="collapse">
  <li><a href="#the-core-idea" id="toc-the-core-idea" class="nav-link" data-scroll-target="#the-core-idea"><span class="header-section-number">4.5.1</span> The Core Idea</a></li>
  <li><a href="#bootstrap-variance-and-standard-error-estimation" id="toc-bootstrap-variance-and-standard-error-estimation" class="nav-link" data-scroll-target="#bootstrap-variance-and-standard-error-estimation"><span class="header-section-number">4.5.2</span> Bootstrap Variance and Standard Error Estimation</a></li>
  </ul></li>
  <li><a href="#bootstrap-confidence-intervals" id="toc-bootstrap-confidence-intervals" class="nav-link" data-scroll-target="#bootstrap-confidence-intervals"><span class="header-section-number">4.6</span> Bootstrap Confidence Intervals</a>
  <ul class="collapse">
  <li><a href="#three-common-methods" id="toc-three-common-methods" class="nav-link" data-scroll-target="#three-common-methods"><span class="header-section-number">4.6.1</span> Three Common Methods</a></li>
  <li><a href="#comparing-bootstrap-confidence-intervals" id="toc-comparing-bootstrap-confidence-intervals" class="nav-link" data-scroll-target="#comparing-bootstrap-confidence-intervals"><span class="header-section-number">4.6.2</span> Comparing Bootstrap Confidence Intervals</a></li>
  </ul></li>
  <li><a href="#bootstrap-application-higher-moments" id="toc-bootstrap-application-higher-moments" class="nav-link" data-scroll-target="#bootstrap-application-higher-moments"><span class="header-section-number">4.7</span> Bootstrap Application: Higher Moments</a></li>
  <li><a href="#when-the-bootstrap-fails" id="toc-when-the-bootstrap-fails" class="nav-link" data-scroll-target="#when-the-bootstrap-fails"><span class="header-section-number">4.8</span> When The Bootstrap Fails</a></li>
  <li><a href="#chapter-summary-and-connections" id="toc-chapter-summary-and-connections" class="nav-link" data-scroll-target="#chapter-summary-and-connections"><span class="header-section-number">4.9</span> Chapter Summary and Connections</a>
  <ul class="collapse">
  <li><a href="#key-concepts-review" id="toc-key-concepts-review" class="nav-link" data-scroll-target="#key-concepts-review"><span class="header-section-number">4.9.1</span> Key Concepts Review</a></li>
  <li><a href="#why-these-concepts-matter" id="toc-why-these-concepts-matter" class="nav-link" data-scroll-target="#why-these-concepts-matter"><span class="header-section-number">4.9.2</span> Why These Concepts Matter</a></li>
  <li><a href="#common-pitfalls-to-avoid" id="toc-common-pitfalls-to-avoid" class="nav-link" data-scroll-target="#common-pitfalls-to-avoid"><span class="header-section-number">4.9.3</span> Common Pitfalls to Avoid</a></li>
  <li><a href="#chapter-connections" id="toc-chapter-connections" class="nav-link" data-scroll-target="#chapter-connections"><span class="header-section-number">4.9.4</span> Chapter Connections</a></li>
  <li><a href="#rejoinder-coming-full-circle" id="toc-rejoinder-coming-full-circle" class="nav-link" data-scroll-target="#rejoinder-coming-full-circle"><span class="header-section-number">4.9.5</span> Rejoinder: Coming Full Circle</a></li>
  <li><a href="#practical-advice" id="toc-practical-advice" class="nav-link" data-scroll-target="#practical-advice"><span class="header-section-number">4.9.6</span> Practical Advice</a></li>
  <li><a href="#quick-self-check" id="toc-quick-self-check" class="nav-link" data-scroll-target="#quick-self-check"><span class="header-section-number">4.9.7</span> Quick Self-Check</a></li>
  <li><a href="#self-test-problems" id="toc-self-test-problems" class="nav-link" data-scroll-target="#self-test-problems"><span class="header-section-number">4.9.8</span> Self-Test Problems</a></li>
  <li><a href="#connections-to-source-material" id="toc-connections-to-source-material" class="nav-link" data-scroll-target="#connections-to-source-material"><span class="header-section-number">4.9.9</span> Connections to Source Material</a></li>
  <li><a href="#python-and-r-reference" id="toc-python-and-r-reference" class="nav-link" data-scroll-target="#python-and-r-reference"><span class="header-section-number">4.9.10</span> Python and R Reference</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Nonparametric Estimation and The Bootstrap</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 7, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="learning-objectives" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">4.1</span> Learning Objectives</h2>
<p>After completing this chapter, you will be able to:</p>
<ul>
<li>Explain the definition and frequentist interpretation of a confidence interval</li>
<li>Apply the plug-in principle with the Empirical Distribution Function (EDF) to estimate statistical functionals</li>
<li>Use the bootstrap to simulate the sampling distribution of a statistic and estimate its standard error</li>
<li>Construct and compare the three main types of bootstrap confidence intervals: Normal, percentile, and pivotal</li>
<li>Identify the assumptions and limitations of the bootstrap, recognizing common situations where it can fail</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This chapter covers nonparametric estimation methods and the bootstrap. The material is adapted from Chapters 7 and 8 of <span class="citation" data-cites="wasserman2013all">Wasserman (<a href="../references.html#ref-wasserman2013all" role="doc-biblioref">2013</a>)</span>, with reference to Chapter 6 for confidence intervals. Additional examples and computational perspectives have been added for data science applications.</p>
</div>
</div>
</section>
<section id="introduction-and-motivation" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="introduction-and-motivation"><span class="header-section-number">4.2</span> Introduction and Motivation</h2>
<section id="beyond-point-estimates-quantifying-uncertainty" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="beyond-point-estimates-quantifying-uncertainty"><span class="header-section-number">4.2.1</span> Beyond Point Estimates: Quantifying Uncertainty</h3>
<p>Imagine you’re a healthcare administrator planning for hospital capacity during an epidemic. Your data scientists provide a point estimate: “We expect 500 patients next week.” But is this estimate reliable enough to base critical decisions on? What if the true number could reasonably be anywhere from 300 to 700? A single point estimate, without quantifying its uncertainty, is often useless for decision-making. You need a plausible <em>range</em> – this is called a <strong>confidence interval</strong>.</p>
<p>In Chapter 3, we learned how to create point estimates – single “best guesses” for unknown quantities. We saw that the sample mean <span class="math inline">\bar{X}_n</span> estimates the population mean <span class="math inline">\mu</span>, and we even derived its standard error. But what about more complex statistics? How do we find the standard error of the median? The correlation coefficient? The 90th percentile?</p>
<p>Traditional statistical theory provides formulas for simple cases, but quickly becomes intractable for complex statistics. This chapter introduces two powerful ideas that revolutionized modern statistics:</p>
<ol type="1">
<li><p><strong>The Plug-In Principle</strong>: A simple, intuitive method for estimating almost any quantity by “plugging in” the empirical distribution for the true distribution.</p></li>
<li><p><strong>The Bootstrap</strong>: A computational method for estimating the standard error and confidence interval of virtually any statistic, even when no formula exists.</p></li>
</ol>
<p>These methods exemplify the computational approach to statistics that has become dominant in the era of cheap computing power. Instead of deriving complex mathematical formulas, we let the computer simulate what would happen if we could repeat our experiment many times.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Finnish Terminology Reference
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For Finnish-speaking students, here’s a reference table of key terms in this chapter:</p>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>English</th>
<th>Finnish</th>
<th>Context</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Confidence interval</td>
<td>Luottamusväli</td>
<td>Range that contains parameter with specified probability</td>
</tr>
<tr class="even">
<td>Coverage</td>
<td>Peitto</td>
<td>Probability that interval contains true parameter</td>
</tr>
<tr class="odd">
<td>Empirical distribution function</td>
<td>Empiirinen kertymäfunktio</td>
<td>Data-based estimate of CDF</td>
</tr>
<tr class="even">
<td>Statistical functional</td>
<td>Tilastollinen funktionaali</td>
<td>Function of the distribution</td>
</tr>
<tr class="odd">
<td>Plug-in estimator</td>
<td>Pistoke-estimaattori</td>
<td>Estimate using empirical distribution</td>
</tr>
<tr class="even">
<td>Bootstrap</td>
<td>Uusio-otanta</td>
<td>Resampling method for uncertainty</td>
</tr>
<tr class="odd">
<td>Resampling</td>
<td>Uudelleenotanta</td>
<td>Drawing samples from data</td>
</tr>
<tr class="even">
<td>Bootstrap sample</td>
<td>Bootstrap-otos</td>
<td>Sample drawn with replacement</td>
</tr>
<tr class="odd">
<td>Percentile interval</td>
<td>Prosenttipiste-luottamusväli</td>
<td>CI using bootstrap quantiles</td>
</tr>
<tr class="even">
<td>Pivotal interval</td>
<td>Pivotaalinen luottamusväli</td>
<td>CI using pivot quantity</td>
</tr>
<tr class="odd">
<td>Standard error</td>
<td>Keskivirhe</td>
<td>Standard deviation of estimator</td>
</tr>
<tr class="even">
<td>Monte Carlo error</td>
<td>Monte Carlo -virhe</td>
<td>Error from finite simulations</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="confidence-sets-the-foundation" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="confidence-sets-the-foundation"><span class="header-section-number">4.3</span> Confidence Sets: The Foundation</h2>
<p>Before diving into nonparametric estimation and the bootstrap, we need to establish the formal framework for confidence intervals, a staple of classical statistics.</p>
<div class="definition">
<p>A <strong><span class="math inline">1-\alpha</span> confidence interval</strong> for a parameter <span class="math inline">\theta</span> is an interval <span class="math inline">C_n = (a, b)</span> where <span class="math inline">a = a(X_1, \ldots, X_n)</span> and <span class="math inline">b = b(X_1, \ldots, X_n)</span> are functions of the data such that <span class="math display">\mathbb{P}_{\theta}(\theta \in C_n) \geq 1 - \alpha, \quad \text{for all } \theta \in \Theta.</span></p>
<p>In other words, <span class="math inline">C_n</span> encloses <span class="math inline">\theta</span> with probability <span class="math inline">1-\alpha</span>. This probability is called the <strong>coverage</strong> of the interval.</p>
</div>
<p>A common choice is <span class="math inline">\alpha = 0.05</span> which yields <span class="math inline">95\%</span> confidence intervals.</p>
<section id="interpretation-of-confidence-sets" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="interpretation-of-confidence-sets"><span class="header-section-number">4.3.1</span> Interpretation of Confidence Sets</h3>
<p>Confidence intervals are not probability statements about <span class="math inline">\theta</span>. The parameter <span class="math inline">\theta</span> is fixed; it’s the interval <span class="math inline">C_n</span> that varies with different samples.</p>
<p>The correct interpretation is: if you repeatedly collect data and construct confidence intervals using the same procedure, <span class="math inline">(1-\alpha) \times 100\%</span> of those intervals will contain the true parameter. This is the <em>frequentist</em> guarantee.</p>
<p>Bayesian credible intervals provide a different type of statement – they give a probability that <span class="math inline">\theta</span> lies in the interval given your observed data. However, Bayesian intervals are not guaranteed to achieve frequentist coverage (containing the true parameter <span class="math inline">(1-\alpha)</span> proportion of the time across repeated sampling).</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Critical Point: What is Random?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Remember that <span class="math inline">\theta</span> is <strong>fixed</strong> and <span class="math inline">C_n</span> is <strong>random</strong>. The parameter doesn’t change; the interval does. Each time we collect new data, we get a different interval. The guarantee is that <span class="math inline">(1-\alpha) \times 100\%</span> of these intervals will contain the true parameter.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advanced: When Coverage Fails
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The frequentist guarantee is an average over all possible datasets. For any specific confidence interval procedure, there may exist parameter values where the actual coverage is less than the nominal <span class="math inline">(1-\alpha)</span> level.</p>
<p>Additionally, for some “unlucky” datasets (the <span class="math inline">\alpha</span> proportion), the computed interval may be far from the true parameter. This is an inherent limitation of the frequentist approach – it provides no guarantees for individual intervals, only for the long-run performance of the procedure.</p>
<p>This suggests different approaches may be preferred in different contexts:</p>
<ul>
<li><strong>Frequentist methods:</strong> Well-suited for repeated analyses where long-run guarantees matter</li>
<li><strong>Bayesian methods:</strong> May be preferred when prior information is available and you need probabilistic statements about parameters given your specific data</li>
</ul>
<p>Both approaches are valuable tools for quantifying uncertainty.</p>
</div>
</div>
</div>
</section>
<section id="normal-based-confidence-intervals" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="normal-based-confidence-intervals"><span class="header-section-number">4.3.2</span> Normal-Based Confidence Intervals</h3>
<p>When an estimator <span class="math inline">\hat{\theta}_n</span> is approximately normally distributed, we can form confidence intervals using the normal approximation. This is often the case for large samples due to the Central Limit Theorem.</p>
<p>Suppose <span class="math inline">\hat{\theta}_n \approx \mathcal{N}(\theta, \widehat{\text{se}}^2)</span>, where <span class="math inline">\widehat{\text{se}}</span> is the (estimated) standard error of the estimator. Then we can standardize to get: <span class="math display">\frac{\hat{\theta}_n - \theta}{\widehat{\text{se}}} \approx \mathcal{N}(0, 1)</span></p>
<p>Let <span class="math inline">z_{\alpha/2} = \Phi^{-1}(1 - \alpha/2)</span> be the upper <span class="math inline">\alpha/2</span> quantile of the standard normal distribution, where <span class="math inline">\Phi</span> is the standard normal CDF. This means:</p>
<ul>
<li><span class="math inline">\mathbb{P}(Z &gt; z_{\alpha/2}) = \alpha/2</span> for <span class="math inline">Z \sim \mathcal{N}(0, 1)</span></li>
<li><span class="math inline">\mathbb{P}(-z_{\alpha/2} &lt; Z &lt; z_{\alpha/2}) = 1 - \alpha</span></li>
</ul>
<p>Therefore: <span class="math display">\mathbb{P}\left(-z_{\alpha/2} &lt; \frac{\hat{\theta}_n - \theta}{\widehat{\text{se}}} &lt; z_{\alpha/2}\right) \approx 1 - \alpha</span></p>
<p>Rearranging to isolate <span class="math inline">\theta</span>: <span class="math display">\mathbb{P}\left(\hat{\theta}_n - z_{\alpha/2} \widehat{\text{se}} &lt; \theta &lt; \hat{\theta}_n + z_{\alpha/2} \widehat{\text{se}}\right) \approx 1 - \alpha</span></p>
<p>This gives us the approximate <span class="math inline">(1-\alpha)</span> confidence interval: <span class="math display">C_n = \left(\hat{\theta}_n - z_{\alpha/2} \widehat{\text{se}}, \hat{\theta}_n + z_{\alpha/2} \widehat{\text{se}}\right)</span></p>
<p>For the common case of 95% confidence intervals (<span class="math inline">\alpha = 0.05</span>):</p>
<ul>
<li><span class="math inline">z_{0.025} = \Phi^{-1}(0.975) \approx 1.96 \approx 2</span></li>
<li>This leads to the familiar rule of thumb: <span class="math inline">\hat{\theta}_n \pm 2 \widehat{\text{se}}</span></li>
</ul>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Confidence Interval for the Mean
</div>
</div>
<div class="callout-body-container callout-body">
<p>For the sample mean <span class="math inline">\bar{X}_n</span> with known population variance <span class="math inline">\sigma^2</span>:</p>
<ul>
<li>Estimator: <span class="math inline">\hat{\theta}_n = \bar{X}_n</span></li>
<li>Standard error: <span class="math inline">\text{se} = \sigma/\sqrt{n}</span></li>
<li>95% CI: <span class="math inline">\bar{X}_n \pm 1.96 \cdot \sigma/\sqrt{n}</span></li>
</ul>
<p>If <span class="math inline">\sigma</span> is unknown, we substitute the sample standard deviation <span class="math inline">s</span> to get:</p>
<ul>
<li>95% CI: <span class="math inline">\bar{X}_n \pm 1.96 \cdot s/\sqrt{n}</span></li>
</ul>
<p>For small samples, we would use the <a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution"><span class="math inline">t</span>-distribution</a> instead of the normal distribution.</p>
</div>
</div>
</section>
</section>
<section id="the-plug-in-principle-a-general-method-for-estimation" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="the-plug-in-principle-a-general-method-for-estimation"><span class="header-section-number">4.4</span> The Plug-In Principle: A General Method for Estimation</h2>
<p>This lecture focuses on <strong>nonparametric estimation</strong>, and the plug-in principle is one key instrument of nonparametric statistics.</p>
<section id="estimating-the-entire-distribution-the-edf" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="estimating-the-entire-distribution-the-edf"><span class="header-section-number">4.4.1</span> Estimating the Entire Distribution: The EDF</h3>
<p>The plug-in principle is a simple idea that provides a unified framework for nonparametric estimation that works for virtually any statistical problem.</p>
<p><strong>The Core Idea</strong>: When we need to estimate some property of an unknown distribution <span class="math inline">F</span>, we simply:</p>
<ol type="1">
<li>Estimate the distribution itself using our data</li>
<li>Calculate the property using our estimated distribution</li>
</ol>
<p>The most fundamental nonparametric estimate is of the CDF itself. Let <span class="math inline">X_1, \ldots, X_n \sim F</span> be an i.i.d. sample where <span class="math inline">F</span> is a distribution function on the real line. Since we don’t know the true CDF <span class="math inline">F</span>, we estimate it with the <strong>Empirical Distribution Function (EDF)</strong>.</p>
<div class="definition">
<p>The <strong>Empirical Distribution Function (EDF)</strong> <span class="math inline">\hat{F}_n</span> is the CDF that puts probability mass <span class="math inline">1/n</span> on each data point. Formally: <span class="math display">\hat{F}_n(x) = \frac{1}{n}\sum_{i=1}^n I(X_i \leq x)</span> where <span class="math inline">I(X_i \leq x) = \begin{cases}
1 &amp; \text{if } X_i \leq x \\
0 &amp; \text{if } X_i &gt; x
\end{cases}</span></p>
</div>
<p>Intuitively, <span class="math inline">\hat{F}_n(x)</span> is simply the proportion of data points less than or equal to <span class="math inline">x</span>. It’s the most natural estimate of <span class="math inline">F(x) = \mathbb{P}(X \leq x)</span>.</p>
<p><strong>Properties of the EDF</strong>:</p>
<p>For any fixed point <span class="math inline">x</span>:</p>
<ul>
<li><strong>Unbiased</strong>: <span class="math inline">\mathbb{E}(\hat{F}_n(x)) = F(x)</span></li>
<li><strong>Variance</strong>: <span class="math inline">\mathbb{V}(\hat{F}_n(x)) = \frac{F(x)(1-F(x))}{n}</span></li>
<li><strong>MSE</strong>: <span class="math inline">\text{MSE}(\hat{F}_n(x)) = \mathbb{V}(\hat{F}_n(x)) = \frac{F(x)(1-F(x))}{n} \to 0</span> as <span class="math inline">n \to \infty</span></li>
<li><strong>Consistent</strong>: <span class="math inline">\hat{F}_n(x) \xrightarrow{P} F(x)</span> as <span class="math inline">n \to \infty</span></li>
</ul>
<p>But the EDF is even better than these pointwise properties suggest:</p>
<div class="theorem" name="Glivenko-Cantelli Theorem">
<p>The EDF converges to the true CDF <em>uniformly</em>: <span class="math display">\sup_x |\hat{F}_n(x) - F(x)| \xrightarrow{P} 0</span></p>
</div>
<p>This is a remarkably strong guarantee – the EDF approximates the true CDF well <em>everywhere</em>, not just at individual points.</p>
<p>Let’s visualize the EDF with an example dataset:</p>
<div id="6afdac89" class="cell" data-fig-height="5" data-fig-width="7" data-execution_count="1">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate nerve data (waiting times between pulses)</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Using exponential distribution as a model for waiting times</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>nerve_data <span class="op">=</span> np.random.exponential(scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>n)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the EDF plot</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort data for plotting</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>sorted_data <span class="op">=</span> np.sort(nerve_data)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the EDF as a step function</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>ax.step(sorted_data, np.arange(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>n, where<span class="op">=</span><span class="st">'post'</span>, </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Empirical CDF'</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Add rug plot to show data points</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>ax.plot(sorted_data, np.zeros_like(sorted_data), <span class="st">'|'</span>, </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">'black'</span>, markersize<span class="op">=</span><span class="dv">10</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Add true CDF for comparison</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>x_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="bu">max</span>(sorted_data)<span class="op">*</span><span class="fl">1.1</span>, <span class="dv">1000</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>true_cdf <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> np.exp(<span class="op">-</span>x_range<span class="op">/</span><span class="fl">0.5</span>)  <span class="co"># Exponential CDF</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>ax.plot(x_range, true_cdf, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'True CDF'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Waiting time (seconds)'</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Cumulative probability'</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Empirical Distribution Function for Nerve Pulse Data (Simulated)'</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">0</span>, <span class="bu">max</span>(sorted_data)<span class="op">*</span><span class="fl">1.05</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="fl">1.05</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The step function shows <span class="math inline">\hat{F}_n</span>, jumping by <span class="math inline">1/n</span> at each data point. The vertical lines at the bottom show the actual data points. Notice how the EDF closely follows the true CDF (shown for comparison).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advanced: Confidence Bands for the CDF
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We can construct confidence bands for the entire CDF using the <a href="https://en.wikipedia.org/wiki/Dvoretzky%E2%80%93Kiefer%E2%80%93Wolfowitz_inequality">Dvoretzky-Kiefer-Wolfowitz (DKW) inequality</a>:</p>
<p><span class="math display">\mathbb{P}\left(\sup_x |F(x) - \hat{F}_n(x)| &gt; \epsilon\right) \leq 2e^{-2n\epsilon^2}</span></p>
<p>This leads to a <span class="math inline">1-\alpha</span> confidence band: <span class="math display">L(x) = \max\{\hat{F}_n(x) - \epsilon_n, 0\}</span> <span class="math display">U(x) = \min\{\hat{F}_n(x) + \epsilon_n, 1\}</span> where <span class="math inline">\epsilon_n = \sqrt{\frac{1}{2n}\log\left(\frac{2}{\alpha}\right)}</span>.</p>
<div id="7259e6b6" class="cell" data-fig-height="5" data-fig-width="7" data-execution_count="2">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add confidence bands to previous plot</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>epsilon_n <span class="op">=</span> np.sqrt(np.log(<span class="dv">2</span><span class="op">/</span>alpha) <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>n))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot EDF</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>ax.step(sorted_data, np.arange(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>n, where<span class="op">=</span><span class="st">'post'</span>, </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Empirical CDF'</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Add confidence bands</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>y_values <span class="op">=</span> np.arange(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>n</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>lower_band <span class="op">=</span> np.maximum(y_values <span class="op">-</span> epsilon_n, <span class="dv">0</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>upper_band <span class="op">=</span> np.minimum(y_values <span class="op">+</span> epsilon_n, <span class="dv">1</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>ax.fill_between(sorted_data, lower_band, upper_band, </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>                step<span class="op">=</span><span class="st">'post'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'gray'</span>, </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span><span class="bu">int</span>((<span class="dv">1</span><span class="op">-</span>alpha)<span class="op">*</span><span class="dv">100</span>)<span class="sc">}</span><span class="ss">% Confidence band'</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Add rug plot</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>ax.plot(sorted_data, np.zeros_like(sorted_data), <span class="st">'|'</span>, </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">'black'</span>, markersize<span class="op">=</span><span class="dv">10</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Waiting time (seconds)'</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Cumulative probability'</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'EDF with Confidence Band'</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">0</span>, <span class="bu">max</span>(sorted_data)<span class="op">*</span><span class="fl">1.05</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="fl">1.05</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Width of confidence band: ±</span><span class="sc">{</span>epsilon_n<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"This means we're 95% confident the true CDF lies within this gray region"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Width of confidence band: ±0.136
This means we're 95% confident the true CDF lies within this gray region</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="estimating-functionals-the-plug-in-estimator" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="estimating-functionals-the-plug-in-estimator"><span class="header-section-number">4.4.2</span> Estimating Functionals: The Plug-In Estimator</h3>
<p>Now that we can estimate the entire distribution, we can estimate any property of it. A <strong>statistical functional</strong> is any function of the CDF <span class="math inline">F</span> or the PDF <span class="math inline">f</span>.</p>
<p>Examples include:</p>
<ul>
<li>The mean: <span class="math inline">\mu = \int x f(x) d x</span></li>
<li>The variance: <span class="math inline">\sigma^2 = \int (x-\mu)^2 f(x) d x</span><br>
</li>
<li>The median: <span class="math inline">m = F^{-1}(1/2)</span></li>
</ul>
<div class="definition">
<p>The <strong>plug-in estimator</strong> of <span class="math inline">\theta = T(F)</span> is defined by: <span class="math display">\hat{\theta}_n = T(\hat{F}_n)</span></p>
</div>
<p>In other words, just <em>plug in</em> the empirical CDF <span class="math inline">\hat{F}_n</span> for the unknown CDF <span class="math inline">F</span>.</p>
<p>This principle is remarkably general. To estimate any property of the population, we calculate that same property on our empirical distribution. Let’s see how this works for various functionals:</p>
<p><strong>The Mean</strong>:</p>
<p>Let <span class="math inline">\mu = T(F) = \int x f(x) dx</span>.</p>
<p>The plug-in estimator is: <span class="math display">\hat{\mu}_n = \sum x \hat{f}_n(x) = \frac{1}{n}\sum_{i=1}^n X_i = \bar{X}_n</span></p>
<p>The plug-in estimator for the mean is just the sample mean!</p>
<p><strong>The Variance</strong>:</p>
<p>Let <span class="math inline">\sigma^2 = T(F) = \mathbb{V}(X) = \int x^2 f(x) d x - \left(\int x f(x) d x\right)^2</span>.</p>
<p>The plug-in estimator is: <span class="math display">\begin{align*}
\hat{\sigma}^2_n &amp;= \sum_x x^2 \hat{f}_n(x) - \left(\sum_x x \hat{f}_n(x)\right)^2 \\
&amp;= \frac{1}{n}\sum_{i=1}^n X_i^2 - \left(\frac{1}{n}\sum_{i=1}^n X_i\right)^2 \\
&amp; = \frac{1}{n}\sum_{i=1}^n (X_i - \bar{X}_n)^2
\end{align*}</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Alternative: The Sample Variance
</div>
</div>
<div class="callout-body-container callout-body">
<p>Another common estimator of <span class="math inline">\sigma^2</span> is the sample variance with the <span class="math inline">n-1</span> correction: <span class="math display">S_n^2 = \frac{1}{n-1}\sum_{i=1}^n(X_i - \bar{X}_n)^2</span></p>
<p>This estimator is unbiased (i.e., <span class="math inline">\mathbb{E}[S_n^2] = \sigma^2</span>) and is almost identical to the plug-in estimator in practice. The factor <span class="math inline">\frac{n}{n-1}</span> makes little difference for moderate to large samples. Most statistical software uses the <span class="math inline">n-1</span> version by default.</p>
</div>
</div>
<p><strong>The Median</strong>:</p>
<p>The median is the value that splits the distribution in half. For the theoretical distribution: <span class="math display">m = T(F) = F^{-1}(0.5)</span></p>
<p>The plug-in estimator is simply the sample median - the middle value when we sort our data. For an odd number of observations, it’s the middle value. For an even number, it’s the average of the two middle values.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advanced: Other Statistical Functionals
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Skewness</strong> (measures asymmetry): <span class="math display">T(F) = \frac{\mathbb{E}[(X-\mu)^3]}{\sigma^3} \implies \hat{\kappa}_n = \frac{\frac{1}{n}\sum_{i=1}^n(X_i-\bar{X}_n)^3}{(\hat{\sigma}^2_n)^{3/2}}</span></p>
<p><strong>Correlation</strong> for bivariate data <span class="math inline">(X,Y)</span>: <span class="math display">T(F) = \frac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y} \implies \hat{\rho}_n = \frac{\frac{1}{n}\sum_{i=1}^n(X_i-\bar{X}_n)(Y_i-\bar{Y}_n)}{\sqrt{\frac{1}{n}\sum_{i=1}^n(X_i-\bar{X}_n)^2}\sqrt{\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y}_n)^2}}</span></p>
<p><strong>Quantiles</strong> in general: <span class="math display">T(F) = F^{-1}(p) \implies \hat{q}_p = \hat{F}_n^{-1}(p)</span></p>
<p>Since <span class="math inline">\hat{F}_n</span> is a step function, we define: <span class="math display">\hat{F}_n^{-1}(p) = \inf\{x : \hat{F}_n(x) \geq p\}</span></p>
<p>This gives us the sample quantile at level <span class="math inline">p</span>.</p>
</div>
</div>
</div>
<p><strong>Confidence Intervals for Plug-in Estimators</strong>:</p>
<p>When the plug-in estimator <span class="math inline">\hat{\theta}_n = T(\hat{F}_n)</span> is approximately normally distributed, we can form confidence intervals using: <span class="math display">\hat{\theta}_n \pm z_{\alpha/2} \widehat{\text{se}}</span></p>
<p>as we saw earlier in the <em>Normal-Based Confidence Intervals</em> section.</p>
<p>The challenge is finding <span class="math inline">\widehat{\text{se}}</span>. For the mean, we know from theory that <span class="math inline">\text{se}(\bar{X}_n) = \sigma/\sqrt{n}</span>, which we can estimate by plugging in <span class="math inline">\hat{\sigma}</span> to get: <span class="math display">\bar{X}_n \pm z_{\alpha/2} \frac{\hat{\sigma}}{\sqrt{n}}</span></p>
<p>But what about the median? The 90th percentile? The interquartile range? For most functionals, <strong>there is no simple formula for the standard error</strong>.</p>
<p>This is where the bootstrap comes to the rescue, as we see next.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recap: Nonparametric Estimation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">X_1, \ldots, X_n \sim F</span> be an i.i.d. sample where <span class="math inline">F</span> is a distribution function on the real line.</p>
<ul>
<li>The <strong>empirical distribution function</strong> <span class="math inline">\hat{F}_n</span> is the CDF that puts mass <span class="math inline">1/n</span> at each data point <span class="math inline">X_i</span></li>
<li>A <strong>statistical functional</strong> <span class="math inline">T(F)</span> is any function of <span class="math inline">F</span> (e.g., mean, variance, median)</li>
<li>The <strong>plug-in estimator</strong> of <span class="math inline">\theta = T(F)</span> is <span class="math inline">\hat{\theta}_n = T(\hat{F}_n)</span></li>
</ul>
<p>We’ve seen how to create point estimates for any functional. The challenge is quantifying their uncertainty when no formula exists for the standard error.</p>
</div>
</div>
</section>
</section>
<section id="the-bootstrap-simulating-uncertainty" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="the-bootstrap-simulating-uncertainty"><span class="header-section-number">4.5</span> The Bootstrap: Simulating Uncertainty</h2>
<section id="the-core-idea" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="the-core-idea"><span class="header-section-number">4.5.1</span> The Core Idea</h3>
<p>The bootstrap, invented by Bradley Efron in 1979, is one of the most important statistical innovations of the 20th century. It provides a general, computational method for assessing the uncertainty of virtually any statistic or functional of the data.</p>
<p>Let <span class="math inline">T_n = g(X_1, \ldots, X_n)</span> be our statistic of interest (e.g., the median, the variance, a given quantile). What’s its variability?</p>
<p>The key insight is simple: <strong>We can learn about the variability of our statistic by seeing how it varies across different samples. Since we only have one sample, we create new samples by resampling from our data.</strong></p>
<p>Here’s the crucial diagram that illustrates the bootstrap principle:</p>
<pre><code>Real World:      F   ==&gt;   X₁,...,Xₙ   ==&gt;   Tₙ = g(X)
                 ↑                            ↑
                 Unknown                      What we want to understand

Bootstrap World: F̂ₙ  ==&gt;   X₁*,...,Xₙ*  ==&gt;  Tₙ* = g(X*)
                 ↑                            ↑
                 Known!                       What we can simulate</code></pre>
<p>In the real world:</p>
<ul>
<li>Nature draws from the unknown distribution <span class="math inline">F</span></li>
<li>We observe one sample <span class="math inline">X_1, \ldots, X_n</span></li>
<li>We calculate our statistic <span class="math inline">T_n = g(X_1, \ldots, X_n)</span></li>
<li>We want to know the sampling distribution of <span class="math inline">T_n</span></li>
</ul>
<p>In the bootstrap world:</p>
<ul>
<li>We draw from the known empirical distribution <span class="math inline">\hat{F}_n</span> (see below)</li>
<li>We get a bootstrap sample <span class="math inline">X_1^*, \ldots, X_n^*</span></li>
<li>We calculate the bootstrap statistic <span class="math inline">T_n^* = g(X_1^*, \ldots, X_n^*)</span></li>
<li><strong>We can repeat the process multiple times to simulate the sampling distribution of <span class="math inline">T_n^*</span></strong></li>
</ul>
<p><strong>The Bootstrap Principle</strong>: The distribution of <span class="math inline">T_n^*</span> around <span class="math inline">T_n</span> approximates the distribution of <span class="math inline">T_n</span> around <span class="math inline">T(F)</span>.</p>
<p>How do we draw from <span class="math inline">\hat{F}_n</span>? Remember that <span class="math inline">\hat{F}_n</span> puts mass <span class="math inline">1/n</span> at each observed data point. Therefore:</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Key Point</strong>: Drawing from <span class="math inline">\hat{F}_n</span> means sampling <strong>with replacement</strong> from the original data. Each bootstrap sample contains <span class="math inline">n</span> observations, some repeated, some omitted.</p>
</div>
</div>
</section>
<section id="bootstrap-variance-and-standard-error-estimation" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="bootstrap-variance-and-standard-error-estimation"><span class="header-section-number">4.5.2</span> Bootstrap Variance and Standard Error Estimation</h3>
<p>Let’s make this concrete with an algorithm:</p>
<p><strong>Bootstrap Algorithm for Standard Error Estimation</strong>:</p>
<ol type="1">
<li>For <span class="math inline">b = 1, \ldots, B</span>:
<ul>
<li>Draw a bootstrap sample <span class="math inline">X_1^*, \ldots, X_n^*</span> by sampling with replacement from <span class="math inline">\{X_1, \ldots, X_n\}</span></li>
<li>Compute the statistic for this bootstrap sample: <span class="math inline">T_{n,b}^* = g(X_1^*, \ldots, X_n^*)</span></li>
</ul></li>
<li>The bootstrap estimate of the standard error is: <span class="math display">\widehat{\text{se}}_{\text{boot}} = \sqrt{\frac{1}{B-1}\sum_{b=1}^B \left(T_{n,b}^* - \bar{T}_n^*\right)^2}</span> where <span class="math inline">\bar{T}_n^* = \frac{1}{B}\sum_{b=1}^B T_{n,b}^*</span></li>
</ol>
<p>Let’s implement this for a concrete example – estimating the standard error of the median:</p>
<div class="tabset-margin-container"></div><div class="tabset-margin-container"></div><div class="panel-tabset"><ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1757255598-357-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1757255598-357-1" role="tab" aria-controls="tabset-1757255598-357-1" aria-selected="true" href="" aria-current="page">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1757255598-357-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1757255598-357-2" role="tab" aria-controls="tabset-1757255598-357-2" aria-selected="false" href="">R</a></li></ul><div class="tab-content"><div id="tabset-1757255598-357-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1757255598-357-1-tab"><div id="2ff17e4f" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1" data-code-fold="false"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bootstrap_se(data, statistic, B<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute bootstrap standard error of a statistic.</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    data : array-like</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Original sample</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    statistic : function</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Function that computes the statistic of interest</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">    B : int</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of bootstrap replications</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">    se : float</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Bootstrap standard error</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co">    boot_samples : array</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">        Bootstrap replications of the statistic</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    boot_samples <span class="op">=</span> np.zeros(B)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw bootstrap sample</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        x_star <span class="op">=</span> np.random.choice(data, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute statistic</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        boot_samples[b] <span class="op">=</span> statistic(x_star)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute standard error</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> np.std(boot_samples, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> se, boot_samples</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Standard error of the median</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.exponential(scale<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Point estimate</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>median_est <span class="op">=</span> np.median(data)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap standard error</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>se_boot, boot_medians <span class="op">=</span> bootstrap_se(data, np.median, B<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample median: </span><span class="sc">{</span>median_est<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Bootstrap SE: </span><span class="sc">{</span>se_boot<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Approximate 95% CI: (</span><span class="sc">{</span>median_est <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>se_boot<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>median_est <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>se_boot<span class="sc">:.3f}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sample median: 1.146
Bootstrap SE: 0.276
Approximate 95% CI: (0.594, 1.697)</code></pre>
</div>
</div></div><div id="tabset-1757255598-357-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1757255598-357-2-tab"><div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>bootstrap_se <span class="ot">&lt;-</span> <span class="cf">function</span>(data, statistic, <span class="at">B =</span> <span class="dv">1000</span>) {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' Compute bootstrap standard error of a statistic</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' </span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @param data Original sample vector</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @param statistic Function that computes the statistic of interest</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @param B Number of bootstrap replications</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @return List with standard error and bootstrap samples</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  boot_samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw bootstrap sample</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    x_star <span class="ot">&lt;-</span> <span class="fu">sample</span>(data, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute statistic</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    boot_samples[b] <span class="ot">&lt;-</span> <span class="fu">statistic</span>(x_star)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute standard error</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  se <span class="ot">&lt;-</span> <span class="fu">sd</span>(boot_samples)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">se =</span> se, <span class="at">boot_samples =</span> boot_samples))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Standard error of the median</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Point estimate</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>median_est <span class="ot">&lt;-</span> <span class="fu">median</span>(data)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap standard error</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">bootstrap_se</span>(data, median, <span class="at">B =</span> <span class="dv">2000</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>se_boot <span class="ot">&lt;-</span> result<span class="sc">$</span>se</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>boot_medians <span class="ot">&lt;-</span> result<span class="sc">$</span>boot_samples</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Sample median: %.3f</span><span class="sc">\n</span><span class="st">"</span>, median_est))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Bootstrap SE: %.3f</span><span class="sc">\n</span><span class="st">"</span>, se_boot))</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Approximate 95%% CI: (%.3f, %.3f)</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            median_est <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>se_boot, median_est <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>se_boot))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></div></div></div>
<p>Let’s visualize the bootstrap distribution:</p>
<div id="a218f16b" class="cell" data-fig-height="5" data-fig-width="7" data-execution_count="4">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Left panel: Original data</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>ax1.hist(data, bins<span class="op">=</span><span class="dv">20</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>ax1.axvline(median_est, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'Median = </span><span class="sc">{</span>median_est<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Original Data'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Right panel: Bootstrap distribution</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>ax2.hist(boot_medians, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'green'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>ax2.axvline(median_est, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>ax2.axvline(median_est <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>se_boot, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>ax2.axvline(median_est <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>se_boot, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="st">'95% CI'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Bootstrap median'</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Bootstrap Distribution'</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The left panel shows our original data. The right panel shows the distribution of the median across 2000 bootstrap samples. This distribution tells us about the uncertainty in our median estimate.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Two Sources of Error
</div>
</div>
<div class="callout-body-container callout-body">
<p>The bootstrap involves two approximations:</p>
<ol type="1">
<li><strong>Statistical Approximation</strong>: <span class="math inline">\mathbb{V}_F(T_n) \approx \mathbb{V}_{\hat{F}_n}(T_n)</span>
<ul>
<li>This depends on how well <span class="math inline">\hat{F}_n</span> approximates <span class="math inline">F</span></li>
<li>We can’t control this – it depends on our sample size <span class="math inline">n</span></li>
</ul></li>
<li><strong>Monte Carlo Approximation</strong>: <span class="math inline">\mathbb{V}_{\hat{F}_n}(T_n) \approx v_{\text{boot}}</span>
<ul>
<li>This depends on the number of bootstrap samples <span class="math inline">B</span></li>
<li>We can make this arbitrarily small by increasing <span class="math inline">B</span></li>
<li>Typically <span class="math inline">B \geq 1000</span> is sufficient</li>
</ul></li>
</ol>
<p>In formulas: <span class="math display">\mathbb{V}_F(T_n) \underbrace{\approx}_{\text{not so small}} \mathbb{V}_{\hat{F}_n}(T_n) \underbrace{\approx}_{\text{small}} v_{\text{boot}}</span></p>
<p>Remember: by increasing the bootstrap samples <span class="math inline">B</span> we can reduce the Monte Carlo error (due to simulation), but we cannot improve the statistical approximation error without obtaining more real data.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Monte Carlo Error Decreases With More Bootstrap Samples
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Let’s verify that the Monte Carlo error decreases with <span class="math inline">B</span>:</p>
<div id="eb6db212" class="cell" data-fig-height="4" data-fig-width="7" data-execution_count="5">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show convergence of bootstrap SE as B increases</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>B_values <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2000</span>, <span class="dv">5000</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>se_estimates <span class="op">=</span> []</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> B <span class="kw">in</span> B_values:</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    se, _ <span class="op">=</span> bootstrap_se(data, np.median, B<span class="op">=</span>B)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    se_estimates.append(se)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">4</span>))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plt.plot(B_values, se_estimates, <span class="st">'bo-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>plt.axhline(se_estimates[<span class="op">-</span><span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Converged value ≈ </span><span class="sc">{</span>se_estimates[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of bootstrap samples (B)'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Bootstrap SE estimate'</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Monte Carlo Error Decreases with B'</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The fluctuations for small <span class="math inline">B</span> are due to Monte Carlo variability. As <span class="math inline">B</span> increases, the bootstrap standard error estimate stabilizes. Still, this is only one component of the error – to improve further we need additional real data.</p>
</div>
</div>
</div>
</section>
</section>
<section id="bootstrap-confidence-intervals" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="bootstrap-confidence-intervals"><span class="header-section-number">4.6</span> Bootstrap Confidence Intervals</h2>
<section id="three-common-methods" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="three-common-methods"><span class="header-section-number">4.6.1</span> Three Common Methods</h3>
<p>Now that we can estimate the sampling distribution of any statistic via the bootstrap, we can construct confidence intervals. But how exactly should we use the bootstrap distribution to form an interval?</p>
<p>There are <strong>three main approaches</strong>, each with different strengths and weaknesses. We’ll illustrate all three using a real example: estimating the correlation between a country’s economic prosperity and the health of its population.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: European Health and Wealth Data
</div>
</div>
<div class="callout-body-container callout-body">
<p>This example explores the correlation between a country’s wealth (GDP per capita) and the average lifespan of its citizens (life expectancy at birth). The data is for a subset of EU countries, with <a href="https://en.wikipedia.org/wiki/List_of_sovereign_states_in_Europe_by_GDP_(nominal)_per_capita">GDP per capita for 2025</a> and <a href="https://en.wikipedia.org/wiki/List_of_European_countries_by_life_expectancy">life expectancy from 2023</a>.</p>
<div id="7ea87c9c" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># European Health and Wealth Data</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GDP per capita (2025 forecast), Life Expectancy at birth (2023) for a subset of EU countries.</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>countries <span class="op">=</span> [</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Germany'</span>, <span class="st">'France'</span>, <span class="st">'Italy'</span>, <span class="st">'Spain'</span>, <span class="st">'Netherlands'</span>, <span class="st">'Poland'</span>, </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Belgium'</span>, <span class="st">'Sweden'</span>, <span class="st">'Austria'</span>, <span class="st">'Ireland'</span>, <span class="st">'Denmark'</span>, <span class="st">'Finland'</span>, </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Portugal'</span>, <span class="st">'Greece'</span>, <span class="st">'Czech Republic'</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>gdp_per_capita <span class="op">=</span> np.array([</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="dv">55911</span>, <span class="dv">46792</span>, <span class="dv">41091</span>, <span class="dv">36192</span>, <span class="dv">70480</span>, <span class="dv">26805</span>, <span class="dv">57772</span>, <span class="dv">58100</span>, <span class="dv">58192</span>, </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="dv">108919</span>, <span class="dv">74969</span>, <span class="dv">54163</span>, <span class="dv">30002</span>, <span class="dv">25756</span>, <span class="dv">33039</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>life_expectancy <span class="op">=</span> np.array([</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="fl">81.38</span>, <span class="fl">83.33</span>, <span class="fl">83.72</span>, <span class="fl">83.67</span>, <span class="fl">82.16</span>, <span class="fl">78.63</span>, <span class="fl">82.11</span>, <span class="fl">83.26</span>, <span class="fl">81.96</span>, </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="fl">82.41</span>, <span class="fl">81.93</span>, <span class="fl">81.91</span>, <span class="fl">82.36</span>, <span class="fl">81.86</span>, <span class="fl">79.83</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine into a single dataset for resampling</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>data_combined <span class="op">=</span> np.column_stack((gdp_per_capita, life_expectancy))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(life_expectancy)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Define correlation function</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> correlation(data):</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>]</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.corrcoef(x, y)[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Original correlation</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>rho_hat <span class="op">=</span> correlation(data_combined)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample correlation: </span><span class="sc">{</span>rho_hat<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Sample correlation: 0.238</code></pre>
</div>
</div>
</div>
</div>
<p>Now let’s generate bootstrap samples:</p>
<div id="c29d9ce9" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap the correlation</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>boot_correlations <span class="op">=</span> np.zeros(B)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resample pairs (important to maintain pairing!)</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(n, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    boot_sample <span class="op">=</span> data_combined[indices]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    boot_correlations[b] <span class="op">=</span> correlation(boot_sample)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap standard error</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>se_boot <span class="op">=</span> np.std(boot_correlations, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Bootstrap SE: </span><span class="sc">{</span>se_boot<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Bootstrap SE: 0.241</code></pre>
</div>
</div>
<p>Let’s visualize the bootstrap distribution:</p>
<div id="17647b0f" class="cell" data-fig-height="5" data-fig-width="7" data-execution_count="8">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of original data</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(gdp_per_capita, life_expectancy, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'GDP per Capita (US$)'</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Life Expectancy (Years)'</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="ss">f'European Countries (ρ = </span><span class="sc">{</span>rho_hat<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>ax2.hist(boot_correlations, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>         color<span class="op">=</span><span class="st">'green'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>ax2.axvline(rho_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Original ρ = </span><span class="sc">{</span>rho_hat<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Bootstrap Correlation'</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Bootstrap Distribution'</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Notice that the bootstrap distribution is somewhat skewed. This skewness will affect our confidence intervals.</p>
</section>
<section id="comparing-bootstrap-confidence-intervals" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="comparing-bootstrap-confidence-intervals"><span class="header-section-number">4.6.2</span> Comparing Bootstrap Confidence Intervals</h3>
<p>Let <span class="math inline">\hat{T}_n = T_n(\hat{F}_n)</span> be the statistic evaluated on the empirical distribution, and <span class="math inline">T_n^*</span> the bootstrap statistic.</p>
<div class="tabset-margin-container"></div><div class="tabset-margin-container"></div><div class="panel-tabset"><ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1757255598-120-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1757255598-120-1" role="tab" aria-controls="tabset-1757255598-120-1" aria-selected="true" href="">Method 1: Normal Interval</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1757255598-120-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1757255598-120-2" role="tab" aria-controls="tabset-1757255598-120-2" aria-selected="false" href="">Method 2: Percentile Interval</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1757255598-120-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1757255598-120-3" role="tab" aria-controls="tabset-1757255598-120-3" aria-selected="false" href="">Method 3: Pivotal Interval</a></li></ul><div class="tab-content"><div id="tabset-1757255598-120-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1757255598-120-1-tab"><p><strong>Formula</strong>:
<span class="math inline">\(\hat{T}_n \pm z_{\alpha/2} \widehat{\text{se}}_{\text{boot}}\)</span></p><p>This is the simplest method – we just use the bootstrap standard
error in the usual normal-based formula.</p><div id="268b751a" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal interval</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>z_alpha <span class="op">=</span> stats.norm.ppf(<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>normal_lower <span class="op">=</span> rho_hat <span class="op">-</span> z_alpha <span class="op">*</span> se_boot</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>normal_upper <span class="op">=</span> rho_hat <span class="op">+</span> z_alpha <span class="op">*</span> se_boot</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Normal interval: (</span><span class="sc">{</span>normal_lower<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>normal_upper<span class="sc">:.3f}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>95% Normal interval: (-0.235, 0.711)</code></pre>
</div>
</div><p><strong>Pros</strong>:</p><ul>
<li>Simple and intuitive</li>
<li>Only requires the standard error, not the full distribution</li>
<li>Familiar to those who know basic statistics</li>
</ul><p><strong>Cons</strong>:</p><ul>
<li>Assumes the sampling distribution is approximately normal</li>
<li>Can give nonsensical intervals (e.g., correlation &gt; 1)</li>
<li>Ignores skewness in the bootstrap distribution</li>
</ul><p>Let’s check if our interval makes sense:</p><div id="cbfd6f2c" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> normal_upper <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Warning: Upper limit </span><span class="sc">{</span>normal_upper<span class="sc">:.3f}</span><span class="ss"> exceeds 1!"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"This is impossible for a correlation!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div><div id="tabset-1757255598-120-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1757255598-120-2-tab"><p><strong>Formula</strong>:
<span class="math inline">\(\left(T^*_{n, \alpha/2}, T^*_{n, 1-\alpha/2}\right)\)</span></p><p>where <span class="math inline">\(T^*_{n,\beta}\)</span> denotes the
<span class="math inline">\(\beta\)</span> sample quantile of the
bootstrapped statistic values
<span class="math inline">\(T^*_n\)</span>.</p><p>The percentile interval method uses the
<span class="math inline">\(\alpha/2\)</span> and
<span class="math inline">\(1-\alpha/2\)</span> quantiles of the
bootstrap distribution directly.</p><div id="44298351" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Percentile interval</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>percentile_lower <span class="op">=</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>percentile_upper <span class="op">=</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Percentile interval: (</span><span class="sc">{</span>percentile_lower<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>percentile_upper<span class="sc">:.3f}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>95% Percentile interval: (-0.389, 0.596)</code></pre>
</div>
</div><p><strong>Pros</strong>:</p><ul>
<li>Doesn’t assume normality – adapts to the actual shape</li>
<li>Always respects parameter bounds (correlation stays in [-1, 1])</li>
<li>Simple to understand: “middle 95% of bootstrap values”</li>
<li>Works well when the bootstrap distribution is approximately
unbiased</li>
</ul><p><strong>Cons</strong>:</p><ul>
<li>Can have poor coverage when there’s bias</li>
<li>Not transformation-invariant</li>
<li>May not be accurate for small samples</li>
</ul></div><div id="tabset-1757255598-120-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1757255598-120-3-tab"><p><strong>Formula</strong>:
<span class="math inline">\(\left(2\hat{T}_n - T^*_{n, 1-\alpha/2}, 2\hat{T}_n - T^*_{n, \alpha/2}\right)\)</span></p><p>This method assumes that the distribution of
<span class="math inline">\(T_n - \theta\)</span> is approximately the
same as the distribution of
<span class="math inline">\(T_n^* - T_n\)</span>, where
<span class="math inline">\(\theta\)</span> is the true parameter.</p><div id="35d90cca" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pivotal interval  </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>pivotal_lower <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> rho_hat <span class="op">-</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>pivotal_upper <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> rho_hat <span class="op">-</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Pivotal interval: (</span><span class="sc">{</span>pivotal_lower<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>pivotal_upper<span class="sc">:.3f}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>95% Pivotal interval: (-0.120, 0.865)</code></pre>
</div>
</div><p><strong>Pros</strong>:</p><ul>
<li>Often more accurate than the other two methods</li>
<li>Corrects for bias in the estimator</li>
<li>Transformation-respecting (invariant under monotone
transformations)</li>
</ul><p><strong>Cons</strong>:</p><ul>
<li>Less intuitive – the formula seems backwards at first</li>
<li>Can occasionally give values outside parameter bounds</li>
<li>Requires symmetric error distribution for best performance</li>
</ul></div></div></div>
<p>Let’s compare all three intervals visually:</p>
<div id="f79a8fa4" class="cell" data-fig-height="5" data-fig-width="7" data-execution_count="13">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot bootstrap distribution</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>histogram_data <span class="op">=</span> ax.hist(boot_correlations, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>                        color<span class="op">=</span><span class="st">'gray'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap distribution'</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the maximum height for positioning intervals</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>max_density <span class="op">=</span> <span class="bu">max</span>(histogram_data[<span class="dv">0</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Add vertical lines for original estimate</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>ax.axvline(rho_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Original estimate'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Add confidence intervals overlaid on the histogram</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>methods <span class="op">=</span> [<span class="st">'Normal'</span>, <span class="st">'Percentile'</span>, <span class="st">'Pivotal'</span>]</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>intervals <span class="op">=</span> [(normal_lower, normal_upper), </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>             (percentile_lower, percentile_upper),</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>             (pivotal_lower, pivotal_upper)]</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>, <span class="st">'green'</span>, <span class="st">'orange'</span>]</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Position intervals at different heights on the histogram</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>y_positions <span class="op">=</span> [max_density <span class="op">*</span> <span class="fl">0.2</span>, max_density <span class="op">*</span> <span class="fl">0.15</span>, max_density <span class="op">*</span> <span class="fl">0.1</span>]</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method, (lower, upper), color, y_pos <span class="kw">in</span> <span class="bu">zip</span>(methods, intervals, colors, y_positions):</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw the interval line</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    ax.plot([lower, upper], [y_pos, y_pos], color<span class="op">=</span>color, linewidth<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>            marker<span class="op">=</span><span class="st">'|'</span>, markersize<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>method<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add vertical lines at interval endpoints</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    ax.vlines([lower, upper], <span class="dv">0</span>, y_pos, color<span class="op">=</span>color, linestyle<span class="op">=</span><span class="st">':'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Correlation'</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Bootstrap Distribution with Confidence Intervals'</span>)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, max_density <span class="op">*</span> <span class="fl">1.1</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s summarize the confidence intervals in a table for easy comparison:</p>
<div id="499b8d91" class="cell" data-execution_count="14">
<div class="cell-output cell-output-stdout">
<pre><code>| Method     | Lower Bound | Upper Bound | Width |
|------------|-------------|-------------|-------|
| Normal     |   -0.235    |    0.711    | 0.946 |
| Percentile |   -0.389    |    0.596    | 0.986 |
| Pivotal    |   -0.120    |    0.865    | 0.986 |</code></pre>
</div>
</div>
<p>In this example:</p>
<ul>
<li>The <strong>Normal interval</strong> is symmetric around the point estimate, ignoring the skewness</li>
<li>The <strong>Percentile interval</strong> reflects the skewness of the bootstrap distribution<br>
</li>
<li>The <strong>Pivotal interval</strong> adjusts for bias and is slightly shifted from the percentile interval</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advanced: Justification for the Pivotal Interval
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The pivotal method seems counterintuitive at first. Why do we subtract the upper quantile from <span class="math inline">2\hat{T}_n</span> to get the lower bound?</p>
<p>The key insight is that the pivotal interval assumes the error <span class="math inline">\hat{T}_n - \theta</span> (where <span class="math inline">\theta = T(F)</span> is the true value) behaves similarly to the bootstrap error <span class="math inline">T_n^* - \hat{T}_n</span>.</p>
<p><strong>Quick derivation</strong>: Start with the bootstrap distribution: <span class="math display">\mathbb{P}( T^*_{n,\alpha/2} \leq T_n^* \leq T^*_{n,1-\alpha/2} ) = 1-\alpha</span></p>
<p>Subtract <span class="math inline">\hat{T}_n</span> throughout: <span class="math display">\mathbb{P}( T^*_{n,\alpha/2} - \hat{T}_n \leq T_n^* - \hat{T}_n \leq T^*_{n,1-\alpha/2} - \hat{T}_n ) = 1-\alpha</span></p>
<p>The key assumption: The bootstrap error <span class="math inline">T_n^* - \hat{T}_n</span> has approximately the same distribution as the real error <span class="math inline">\hat{T}_n - \theta</span>. Therefore: <span class="math display">\mathbb{P}( T^*_{n,\alpha/2} - \hat{T}_n \leq \hat{T}_n - \theta \leq T^*_{n,1-\alpha/2} - \hat{T}_n ) \approx 1-\alpha</span></p>
<p>Rearranging to isolate <span class="math inline">\theta</span>: <span class="math display">\mathbb{P}( 2\hat{T}_n - T^*_{n,1-\alpha/2} \leq \theta \leq 2\hat{T}_n - T^*_{n,\alpha/2} ) \approx 1-\alpha</span></p>
<p>This gives us the pivotal interval: <span class="math inline">(2\hat{T}_n - T^*_{n,1-\alpha/2}, 2\hat{T}_n - T^*_{n,\alpha/2})</span>.</p>
<p><strong>Intuition</strong>: If bootstrap values tend to be above our estimate, then our estimate is probably below the truth by a similar amount. The “2×estimate minus bootstrap quantile” formula automatically corrects for this bias.</p>
</div>
</div>
</div>
</section>
</section>
<section id="bootstrap-application-higher-moments" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="bootstrap-application-higher-moments"><span class="header-section-number">4.7</span> Bootstrap Application: Higher Moments</h2>
<p>The following example demonstrates both the power and limitations of the bootstrap.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Bootstrap for Higher Moments
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a sample of <span class="math inline">n = 20</span> observations from a standard normal distribution <span class="math inline">\mathcal{N}(0, 1)</span>. We’ll use the bootstrap to estimate confidence intervals for two related statistics:</p>
<ol type="1">
<li><span class="math inline">T^{(1)}(F) = \mathbb{E}[X^4]</span> - the fourth raw moment</li>
<li><span class="math inline">T^{(2)}(F) = \mathbb{E}[(X - \mu)^4]</span> - the fourth central moment</li>
</ol>
<p>For the standard normal, both have the same true value: <span class="math inline">T^{(1)}(F) = T^{(2)}(F) = 3</span>.</p>
<p>This example is valuable because:</p>
<ul>
<li>We can compute the true sampling distribution via simulation</li>
<li>It shows how bootstrap performs for non-standard statistics</li>
<li>It reveals differences between seemingly similar estimators</li>
</ul>
</div>
</div>
<p>Let’s implement this comparison:</p>
<div id="5d3db68b" class="cell" data-fig-height="10" data-fig-width="8" data-execution_count="15">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the experiment</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>true_value <span class="op">=</span> <span class="dv">3</span>  <span class="co"># True 4th moment for N(0,1)</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate one sample</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute point estimates</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>T1_hat <span class="op">=</span> np.mean(sample<span class="op">**</span><span class="dv">4</span>)  <span class="co"># Raw 4th moment</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>T2_hat <span class="op">=</span> np.mean((sample <span class="op">-</span> np.mean(sample))<span class="op">**</span><span class="dv">4</span>)  <span class="co"># Central 4th moment</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True value: </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"T¹ (raw 4th moment): </span><span class="sc">{</span>T1_hat<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"T² (central 4th moment): </span><span class="sc">{</span>T2_hat<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distributions</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>boot_T1 <span class="op">=</span> np.zeros(B)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>boot_T2 <span class="op">=</span> np.zeros(B)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    boot_sample <span class="op">=</span> np.random.choice(sample, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    boot_T1[b] <span class="op">=</span> np.mean(boot_sample<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    boot_T2[b] <span class="op">=</span> np.mean((boot_sample <span class="op">-</span> np.mean(boot_sample))<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distributions (via simulation)</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>n_true <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>true_T1 <span class="op">=</span> np.zeros(n_true)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>true_T2 <span class="op">=</span> np.zeros(n_true)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_true):</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    true_sample <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    true_T1[i] <span class="op">=</span> np.mean(true_sample<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>    true_T2[i] <span class="op">=</span> np.mean((true_sample <span class="op">-</span> np.mean(true_sample))<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine common x-axis range to show the dramatic difference</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>x_min <span class="op">=</span> <span class="bu">min</span>(np.<span class="bu">min</span>(boot_T1), np.<span class="bu">min</span>(boot_T2), np.<span class="bu">min</span>(true_T1), np.<span class="bu">min</span>(true_T2))</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>x_max <span class="op">=</span> <span class="bu">max</span>(np.<span class="bu">max</span>(boot_T1), np.<span class="bu">max</span>(boot_T2), np.<span class="bu">max</span>(true_T1), np.<span class="bu">max</span>(true_T2))</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure with 4 subplots</span></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">10</span>))</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a><span class="co"># T1: Raw 4th moment</span></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>ax1.hist(boot_T1, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, </span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap'</span>)</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>ax1.axvline(T1_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Estimate = </span><span class="sc">{</span>T1_hat<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>ax1.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'T¹: Bootstrap Distribution'</span>)</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>ax1.set_xlim(x_min, x_max)</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distribution</span></span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>ax2.hist(true_T1, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'green'</span>, </span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'True sampling dist'</span>)</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>ax2.axvline(np.mean(true_T1), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Mean = </span><span class="sc">{</span>np<span class="sc">.</span>mean(true_T1)<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>ax2.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'T¹: True Sampling Distribution'</span>)</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>ax2.set_xlim(x_min, x_max)</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a><span class="co"># T2: Central 4th moment</span></span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a>ax3 <span class="op">=</span> axes[<span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>ax3.hist(boot_T2, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, </span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap'</span>)</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>ax3.axvline(T2_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Estimate = </span><span class="sc">{</span>T2_hat<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a>ax3.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a>ax3.set_title(<span class="st">'T²: Bootstrap Distribution'</span>)</span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>ax3.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a>ax3.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>ax3.set_xlim(x_min, x_max)</span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>ax3.legend()</span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a>ax3.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distribution</span></span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a>ax4 <span class="op">=</span> axes[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a>ax4.hist(true_T2, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'green'</span>, </span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'True sampling dist'</span>)</span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a>ax4.axvline(np.mean(true_T2), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Mean = </span><span class="sc">{</span>np<span class="sc">.</span>mean(true_T2)<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a>ax4.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a>ax4.set_title(<span class="st">'T²: True Sampling Distribution'</span>)</span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a>ax4.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a>ax4.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a>ax4.set_xlim(x_min, x_max)</span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a>ax4.legend()</span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a>ax4.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Bootstrap vs True Sampling Distributions'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>True value: 3
T¹ (raw 4th moment): 2.025
T² (central 4th moment): 1.882</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-16-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now let’s compare the confidence intervals:</p>
<div id="413ba500" class="cell" data-execution_count="16">
<div class="cell-output cell-output-stdout">
<pre><code>Confidence Intervals for T¹ (Raw 4th Moment):
  True 95% CI:        (0.58, 8.84)
  Bootstrap Normal:   (0.42, 3.63)
  Bootstrap Percent:  (0.64, 3.79)
  Bootstrap Pivotal:  (0.26, 3.41)

Confidence Intervals for T² (Central 4th Moment):
  True 95% CI:        (0.50, 7.97)
  Bootstrap Normal:   (0.41, 3.36)
  Bootstrap Percent:  (0.48, 3.36)
  Bootstrap Pivotal:  (0.40, 3.29)</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What Went Wrong?
</div>
</div>
<div class="callout-body-container callout-body">
<p>The bootstrap catastrophically fails here – all methods estimate upper confidence bounds of ~3.4-3.8, while the true bounds are ~8-9 (more than double!).</p>
<p>Why? Fourth moments have heavy-tailed sampling distributions. With only n=20 observations, we likely missed the rare extreme values that drive the true variability. The bootstrap can only resample what it sees, so it fundamentally cannot capture the full range of uncertainty.</p>
<p>This isn’t just a small sample problem – it’s a fundamental limitation when statistics depend heavily on extreme values. Let’s explore when else the bootstrap fails…</p>
</div>
</div>
</section>
<section id="when-the-bootstrap-fails" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="when-the-bootstrap-fails"><span class="header-section-number">4.8</span> When The Bootstrap Fails</h2>
<p>The bootstrap is remarkably general, but it’s not foolproof. It relies on the sample being a good representation of the population. When this assumption breaks down, so does the bootstrap.</p>
<p>The bootstrap may fail or perform poorly when:</p>
<ol type="1">
<li><strong>Sample size is too small</strong> (typically n &lt; 20-30)</li>
<li><strong>Estimating extreme order statistics</strong> (min, max, extreme quantiles)</li>
<li><strong>Heavy-tailed distributions</strong> without finite moments</li>
<li><strong>Non-smooth statistics</strong> (e.g., number of modes)</li>
<li><strong>Dependent data</strong> (unless using specialized methods like block bootstrap)</li>
</ol>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Estimators at the Boundary
</div>
</div>
<div class="callout-body-container callout-body">
<p>The bootstrap performs poorly for statistics at the edge of the parameter space. The classic example is estimating the maximum of a uniform distribution:</p>
<div id="f17d3626" class="cell" data-fig-height="5" data-fig-width="7" data-execution_count="17">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Uniform distribution example</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>true_max <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>uniform_sample <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, true_max, n)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>sample_max <span class="op">=</span> np.<span class="bu">max</span>(uniform_sample)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distribution of the maximum</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># For Uniform(0, θ), the maximum has CDF F(x) = (x/θ)^n</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>x_theory <span class="op">=</span> np.linspace(sample_max <span class="op">*</span> <span class="fl">0.8</span>, true_max, <span class="dv">1000</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>pdf_theory <span class="op">=</span> n <span class="op">*</span> (x_theory<span class="op">/</span>true_max)<span class="op">**</span>(n<span class="op">-</span><span class="dv">1</span>) <span class="op">/</span> true_max</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>boot_max_uniform <span class="op">=</span> np.zeros(B)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    boot_sample <span class="op">=</span> np.random.choice(uniform_sample, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    boot_max_uniform[b] <span class="op">=</span> np.<span class="bu">max</span>(boot_sample)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap histogram</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>ax.hist(boot_max_uniform, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap distribution'</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co"># True distribution</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>ax.plot(x_theory, pdf_theory, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True distribution'</span>)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Key values</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>ax.axvline(sample_max, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Sample max = </span><span class="sc">{</span>sample_max<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>ax.axvline(true_max, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'True θ = </span><span class="sc">{</span>true_max<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Bootstrap Fails for Uniform Maximum'</span>)</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">8</span>, <span class="fl">10.5</span>)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04-nonparametric-bootstrap_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Why it fails</strong>:</p>
<ul>
<li>The true maximum (<span class="math inline">\theta = 10</span>) is always ≥ the sample maximum</li>
<li>The true sampling distribution has support on <span class="math inline">[\text{sample max}, \theta]</span></li>
<li>But bootstrap samples can never exceed the original sample maximum!</li>
<li>The bootstrap distribution is entirely to the left of where it should be</li>
</ul>
<p><strong>Note:</strong> Similar biases arise when estimating extreme statistics (e.g., very small or very large quantiles) of any distribution.</p>
</div>
</div>
<p>Despite these limitations, the bootstrap remains one of the most useful tools in modern statistics. Just remember: it’s a powerful method, not a magical one.</p>
</section>
<section id="chapter-summary-and-connections" class="level2" data-number="4.9">
<h2 data-number="4.9" class="anchored" data-anchor-id="chapter-summary-and-connections"><span class="header-section-number">4.9</span> Chapter Summary and Connections</h2>
<section id="key-concepts-review" class="level3" data-number="4.9.1">
<h3 data-number="4.9.1" class="anchored" data-anchor-id="key-concepts-review"><span class="header-section-number">4.9.1</span> Key Concepts Review</h3>
<p>We’ve covered two fundamental ideas that revolutionized statistical practice:</p>
<p><strong>The Plug-In Principle</strong>:</p>
<ul>
<li>Estimate the distribution with the empirical distribution function (EDF)</li>
<li>Estimate any functional <span class="math inline">T(F)</span> by computing <span class="math inline">T(\hat{F}_n)</span></li>
<li>Simple, intuitive, and widely applicable</li>
<li>Gives us point estimates for any statistic</li>
</ul>
<p><strong>The Bootstrap</strong>:</p>
<ul>
<li>Assess uncertainty by resampling from the data</li>
<li>Create the “bootstrap world” that mimics the real world</li>
<li>Estimate standard errors and confidence intervals for any statistic</li>
<li>Three types of confidence intervals: Normal, Percentile, Pivotal</li>
</ul>
</section>
<section id="why-these-concepts-matter" class="level3" data-number="4.9.2">
<h3 data-number="4.9.2" class="anchored" data-anchor-id="why-these-concepts-matter"><span class="header-section-number">4.9.2</span> Why These Concepts Matter</h3>
<p><strong>For Statistical Practice</strong>:</p>
<ul>
<li>No need to derive complex formulas for standard errors</li>
<li>Works for statistics where theory is intractable (median, correlation, etc.)</li>
<li>Provides a unified approach to uncertainty quantification</li>
<li>Democratizes statistics – complex inference becomes accessible</li>
</ul>
<p><strong>For Data Science</strong>:</p>
<ul>
<li>Computational approach aligns with modern computing power</li>
<li>Easy to implement and parallelize</li>
<li>Works with complex models and machine learning algorithms</li>
<li>Provides uncertainty estimates crucial for decision-making</li>
</ul>
<p><strong>For Understanding</strong>:</p>
<ul>
<li>Makes abstract concepts concrete through simulation</li>
<li>Reveals the sampling distribution visually</li>
<li>Helps build intuition about statistical variability</li>
<li>Connects theoretical statistics to computational practice</li>
</ul>
</section>
<section id="common-pitfalls-to-avoid" class="level3" data-number="4.9.3">
<h3 data-number="4.9.3" class="anchored" data-anchor-id="common-pitfalls-to-avoid"><span class="header-section-number">4.9.3</span> Common Pitfalls to Avoid</h3>
<ol type="1">
<li><strong>Forgetting to sample with replacement</strong>
<ul>
<li>Bootstrap samples must be the same size as original</li>
<li>Sampling without replacement gives wrong answers</li>
</ul></li>
<li><strong>Using too few bootstrap samples</strong>
<ul>
<li>Use at least <span class="math inline">B = 1,000</span> for standard errors</li>
<li>Use <span class="math inline">B = 10,000</span> or more for confidence intervals</li>
<li>Monte Carlo error decreases with <span class="math inline">\sqrt{B}</span></li>
<li>In practice, use as many as you can given your available compute</li>
</ul></li>
<li><strong>Misinterpreting confidence intervals</strong>
<ul>
<li>They quantify uncertainty in the estimate</li>
<li>They are not probability statements about parameters</li>
<li>Different methods can give different intervals</li>
</ul></li>
<li><strong>Applying bootstrap blindly</strong>
<ul>
<li>Check if your statistic is smooth</li>
<li>Be cautious with very small samples</li>
<li>Watch out for boundary cases</li>
</ul></li>
<li><strong>Ignoring the assumptions</strong>
<ul>
<li>Bootstrap assumes the sample represents the population</li>
<li>It can’t fix biased sampling or systematic errors</li>
<li>It’s not magic – just clever resampling</li>
</ul></li>
</ol>
</section>
<section id="chapter-connections" class="level3" data-number="4.9.4">
<h3 data-number="4.9.4" class="anchored" data-anchor-id="chapter-connections"><span class="header-section-number">4.9.4</span> Chapter Connections</h3>
<p>The bootstrap builds on our theoretical foundations and provides a computational path forward:</p>
<ul>
<li><p><strong>From Previous Chapters</strong>: We’ve applied the plug-in principle to the empirical distribution (Chapter 1’s probability concepts), used Chapter 2’s variance formulas for bootstrap standard errors, and provided an alternative to Chapter 3’s CLT-based confidence intervals when theoretical distributions are intractable</p></li>
<li><p><strong>Next - Hypothesis Testing (Chapter 5)</strong>: Bootstrap will create null distributions for complex test statistics, complemented by permutation tests as another resampling approach</p></li>
<li><p><strong>Parametric Methods (Chapters 6-7)</strong>: Compare bootstrap to theoretical approaches, use it to validate assumptions, and construct confidence intervals for maximum likelihood estimates when standard theory is difficult</p></li>
<li><p><strong>Machine Learning Applications</strong>: Bootstrap underpins ensemble methods (bagging), provides uncertainty quantification for predictions, and helps with model selection—making it essential for modern data science</p></li>
</ul>
</section>
<section id="rejoinder-coming-full-circle" class="level3" data-number="4.9.5">
<h3 data-number="4.9.5" class="anchored" data-anchor-id="rejoinder-coming-full-circle"><span class="header-section-number">4.9.5</span> Rejoinder: Coming Full Circle</h3>
<p>Recall our opening example: the healthcare administrator planning hospital capacity during an epidemic. We began by asking how to quantify the uncertainty in our estimates, not just provide point predictions.</p>
<p>Through this chapter, we’ve answered that question with two powerful tools:</p>
<ol type="1">
<li><strong>The plug-in principle</strong> gave us a way to estimate any property of a distribution</li>
<li><strong>The bootstrap</strong> gave us a way to quantify the uncertainty of those estimates</li>
</ol>
<p>These tools enable data-driven decision making by providing not just estimates, but confidence intervals that capture the range of plausible values. Whether you’re estimating hospital capacity, financial risk, or any other critical quantity, you now have the tools to say not just “we expect 500 patients” but “we’re 95% confident it will be between 300 and 700 patients.”</p>
<p>This transformation from point estimates to uncertainty quantification is what makes statistics invaluable for real-world decision making.</p>
</section>
<section id="practical-advice" class="level3" data-number="4.9.6">
<h3 data-number="4.9.6" class="anchored" data-anchor-id="practical-advice"><span class="header-section-number">4.9.6</span> Practical Advice</h3>
<ol type="1">
<li><strong>Start simple</strong>: Use percentile intervals as your default</li>
<li><strong>Visualize</strong>: Always plot the bootstrap distribution</li>
<li><strong>Compare methods</strong>: Try different CI methods to check robustness</li>
<li><strong>Think about assumptions</strong>: Is your sample representative?</li>
<li><strong>Use modern tools</strong>: Most software has built-in bootstrap functions</li>
</ol>
<p>The bootstrap exemplifies the shift from mathematical to computational statistics. Master it, and you’ll have a powerful tool for almost any statistical problem you encounter.</p>
</section>
<section id="quick-self-check" class="level3" data-number="4.9.7">
<h3 data-number="4.9.7" class="anchored" data-anchor-id="quick-self-check"><span class="header-section-number">4.9.7</span> Quick Self-Check</h3>
<p>Before moving on, test your understanding with these questions:</p>
<ol type="1">
<li><strong>What is bootstrap sampling used for?</strong></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Estimating the sampling distribution of a statistic</li>
<li>Computing standard errors and confidence intervals<br>
</li>
<li>Assessing uncertainty when no formula exists</li>
</ul>
<p>The bootstrap is particularly valuable when theoretical formulas are intractable or don’t exist, such as for the median, correlation coefficient, or complex machine learning predictions.</p>
</div>
</div>
</div>
<ol start="2" type="1">
<li><strong>What approximations does the method make?</strong></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Statistical approximation</strong>: Assumes <span class="math inline">\hat{F}_n</span> approximates <span class="math inline">F</span> well
<ul>
<li>This depends on sample size <span class="math inline">n</span> and cannot be improved without more data</li>
</ul></li>
<li><strong>Monte Carlo approximation</strong>: Finite <span class="math inline">B</span> approximates infinite resampling
<ul>
<li>This can be made arbitrarily small by increasing <span class="math inline">B</span> (typically <span class="math inline">B \geq 1,000</span>)</li>
</ul></li>
</ul>
<p>Remember: <span class="math inline">\mathbb{V}_F(T_n) \underbrace{\approx}_{\text{statistical error}} \mathbb{V}_{\hat{F}_n}(T_n) \underbrace{\approx}_{\text{Monte Carlo error}} v_{\text{boot}}</span></p>
</div>
</div>
</div>
<ol start="3" type="1">
<li><strong>What are its limitations?</strong></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Small samples</strong> (typically <span class="math inline">n &lt; 20-30</span>): The empirical distribution poorly represents the population</li>
<li><strong>Extreme order statistics</strong>: Cannot extrapolate beyond observed data range (e.g., max of uniform distribution)</li>
<li><strong>Heavy-tailed distributions</strong>: May miss rare extreme values that drive variability (as we saw with 4th moments)</li>
<li><strong>Non-smooth statistics</strong>: Discontinuous functions like the number of modes</li>
<li><strong>Dependent data</strong>: Requires specialized methods like block bootstrap for time series</li>
</ul>
<p>The key limitation: bootstrap cannot see what’s not in your sample!</p>
</div>
</div>
</div>
<ol start="4" type="1">
<li><strong>How can bootstrap be used to construct confidence intervals?</strong></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Three main methods, each with different strengths:</p>
<ul>
<li><strong>Normal interval</strong>: <span class="math inline">\hat{T}_n \pm z_{\alpha/2} \cdot \widehat{\text{se}}_{\text{boot}}</span>
<ul>
<li>Simplest, but assumes normality</li>
<li>Can give impossible values (e.g., correlation &gt; 1)</li>
</ul></li>
<li><strong>Percentile interval</strong>: <span class="math inline">(T^*_{n,\alpha/2}, T^*_{n,1-\alpha/2})</span>
<ul>
<li>Uses bootstrap quantiles directly</li>
<li>Respects parameter bounds, good default choice</li>
</ul></li>
<li><strong>Pivotal interval</strong>: <span class="math inline">(2\hat{T}_n - T^*_{n,1-\alpha/2}, 2\hat{T}_n - T^*_{n,\alpha/2})</span>
<ul>
<li>Corrects for bias, often most accurate</li>
<li>Can occasionally exceed parameter bounds</li>
</ul></li>
</ul>
<p>Choose based on your specific problem and always visualize the bootstrap distribution!</p>
</div>
</div>
</div>
</section>
<section id="self-test-problems" class="level3" data-number="4.9.8">
<h3 data-number="4.9.8" class="anchored" data-anchor-id="self-test-problems"><span class="header-section-number">4.9.8</span> Self-Test Problems</h3>
<ol type="1">
<li><p><strong>Implementing Bootstrap</strong>: Write a function to bootstrap the trimmed mean (removing top and bottom 10% before averaging). Compare its standard error to the regular mean for normal and heavy-tailed data.</p></li>
<li><p><strong>Correlation CI</strong>: Using the European Health and Wealth data from the chapter, compute bootstrap confidence intervals for <span class="math inline">\rho^2</span> (squared correlation). How do the three methods compare? What happens to the intervals when you transform from <span class="math inline">\rho</span> to <span class="math inline">\rho^2</span>?</p></li>
<li><p><strong>Ratio Statistics</strong>: Given paired data <span class="math inline">(X_i, Y_i)</span>, bootstrap the ratio <span class="math inline">\bar{Y}/\bar{X}</span>. Why might this be challenging? Compare the three CI methods.</p></li>
<li><p><strong>Bootstrap Failure - Range Statistic</strong>: Generate <span class="math inline">n=30</span> observations from a standard normal distribution and bootstrap the range (max - min). Compare the bootstrap distribution to the true sampling distribution (via simulation). Why does the bootstrap underestimate the variability? How does this relate to our discussion of extreme order statistics?</p></li>
</ol>
</section>
<section id="connections-to-source-material" class="level3" data-number="4.9.9">
<h3 data-number="4.9.9" class="anchored" data-anchor-id="connections-to-source-material"><span class="header-section-number">4.9.9</span> Connections to Source Material</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mapping to “All of Statistics”
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This table maps sections in these lecture notes to the corresponding sections in <span class="citation" data-cites="wasserman2013all">Wasserman (<a href="../references.html#ref-wasserman2013all" role="doc-biblioref">2013</a>)</span> (“All of Statistics” or AoS).</p>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Lecture Note Section</th>
<th style="text-align: left;">Corresponding AoS Section(s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Introduction and Motivation</strong></td>
<td style="text-align: left;">Expanded material from the slides, providing context for nonparametric estimation and the bootstrap.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Confidence Sets: The Foundation</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">↳ Definition and Interpretation of Confidence Intervals</td>
<td style="text-align: left;">AoS §6.3.2</td>
</tr>
<tr class="even">
<td style="text-align: left;">↳ Normal-Based Confidence Intervals</td>
<td style="text-align: left;">AoS §6.3.2 (Theorem 6.16)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>The Plug-In Principle: A General Method for Estimation</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">↳ The Empirical Distribution Function (EDF)</td>
<td style="text-align: left;">AoS §7.1 (Definition 7.1)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">↳ Properties of the EDF (Glivenko-Cantelli)</td>
<td style="text-align: left;">AoS §7.1 (Theorems 7.3, 7.4)</td>
</tr>
<tr class="even">
<td style="text-align: left;">↳ Confidence Bands for the CDF (DKW Inequality)</td>
<td style="text-align: left;">AoS §7.1 (Theorem 7.5)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">↳ The Plug-In Estimator for Statistical Functionals</td>
<td style="text-align: left;">AoS §7.2 (Definition 7.7)</td>
</tr>
<tr class="even">
<td style="text-align: left;">↳ Plug-in Examples (Mean, Variance, etc.)</td>
<td style="text-align: left;">AoS §7.2 (Examples 7.10, 7.11, etc.)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>The Bootstrap: Simulating Uncertainty</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">↳ The Core Idea and Bootstrap World</td>
<td style="text-align: left;">AoS §8 (Introduction), §8.2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">↳ Bootstrap Variance and Standard Error Estimation</td>
<td style="text-align: left;">AoS §8.2</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Bootstrap Confidence Intervals</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">↳ Three Common Methods (Normal, Percentile, Pivotal)</td>
<td style="text-align: left;">AoS §8.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">↳ Comparing Bootstrap CIs (Health and Wealth Example)</td>
<td style="text-align: left;">New example, applies concepts from AoS §8.3.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Bootstrap Application: Higher Moments</strong></td>
<td style="text-align: left;">New example from the slides.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>When The Bootstrap Fails</strong></td>
<td style="text-align: left;">New material, summarizing common failure modes. Examples inspired by AoS exercises (e.g., §8.6 Q7 for Uniform max).</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Chapter Summary and Connections</strong></td>
<td style="text-align: left;">New summary material.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="python-and-r-reference" class="level3" data-number="4.9.10">
<h3 data-number="4.9.10" class="anchored" data-anchor-id="python-and-r-reference"><span class="header-section-number">4.9.10</span> Python and R Reference</h3>
<div class="tabset-margin-container"></div><div class="tabset-margin-container"></div><div class="panel-tabset"><ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1757255598-765-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1757255598-765-1" role="tab" aria-controls="tabset-1757255598-765-1" aria-selected="true" href="">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1757255598-765-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1757255598-765-2" role="tab" aria-controls="tabset-1757255598-765-2" aria-selected="false" href="">R</a></li></ul><div class="tab-content"><div id="tabset-1757255598-765-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1757255598-765-1-tab"><div id="53d4355a" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Essential bootstrap code template</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bootstrap(data, statistic, B<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.05</span>):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Generic bootstrap function for any statistic.</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - point_estimate: Original statistic value</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    - se: Bootstrap standard error  </span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">    - ci_normal: Normal-based CI</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">    - ci_percentile: Percentile CI</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">    - ci_pivotal: Pivotal CI</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">    - boot_dist: Bootstrap distribution</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    boot_samples <span class="op">=</span> np.zeros(B)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original estimate</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    point_estimate <span class="op">=</span> statistic(data)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bootstrap</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        boot_data <span class="op">=</span> np.random.choice(data, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        boot_samples[b] <span class="op">=</span> statistic(boot_data)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Standard error</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> np.std(boot_samples, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Confidence intervals</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> stats.norm.ppf(<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    ci_normal <span class="op">=</span> (point_estimate <span class="op">-</span> z<span class="op">*</span>se, point_estimate <span class="op">+</span> z<span class="op">*</span>se)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    ci_percentile <span class="op">=</span> (np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>alpha<span class="op">/</span><span class="dv">2</span>),</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>                     np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>)))</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    ci_pivotal <span class="op">=</span> (<span class="dv">2</span><span class="op">*</span>point_estimate <span class="op">-</span> np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>)),</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>                  <span class="dv">2</span><span class="op">*</span>point_estimate <span class="op">-</span> np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="st">'estimate'</span>: point_estimate,</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">'se'</span>: se,</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ci_normal'</span>: ci_normal,</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ci_percentile'</span>: ci_percentile,</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ci_pivotal'</span>: ci_pivotal,</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">'boot_dist'</span>: boot_samples</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.exponential(<span class="dv">2</span>, <span class="dv">50</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> bootstrap(data, np.median, B<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Median: </span><span class="sc">{</span>results[<span class="st">'estimate'</span>]<span class="sc">:.3f}</span><span class="ss"> (SE: </span><span class="sc">{</span>results[<span class="st">'se'</span>]<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Percentile CI: </span><span class="sc">{</span>results[<span class="st">'ci_percentile'</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div><div id="tabset-1757255598-765-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1757255598-765-2-tab"><div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Essential bootstrap code template</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>bootstrap <span class="ot">&lt;-</span> <span class="cf">function</span>(data, statistic, <span class="at">B =</span> <span class="dv">1000</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>) {</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  boot_samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Original estimate</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  point_estimate <span class="ot">&lt;-</span> <span class="fu">statistic</span>(data)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Bootstrap</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    boot_data <span class="ot">&lt;-</span> <span class="fu">sample</span>(data, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    boot_samples[b] <span class="ot">&lt;-</span> <span class="fu">statistic</span>(boot_data)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Standard error</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  se <span class="ot">&lt;-</span> <span class="fu">sd</span>(boot_samples)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Confidence intervals</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  z <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  ci_normal <span class="ot">&lt;-</span> <span class="fu">c</span>(point_estimate <span class="sc">-</span> z<span class="sc">*</span>se, point_estimate <span class="sc">+</span> z<span class="sc">*</span>se)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  ci_percentile <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_samples, <span class="fu">c</span>(alpha<span class="sc">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  ci_pivotal <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span><span class="sc">*</span>point_estimate <span class="sc">-</span> <span class="fu">quantile</span>(boot_samples, <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>),</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                  <span class="dv">2</span><span class="sc">*</span>point_estimate <span class="sc">-</span> <span class="fu">quantile</span>(boot_samples, alpha<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">estimate =</span> point_estimate,</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">se =</span> se,</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_normal =</span> ci_normal,</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_percentile =</span> ci_percentile,</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_pivotal =</span> ci_pivotal,</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">boot_dist =</span> boot_samples</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">bootstrap</span>(data, median, <span class="at">B =</span> <span class="dv">2000</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Median: %.3f (SE: %.3f)</span><span class="sc">\n</span><span class="st">"</span>, results<span class="sc">$</span>estimate, results<span class="sc">$</span>se))</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"95%% Percentile CI: (%.3f, %.3f)</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            results<span class="sc">$</span>ci_percentile[<span class="dv">1</span>], results<span class="sc">$</span>ci_percentile[<span class="dv">2</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></div></div></div>
<hr>
<p><em>Remember: The bootstrap transforms the abstract problem of understanding sampling distributions into the concrete task of resampling from your data. It’s statistics made tangible through computation. When in doubt, bootstrap it!</em></p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-wasserman2013all" class="csl-entry" role="listitem">
Wasserman, Larry. 2013. <em>All of Statistics: A Concise Course in Statistical Inference</em>. Springer Science &amp; Business Media.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/03-convergence-inference.html" class="pagination-link" aria-label="Convergence and The Basics of Inference">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Convergence and The Basics of Inference</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/05-parametric-inference-I.html" class="pagination-link" aria-label="Parametric Inference I: Finding Estimators">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Parametric Inference I: Finding Estimators</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> today</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="fu"># Nonparametric Estimation and The Bootstrap</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## Learning Objectives</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>After completing this chapter, you will be able to:</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Explain the definition and frequentist interpretation of a confidence interval</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Apply the plug-in principle with the Empirical Distribution Function (EDF) to estimate statistical functionals</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use the bootstrap to simulate the sampling distribution of a statistic and estimate its standard error</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Construct and compare the three main types of bootstrap confidence intervals: Normal, percentile, and pivotal</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Identify the assumptions and limitations of the bootstrap, recognizing common situations where it can fail</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>This chapter covers nonparametric estimation methods and the bootstrap. The material is adapted from Chapters 7 and 8 of @wasserman2013all, with reference to Chapter 6 for confidence intervals. Additional examples and computational perspectives have been added for data science applications.</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction and Motivation</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="fu">### Beyond Point Estimates: Quantifying Uncertainty</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>Imagine you're a healthcare administrator planning for hospital capacity during an epidemic. Your data scientists provide a point estimate: "We expect 500 patients next week." But is this estimate reliable enough to base critical decisions on? What if the true number could reasonably be anywhere from 300 to 700? A single point estimate, without quantifying its uncertainty, is often useless for decision-making. You need a plausible *range* -- this is called a **confidence interval**.</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>In Chapter 3, we learned how to create point estimates -- single "best guesses" for unknown quantities. We saw that the sample mean $\bar{X}_n$ estimates the population mean $\mu$, and we even derived its standard error. But what about more complex statistics? How do we find the standard error of the median? The correlation coefficient? The 90th percentile?</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>Traditional statistical theory provides formulas for simple cases, but quickly becomes intractable for complex statistics. This chapter introduces two powerful ideas that revolutionized modern statistics:</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**The Plug-In Principle**: A simple, intuitive method for estimating almost any quantity by "plugging in" the empirical distribution for the true distribution.</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**The Bootstrap**: A computational method for estimating the standard error and confidence interval of virtually any statistic, even when no formula exists.</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>These methods exemplify the computational approach to statistics that has become dominant in the era of cheap computing power. Instead of deriving complex mathematical formulas, we let the computer simulate what would happen if we could repeat our experiment many times.</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## Finnish Terminology Reference</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>For Finnish-speaking students, here's a reference table of key terms in this chapter:</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>| English | Finnish | Context |</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>|---------|---------|---------|</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>| Confidence interval | Luottamusväli | Range that contains parameter with specified probability |</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>| Coverage | Peitto | Probability that interval contains true parameter |</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>| Empirical distribution function | Empiirinen kertymäfunktio | Data-based estimate of CDF |</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>| Statistical functional | Tilastollinen funktionaali | Function of the distribution |</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>| Plug-in estimator | Pistoke-estimaattori | Estimate using empirical distribution |</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>| Bootstrap | Uusio-otanta | Resampling method for uncertainty |</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>| Resampling | Uudelleenotanta | Drawing samples from data |</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>| Bootstrap sample | Bootstrap-otos | Sample drawn with replacement |</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>| Percentile interval | Prosenttipiste-luottamusväli | CI using bootstrap quantiles |</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>| Pivotal interval | Pivotaalinen luottamusväli | CI using pivot quantity |</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>| Standard error | Keskivirhe | Standard deviation of estimator |</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>| Monte Carlo error | Monte Carlo -virhe | Error from finite simulations |</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a><span class="fu">## Confidence Sets: The Foundation</span></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>Before diving into nonparametric estimation and the bootstrap, we need to establish the formal framework for confidence intervals, a staple of classical statistics.</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>::: {.definition}</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>A **$1-\alpha$ confidence interval** for a parameter $\theta$ is an interval $C_n = (a, b)$ where $a = a(X_1, \ldots, X_n)$ and $b = b(X_1, \ldots, X_n)$ are functions of the data such that</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}_{\theta}(\theta \in C_n) \geq 1 - \alpha, \quad \text{for all } \theta \in \Theta.$$</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>In other words, $C_n$ encloses $\theta$ with probability $1-\alpha$. This probability is called the **coverage** of the interval.</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>A common choice is $\alpha = 0.05$ which yields $95\%$ confidence intervals.</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpretation of Confidence Sets</span></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>Confidence intervals are not probability statements about $\theta$. The parameter $\theta$ is fixed; it's the interval $C_n$ that varies with different samples.</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>The correct interpretation is: if you repeatedly collect data and construct confidence intervals using the same procedure, $(1-\alpha) \times 100\%$ of those intervals will contain the true parameter. This is the *frequentist* guarantee.</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>Bayesian credible intervals provide a different type of statement -- they give a probability that $\theta$ lies in the interval given your observed data. However, Bayesian intervals are not guaranteed to achieve frequentist coverage (containing the true parameter $(1-\alpha)$ proportion of the time across repeated sampling).</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a><span class="fu">## Critical Point: What is Random?</span></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>Remember that $\theta$ is **fixed** and $C_n$ is **random**. The parameter doesn't change; the interval does. Each time we collect new data, we get a different interval. The guarantee is that $(1-\alpha) \times 100\%$ of these intervals will contain the true parameter.</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a><span class="fu">## Advanced: When Coverage Fails</span></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>The frequentist guarantee is an average over all possible datasets. For any specific confidence interval procedure, there may exist parameter values where the actual coverage is less than the nominal $(1-\alpha)$ level. </span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>Additionally, for some "unlucky" datasets (the $\alpha$ proportion), the computed interval may be far from the true parameter. This is an inherent limitation of the frequentist approach -- it provides no guarantees for individual intervals, only for the long-run performance of the procedure.</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>This suggests different approaches may be preferred in different contexts:</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Frequentist methods:** Well-suited for repeated analyses where long-run guarantees matter</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Bayesian methods:** May be preferred when prior information is available and you need probabilistic statements about parameters given your specific data</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>Both approaches are valuable tools for quantifying uncertainty.</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a><span class="fu">### Normal-Based Confidence Intervals</span></span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>When an estimator $\hat{\theta}_n$ is approximately normally distributed, we can form confidence intervals using the normal approximation. This is often the case for large samples due to the Central Limit Theorem.</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>Suppose $\hat{\theta}_n \approx \mathcal{N}(\theta, \widehat{\text{se}}^2)$, where $\widehat{\text{se}}$ is the (estimated) standard error of the estimator. Then we can standardize to get:</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>$$\frac{\hat{\theta}_n - \theta}{\widehat{\text{se}}} \approx \mathcal{N}(0, 1)$$</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>Let $z_{\alpha/2} = \Phi^{-1}(1 - \alpha/2)$ be the upper $\alpha/2$ quantile of the standard normal distribution, where $\Phi$ is the standard normal CDF. This means:</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\mathbb{P}(Z &gt; z_{\alpha/2}) = \alpha/2$ for $Z \sim \mathcal{N}(0, 1)$</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\mathbb{P}(-z_{\alpha/2} &lt; Z &lt; z_{\alpha/2}) = 1 - \alpha$</span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>Therefore:</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}\left(-z_{\alpha/2} &lt; \frac{\hat{\theta}_n - \theta}{\widehat{\text{se}}} &lt; z_{\alpha/2}\right) \approx 1 - \alpha$$</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>Rearranging to isolate $\theta$:</span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}\left(\hat{\theta}_n - z_{\alpha/2} \widehat{\text{se}} &lt; \theta &lt; \hat{\theta}_n + z_{\alpha/2} \widehat{\text{se}}\right) \approx 1 - \alpha$$</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>This gives us the approximate $(1-\alpha)$ confidence interval:</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>$$C_n = \left(\hat{\theta}_n - z_{\alpha/2} \widehat{\text{se}}, \hat{\theta}_n + z_{\alpha/2} \widehat{\text{se}}\right)$$</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>For the common case of 95% confidence intervals ($\alpha = 0.05$):</span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$z_{0.025} = \Phi^{-1}(0.975) \approx 1.96 \approx 2$</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This leads to the familiar rule of thumb: $\hat{\theta}_n \pm 2 \widehat{\text{se}}$</span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip icon=false}</span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example: Confidence Interval for the Mean</span></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a>For the sample mean $\bar{X}_n$ with known population variance $\sigma^2$:</span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Estimator: $\hat{\theta}_n = \bar{X}_n$</span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Standard error: $\text{se} = \sigma/\sqrt{n}$</span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>95% CI: $\bar{X}_n \pm 1.96 \cdot \sigma/\sqrt{n}$</span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a>If $\sigma$ is unknown, we substitute the sample standard deviation $s$ to get:</span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>95% CI: $\bar{X}_n \pm 1.96 \cdot s/\sqrt{n}$</span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a>For small samples, we would use the <span class="co">[</span><span class="ot">$t$-distribution</span><span class="co">](https://en.wikipedia.org/wiki/Student%27s_t-distribution)</span> instead of the normal distribution.</span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Plug-In Principle: A General Method for Estimation</span></span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a>This lecture focuses on **nonparametric estimation**, and the plug-in principle is one key instrument of nonparametric statistics.</span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimating the Entire Distribution: The EDF</span></span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>The plug-in principle is a simple idea that provides a unified framework for nonparametric estimation that works for virtually any statistical problem.</span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a>**The Core Idea**: When we need to estimate some property of an unknown distribution $F$, we simply:</span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Estimate the distribution itself using our data</span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculate the property using our estimated distribution</span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>The most fundamental nonparametric estimate is of the CDF itself. Let $X_1, \ldots, X_n \sim F$ be an i.i.d. sample where $F$ is a distribution function on the real line. Since we don't know the true CDF $F$, we estimate it with the **Empirical Distribution Function (EDF)**.</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a>::: {.definition}</span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a>The **Empirical Distribution Function (EDF)** $\hat{F}_n$ is the CDF that puts probability mass $1/n$ on each data point. Formally:</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a>$$\hat{F}_n(x) = \frac{1}{n}\sum_{i=1}^n I(X_i \leq x)$$</span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>where $I(X_i \leq x) = \begin{cases}</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a>1 &amp; \text{if } X_i \leq x <span class="sc">\\</span></span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a>0 &amp; \text{if } X_i &gt; x</span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a>\end{cases}$</span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a>Intuitively, $\hat{F}_n(x)$ is simply the proportion of data points less than or equal to $x$. It's the most natural estimate of $F(x) = \mathbb{P}(X \leq x)$.</span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>**Properties of the EDF**:</span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a>For any fixed point $x$:</span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Unbiased**: $\mathbb{E}(\hat{F}_n(x)) = F(x)$</span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Variance**: $\mathbb{V}(\hat{F}_n(x)) = \frac{F(x)(1-F(x))}{n}$</span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MSE**: $\text{MSE}(\hat{F}_n(x)) = \mathbb{V}(\hat{F}_n(x)) = \frac{F(x)(1-F(x))}{n} \to 0$ as $n \to \infty$</span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Consistent**: $\hat{F}_n(x) \xrightarrow{P} F(x)$ as $n \to \infty$</span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a>But the EDF is even better than these pointwise properties suggest:</span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a>::: {.theorem name="Glivenko-Cantelli Theorem"}</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a>The EDF converges to the true CDF *uniformly*:</span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a>$$\sup_x |\hat{F}_n(x) - F(x)| \xrightarrow{P} 0$$</span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a>This is a remarkably strong guarantee -- the EDF approximates the true CDF well *everywhere*, not just at individual points.</span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a>Let's visualize the EDF with an example dataset:</span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate nerve data (waiting times between pulses)</span></span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a><span class="co"># Using exponential distribution as a model for waiting times</span></span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a>nerve_data <span class="op">=</span> np.random.exponential(scale<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span>n)</span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the EDF plot</span></span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort data for plotting</span></span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a>sorted_data <span class="op">=</span> np.sort(nerve_data)</span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the EDF as a step function</span></span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a>ax.step(sorted_data, np.arange(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>n, where<span class="op">=</span><span class="st">'post'</span>, </span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Empirical CDF'</span>)</span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a><span class="co"># Add rug plot to show data points</span></span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a>ax.plot(sorted_data, np.zeros_like(sorted_data), <span class="st">'|'</span>, </span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">'black'</span>, markersize<span class="op">=</span><span class="dv">10</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a><span class="co"># Add true CDF for comparison</span></span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a>x_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="bu">max</span>(sorted_data)<span class="op">*</span><span class="fl">1.1</span>, <span class="dv">1000</span>)</span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a>true_cdf <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> np.exp(<span class="op">-</span>x_range<span class="op">/</span><span class="fl">0.5</span>)  <span class="co"># Exponential CDF</span></span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a>ax.plot(x_range, true_cdf, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'True CDF'</span>)</span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Waiting time (seconds)'</span>)</span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Cumulative probability'</span>)</span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Empirical Distribution Function for Nerve Pulse Data (Simulated)'</span>)</span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">0</span>, <span class="bu">max</span>(sorted_data)<span class="op">*</span><span class="fl">1.05</span>)</span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="fl">1.05</span>)</span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-234"><a href="#cb18-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-235"><a href="#cb18-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a>The step function shows $\hat{F}_n$, jumping by $1/n$ at each data point. The vertical lines at the bottom show the actual data points. Notice how the EDF closely follows the true CDF (shown for comparison).</span>
<span id="cb18-237"><a href="#cb18-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a><span class="fu">## Advanced: Confidence Bands for the CDF</span></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a>We can construct confidence bands for the entire CDF using the <span class="co">[</span><span class="ot">Dvoretzky-Kiefer-Wolfowitz (DKW) inequality</span><span class="co">](https://en.wikipedia.org/wiki/Dvoretzky%E2%80%93Kiefer%E2%80%93Wolfowitz_inequality)</span>:</span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}\left(\sup_x |F(x) - \hat{F}_n(x)| &gt; \epsilon\right) \leq 2e^{-2n\epsilon^2}$$</span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a>This leads to a $1-\alpha$ confidence band:</span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a>$$L(x) = \max<span class="sc">\{</span>\hat{F}_n(x) - \epsilon_n, 0<span class="sc">\}</span>$$</span>
<span id="cb18-247"><a href="#cb18-247" aria-hidden="true" tabindex="-1"></a>$$U(x) = \min<span class="sc">\{</span>\hat{F}_n(x) + \epsilon_n, 1<span class="sc">\}</span>$$</span>
<span id="cb18-248"><a href="#cb18-248" aria-hidden="true" tabindex="-1"></a>where $\epsilon_n = \sqrt{\frac{1}{2n}\log\left(\frac{2}{\alpha}\right)}$.</span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a><span class="co"># Add confidence bands to previous plot</span></span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a>epsilon_n <span class="op">=</span> np.sqrt(np.log(<span class="dv">2</span><span class="op">/</span>alpha) <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>n))</span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot EDF</span></span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a>ax.step(sorted_data, np.arange(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>n, where<span class="op">=</span><span class="st">'post'</span>, </span>
<span id="cb18-263"><a href="#cb18-263" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Empirical CDF'</span>)</span>
<span id="cb18-264"><a href="#cb18-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a><span class="co"># Add confidence bands</span></span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a>y_values <span class="op">=</span> np.arange(<span class="dv">1</span>, n<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>n</span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a>lower_band <span class="op">=</span> np.maximum(y_values <span class="op">-</span> epsilon_n, <span class="dv">0</span>)</span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a>upper_band <span class="op">=</span> np.minimum(y_values <span class="op">+</span> epsilon_n, <span class="dv">1</span>)</span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a>ax.fill_between(sorted_data, lower_band, upper_band, </span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a>                step<span class="op">=</span><span class="st">'post'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'gray'</span>, </span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span><span class="bu">int</span>((<span class="dv">1</span><span class="op">-</span>alpha)<span class="op">*</span><span class="dv">100</span>)<span class="sc">}</span><span class="ss">% Confidence band'</span>)</span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a><span class="co"># Add rug plot</span></span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a>ax.plot(sorted_data, np.zeros_like(sorted_data), <span class="st">'|'</span>, </span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">'black'</span>, markersize<span class="op">=</span><span class="dv">10</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-277"><a href="#cb18-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-278"><a href="#cb18-278" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Waiting time (seconds)'</span>)</span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Cumulative probability'</span>)</span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'EDF with Confidence Band'</span>)</span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">0</span>, <span class="bu">max</span>(sorted_data)<span class="op">*</span><span class="fl">1.05</span>)</span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="fl">1.05</span>)</span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Width of confidence band: ±</span><span class="sc">{</span>epsilon_n<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"This means we're 95% confident the true CDF lies within this gray region"</span>)</span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimating Functionals: The Plug-In Estimator</span></span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a>Now that we can estimate the entire distribution, we can estimate any property of it. A **statistical functional** is any function of the CDF $F$ or the PDF $f$.</span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a>Examples include:</span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The mean: $\mu = \int x f(x) d x$</span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The variance: $\sigma^2 = \int (x-\mu)^2 f(x) d x$  </span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The median: $m = F^{-1}(1/2)$</span>
<span id="cb18-303"><a href="#cb18-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-304"><a href="#cb18-304" aria-hidden="true" tabindex="-1"></a>::: {.definition}</span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a>The **plug-in estimator** of $\theta = T(F)$ is defined by:</span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a>$$\hat{\theta}_n = T(\hat{F}_n)$$</span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a>In other words, just *plug in* the empirical CDF $\hat{F}_n$ for the unknown CDF $F$.</span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a>This principle is remarkably general. To estimate any property of the population, we calculate that same property on our empirical distribution. Let's see how this works for various functionals:</span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a>**The Mean**:</span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a>Let $\mu = T(F) = \int x f(x) dx$.</span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a>The plug-in estimator is:</span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a>$$\hat{\mu}_n = \sum x \hat{f}_n(x) = \frac{1}{n}\sum_{i=1}^n X_i = \bar{X}_n$$</span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a>The plug-in estimator for the mean is just the sample mean!</span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a>**The Variance**:</span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a>Let $\sigma^2 = T(F) = \mathbb{V}(X) = \int x^2 f(x) d x - \left(\int x f(x) d x\right)^2$.</span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a>The plug-in estimator is:</span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a>\hat{\sigma}^2_n &amp;= \sum_x x^2 \hat{f}_n(x) - \left(\sum_x x \hat{f}_n(x)\right)^2 <span class="sc">\\</span></span>
<span id="cb18-329"><a href="#cb18-329" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{1}{n}\sum_{i=1}^n X_i^2 - \left(\frac{1}{n}\sum_{i=1}^n X_i\right)^2 <span class="sc">\\</span></span>
<span id="cb18-330"><a href="#cb18-330" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{1}{n}\sum_{i=1}^n (X_i - \bar{X}_n)^2</span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a><span class="fu">## Alternative: The Sample Variance</span></span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a>Another common estimator of $\sigma^2$ is the sample variance with the $n-1$ correction:</span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a>$$S_n^2 = \frac{1}{n-1}\sum_{i=1}^n(X_i - \bar{X}_n)^2$$</span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a>This estimator is unbiased (i.e., $\mathbb{E}<span class="co">[</span><span class="ot">S_n^2</span><span class="co">]</span> = \sigma^2$) and is almost identical to the plug-in estimator in practice. The factor $\frac{n}{n-1}$ makes little difference for moderate to large samples. Most statistical software uses the $n-1$ version by default.</span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-341"><a href="#cb18-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-342"><a href="#cb18-342" aria-hidden="true" tabindex="-1"></a>**The Median**:</span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a>The median is the value that splits the distribution in half. For the theoretical distribution:</span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a>$$m = T(F) = F^{-1}(0.5)$$</span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a>The plug-in estimator is simply the sample median - the middle value when we sort our data. For an odd number of observations, it's the middle value. For an even number, it's the average of the two middle values.</span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a><span class="fu">## Advanced: Other Statistical Functionals</span></span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a>**Skewness** (measures asymmetry):</span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a>$$T(F) = \frac{\mathbb{E}<span class="co">[</span><span class="ot">(X-\mu)^3</span><span class="co">]</span>}{\sigma^3} \implies \hat{\kappa}_n = \frac{\frac{1}{n}\sum_{i=1}^n(X_i-\bar{X}_n)^3}{(\hat{\sigma}^2_n)^{3/2}}$$</span>
<span id="cb18-354"><a href="#cb18-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-355"><a href="#cb18-355" aria-hidden="true" tabindex="-1"></a>**Correlation** for bivariate data $(X,Y)$:</span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a>$$T(F) = \frac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y} \implies \hat{\rho}_n = \frac{\frac{1}{n}\sum_{i=1}^n(X_i-\bar{X}_n)(Y_i-\bar{Y}_n)}{\sqrt{\frac{1}{n}\sum_{i=1}^n(X_i-\bar{X}_n)^2}\sqrt{\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y}_n)^2}}$$</span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a>**Quantiles** in general:</span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a>$$T(F) = F^{-1}(p) \implies \hat{q}_p = \hat{F}_n^{-1}(p)$$</span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a>Since $\hat{F}_n$ is a step function, we define:</span>
<span id="cb18-362"><a href="#cb18-362" aria-hidden="true" tabindex="-1"></a>$$\hat{F}_n^{-1}(p) = \inf<span class="sc">\{</span>x : \hat{F}_n(x) \geq p<span class="sc">\}</span>$$</span>
<span id="cb18-363"><a href="#cb18-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a>This gives us the sample quantile at level $p$.</span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-366"><a href="#cb18-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-367"><a href="#cb18-367" aria-hidden="true" tabindex="-1"></a>**Confidence Intervals for Plug-in Estimators**:</span>
<span id="cb18-368"><a href="#cb18-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-369"><a href="#cb18-369" aria-hidden="true" tabindex="-1"></a>When the plug-in estimator $\hat{\theta}_n = T(\hat{F}_n)$ is approximately normally distributed, we can form confidence intervals using:</span>
<span id="cb18-370"><a href="#cb18-370" aria-hidden="true" tabindex="-1"></a>$$\hat{\theta}_n \pm z_{\alpha/2} \widehat{\text{se}}$$</span>
<span id="cb18-371"><a href="#cb18-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-372"><a href="#cb18-372" aria-hidden="true" tabindex="-1"></a>as we saw earlier in the *Normal-Based Confidence Intervals* section.</span>
<span id="cb18-373"><a href="#cb18-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-374"><a href="#cb18-374" aria-hidden="true" tabindex="-1"></a>The challenge is finding $\widehat{\text{se}}$. For the mean, we know from theory that $\text{se}(\bar{X}_n) = \sigma/\sqrt{n}$, which we can estimate by plugging in $\hat{\sigma}$ to get:</span>
<span id="cb18-375"><a href="#cb18-375" aria-hidden="true" tabindex="-1"></a>$$\bar{X}_n \pm z_{\alpha/2} \frac{\hat{\sigma}}{\sqrt{n}}$$</span>
<span id="cb18-376"><a href="#cb18-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-377"><a href="#cb18-377" aria-hidden="true" tabindex="-1"></a>But what about the median? The 90th percentile? The interquartile range? For most functionals, **there is no simple formula for the standard error**.</span>
<span id="cb18-378"><a href="#cb18-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-379"><a href="#cb18-379" aria-hidden="true" tabindex="-1"></a>This is where the bootstrap comes to the rescue, as we see next.</span>
<span id="cb18-380"><a href="#cb18-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-381"><a href="#cb18-381" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb18-382"><a href="#cb18-382" aria-hidden="true" tabindex="-1"></a><span class="fu">## Recap: Nonparametric Estimation</span></span>
<span id="cb18-383"><a href="#cb18-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-384"><a href="#cb18-384" aria-hidden="true" tabindex="-1"></a>Let $X_1, \ldots, X_n \sim F$ be an i.i.d. sample where $F$ is a distribution function on the real line.</span>
<span id="cb18-385"><a href="#cb18-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-386"><a href="#cb18-386" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **empirical distribution function** $\hat{F}_n$ is the CDF that puts mass $1/n$ at each data point $X_i$</span>
<span id="cb18-387"><a href="#cb18-387" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A **statistical functional** $T(F)$ is any function of $F$ (e.g., mean, variance, median)</span>
<span id="cb18-388"><a href="#cb18-388" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **plug-in estimator** of $\theta = T(F)$ is $\hat{\theta}_n = T(\hat{F}_n)$</span>
<span id="cb18-389"><a href="#cb18-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-390"><a href="#cb18-390" aria-hidden="true" tabindex="-1"></a>We've seen how to create point estimates for any functional. The challenge is quantifying their uncertainty when no formula exists for the standard error.</span>
<span id="cb18-391"><a href="#cb18-391" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-392"><a href="#cb18-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-393"><a href="#cb18-393" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Bootstrap: Simulating Uncertainty</span></span>
<span id="cb18-394"><a href="#cb18-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-395"><a href="#cb18-395" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Core Idea</span></span>
<span id="cb18-396"><a href="#cb18-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-397"><a href="#cb18-397" aria-hidden="true" tabindex="-1"></a>The bootstrap, invented by Bradley Efron in 1979, is one of the most important statistical innovations of the 20th century. It provides a general, computational method for assessing the uncertainty of virtually any statistic or functional of the data.</span>
<span id="cb18-398"><a href="#cb18-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-399"><a href="#cb18-399" aria-hidden="true" tabindex="-1"></a>Let $T_n = g(X_1, \ldots, X_n)$ be our statistic of interest (e.g., the median, the variance, a given quantile). What's its variability?</span>
<span id="cb18-400"><a href="#cb18-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-401"><a href="#cb18-401" aria-hidden="true" tabindex="-1"></a>The key insight is simple: **We can learn about the variability of our statistic by seeing how it varies across different samples. Since we only have one sample, we create new samples by resampling from our data.**</span>
<span id="cb18-402"><a href="#cb18-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-403"><a href="#cb18-403" aria-hidden="true" tabindex="-1"></a>Here's the crucial diagram that illustrates the bootstrap principle:</span>
<span id="cb18-404"><a href="#cb18-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-405"><a href="#cb18-405" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-406"><a href="#cb18-406" aria-hidden="true" tabindex="-1"></a><span class="in">Real World:      F   ==&gt;   X₁,...,Xₙ   ==&gt;   Tₙ = g(X)</span></span>
<span id="cb18-407"><a href="#cb18-407" aria-hidden="true" tabindex="-1"></a><span class="in">                 ↑                            ↑</span></span>
<span id="cb18-408"><a href="#cb18-408" aria-hidden="true" tabindex="-1"></a><span class="in">                 Unknown                      What we want to understand</span></span>
<span id="cb18-409"><a href="#cb18-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-410"><a href="#cb18-410" aria-hidden="true" tabindex="-1"></a><span class="in">Bootstrap World: F̂ₙ  ==&gt;   X₁*,...,Xₙ*  ==&gt;  Tₙ* = g(X*)</span></span>
<span id="cb18-411"><a href="#cb18-411" aria-hidden="true" tabindex="-1"></a><span class="in">                 ↑                            ↑</span></span>
<span id="cb18-412"><a href="#cb18-412" aria-hidden="true" tabindex="-1"></a><span class="in">                 Known!                       What we can simulate</span></span>
<span id="cb18-413"><a href="#cb18-413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-414"><a href="#cb18-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-415"><a href="#cb18-415" aria-hidden="true" tabindex="-1"></a>In the real world:</span>
<span id="cb18-416"><a href="#cb18-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-417"><a href="#cb18-417" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Nature draws from the unknown distribution $F$</span>
<span id="cb18-418"><a href="#cb18-418" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We observe one sample $X_1, \ldots, X_n$</span>
<span id="cb18-419"><a href="#cb18-419" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We calculate our statistic $T_n = g(X_1, \ldots, X_n)$</span>
<span id="cb18-420"><a href="#cb18-420" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We want to know the sampling distribution of $T_n$</span>
<span id="cb18-421"><a href="#cb18-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-422"><a href="#cb18-422" aria-hidden="true" tabindex="-1"></a>In the bootstrap world:</span>
<span id="cb18-423"><a href="#cb18-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-424"><a href="#cb18-424" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We draw from the known empirical distribution $\hat{F}_n$ (see below)</span>
<span id="cb18-425"><a href="#cb18-425" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We get a bootstrap sample $X_1^*, \ldots, X_n^*$</span>
<span id="cb18-426"><a href="#cb18-426" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We calculate the bootstrap statistic $T_n^* = g(X_1^*, \ldots, X_n^*)$</span>
<span id="cb18-427"><a href="#cb18-427" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**We can repeat the process multiple times to simulate the sampling distribution of $T_n^*$**</span>
<span id="cb18-428"><a href="#cb18-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-429"><a href="#cb18-429" aria-hidden="true" tabindex="-1"></a>**The Bootstrap Principle**: The distribution of $T_n^*$ around $T_n$ approximates the distribution of $T_n$ around $T(F)$.</span>
<span id="cb18-430"><a href="#cb18-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-431"><a href="#cb18-431" aria-hidden="true" tabindex="-1"></a>How do we draw from $\hat{F}_n$? Remember that $\hat{F}_n$ puts mass $1/n$ at each observed data point. Therefore:</span>
<span id="cb18-432"><a href="#cb18-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-433"><a href="#cb18-433" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb18-434"><a href="#cb18-434" aria-hidden="true" tabindex="-1"></a>**Key Point**: Drawing from $\hat{F}_n$ means sampling **with replacement** from the original data. Each bootstrap sample contains $n$ observations, some repeated, some omitted.</span>
<span id="cb18-435"><a href="#cb18-435" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-436"><a href="#cb18-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-437"><a href="#cb18-437" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bootstrap Variance and Standard Error Estimation</span></span>
<span id="cb18-438"><a href="#cb18-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-439"><a href="#cb18-439" aria-hidden="true" tabindex="-1"></a>Let's make this concrete with an algorithm:</span>
<span id="cb18-440"><a href="#cb18-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-441"><a href="#cb18-441" aria-hidden="true" tabindex="-1"></a>**Bootstrap Algorithm for Standard Error Estimation**:</span>
<span id="cb18-442"><a href="#cb18-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-443"><a href="#cb18-443" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>For $b = 1, \ldots, B$:</span>
<span id="cb18-444"><a href="#cb18-444" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Draw a bootstrap sample $X_1^*, \ldots, X_n^*$ by sampling with replacement from $<span class="sc">\{</span>X_1, \ldots, X_n<span class="sc">\}</span>$</span>
<span id="cb18-445"><a href="#cb18-445" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Compute the statistic for this bootstrap sample: $T_{n,b}^* = g(X_1^*, \ldots, X_n^*)$</span>
<span id="cb18-446"><a href="#cb18-446" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The bootstrap estimate of the standard error is:</span>
<span id="cb18-447"><a href="#cb18-447" aria-hidden="true" tabindex="-1"></a>   $$\widehat{\text{se}}_{\text{boot}} = \sqrt{\frac{1}{B-1}\sum_{b=1}^B \left(T_{n,b}^* - \bar{T}_n^*\right)^2}$$</span>
<span id="cb18-448"><a href="#cb18-448" aria-hidden="true" tabindex="-1"></a>   where $\bar{T}_n^* = \frac{1}{B}\sum_{b=1}^B T_{n,b}^*$</span>
<span id="cb18-449"><a href="#cb18-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-450"><a href="#cb18-450" aria-hidden="true" tabindex="-1"></a>Let's implement this for a concrete example -- estimating the standard error of the median:</span>
<span id="cb18-451"><a href="#cb18-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-452"><a href="#cb18-452" aria-hidden="true" tabindex="-1"></a>::: {.tabbed-content}</span>
<span id="cb18-453"><a href="#cb18-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-454"><a href="#cb18-454" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb18-455"><a href="#cb18-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-458"><a href="#cb18-458" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-459"><a href="#cb18-459" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb18-460"><a href="#cb18-460" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-461"><a href="#cb18-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-462"><a href="#cb18-462" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bootstrap_se(data, statistic, B<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb18-463"><a href="#cb18-463" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-464"><a href="#cb18-464" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute bootstrap standard error of a statistic.</span></span>
<span id="cb18-465"><a href="#cb18-465" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb18-466"><a href="#cb18-466" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb18-467"><a href="#cb18-467" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb18-468"><a href="#cb18-468" aria-hidden="true" tabindex="-1"></a><span class="co">    data : array-like</span></span>
<span id="cb18-469"><a href="#cb18-469" aria-hidden="true" tabindex="-1"></a><span class="co">        Original sample</span></span>
<span id="cb18-470"><a href="#cb18-470" aria-hidden="true" tabindex="-1"></a><span class="co">    statistic : function</span></span>
<span id="cb18-471"><a href="#cb18-471" aria-hidden="true" tabindex="-1"></a><span class="co">        Function that computes the statistic of interest</span></span>
<span id="cb18-472"><a href="#cb18-472" aria-hidden="true" tabindex="-1"></a><span class="co">    B : int</span></span>
<span id="cb18-473"><a href="#cb18-473" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of bootstrap replications</span></span>
<span id="cb18-474"><a href="#cb18-474" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb18-475"><a href="#cb18-475" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb18-476"><a href="#cb18-476" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb18-477"><a href="#cb18-477" aria-hidden="true" tabindex="-1"></a><span class="co">    se : float</span></span>
<span id="cb18-478"><a href="#cb18-478" aria-hidden="true" tabindex="-1"></a><span class="co">        Bootstrap standard error</span></span>
<span id="cb18-479"><a href="#cb18-479" aria-hidden="true" tabindex="-1"></a><span class="co">    boot_samples : array</span></span>
<span id="cb18-480"><a href="#cb18-480" aria-hidden="true" tabindex="-1"></a><span class="co">        Bootstrap replications of the statistic</span></span>
<span id="cb18-481"><a href="#cb18-481" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-482"><a href="#cb18-482" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb18-483"><a href="#cb18-483" aria-hidden="true" tabindex="-1"></a>    boot_samples <span class="op">=</span> np.zeros(B)</span>
<span id="cb18-484"><a href="#cb18-484" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-485"><a href="#cb18-485" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb18-486"><a href="#cb18-486" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Draw bootstrap sample</span></span>
<span id="cb18-487"><a href="#cb18-487" aria-hidden="true" tabindex="-1"></a>        x_star <span class="op">=</span> np.random.choice(data, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-488"><a href="#cb18-488" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute statistic</span></span>
<span id="cb18-489"><a href="#cb18-489" aria-hidden="true" tabindex="-1"></a>        boot_samples[b] <span class="op">=</span> statistic(x_star)</span>
<span id="cb18-490"><a href="#cb18-490" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-491"><a href="#cb18-491" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute standard error</span></span>
<span id="cb18-492"><a href="#cb18-492" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> np.std(boot_samples, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-493"><a href="#cb18-493" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-494"><a href="#cb18-494" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> se, boot_samples</span>
<span id="cb18-495"><a href="#cb18-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-496"><a href="#cb18-496" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Standard error of the median</span></span>
<span id="cb18-497"><a href="#cb18-497" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-498"><a href="#cb18-498" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.exponential(scale<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb18-499"><a href="#cb18-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-500"><a href="#cb18-500" aria-hidden="true" tabindex="-1"></a><span class="co"># Point estimate</span></span>
<span id="cb18-501"><a href="#cb18-501" aria-hidden="true" tabindex="-1"></a>median_est <span class="op">=</span> np.median(data)</span>
<span id="cb18-502"><a href="#cb18-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-503"><a href="#cb18-503" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap standard error</span></span>
<span id="cb18-504"><a href="#cb18-504" aria-hidden="true" tabindex="-1"></a>se_boot, boot_medians <span class="op">=</span> bootstrap_se(data, np.median, B<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb18-505"><a href="#cb18-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-506"><a href="#cb18-506" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample median: </span><span class="sc">{</span>median_est<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-507"><a href="#cb18-507" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Bootstrap SE: </span><span class="sc">{</span>se_boot<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-508"><a href="#cb18-508" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Approximate 95% CI: (</span><span class="sc">{</span>median_est <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>se_boot<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>median_est <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>se_boot<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb18-509"><a href="#cb18-509" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-510"><a href="#cb18-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-511"><a href="#cb18-511" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb18-512"><a href="#cb18-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-513"><a href="#cb18-513" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb18-514"><a href="#cb18-514" aria-hidden="true" tabindex="-1"></a>bootstrap_se <span class="ot">&lt;-</span> <span class="cf">function</span>(data, statistic, <span class="at">B =</span> <span class="dv">1000</span>) {</span>
<span id="cb18-515"><a href="#cb18-515" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' Compute bootstrap standard error of a statistic</span></span>
<span id="cb18-516"><a href="#cb18-516" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' </span></span>
<span id="cb18-517"><a href="#cb18-517" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @param data Original sample vector</span></span>
<span id="cb18-518"><a href="#cb18-518" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @param statistic Function that computes the statistic of interest</span></span>
<span id="cb18-519"><a href="#cb18-519" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @param B Number of bootstrap replications</span></span>
<span id="cb18-520"><a href="#cb18-520" aria-hidden="true" tabindex="-1"></a>  <span class="co">#' @return List with standard error and bootstrap samples</span></span>
<span id="cb18-521"><a href="#cb18-521" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-522"><a href="#cb18-522" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb18-523"><a href="#cb18-523" aria-hidden="true" tabindex="-1"></a>  boot_samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb18-524"><a href="#cb18-524" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-525"><a href="#cb18-525" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb18-526"><a href="#cb18-526" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw bootstrap sample</span></span>
<span id="cb18-527"><a href="#cb18-527" aria-hidden="true" tabindex="-1"></a>    x_star <span class="ot">&lt;-</span> <span class="fu">sample</span>(data, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-528"><a href="#cb18-528" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute statistic</span></span>
<span id="cb18-529"><a href="#cb18-529" aria-hidden="true" tabindex="-1"></a>    boot_samples[b] <span class="ot">&lt;-</span> <span class="fu">statistic</span>(x_star)</span>
<span id="cb18-530"><a href="#cb18-530" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb18-531"><a href="#cb18-531" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-532"><a href="#cb18-532" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute standard error</span></span>
<span id="cb18-533"><a href="#cb18-533" aria-hidden="true" tabindex="-1"></a>  se <span class="ot">&lt;-</span> <span class="fu">sd</span>(boot_samples)</span>
<span id="cb18-534"><a href="#cb18-534" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-535"><a href="#cb18-535" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">se =</span> se, <span class="at">boot_samples =</span> boot_samples))</span>
<span id="cb18-536"><a href="#cb18-536" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-537"><a href="#cb18-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-538"><a href="#cb18-538" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Standard error of the median</span></span>
<span id="cb18-539"><a href="#cb18-539" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb18-540"><a href="#cb18-540" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb18-541"><a href="#cb18-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-542"><a href="#cb18-542" aria-hidden="true" tabindex="-1"></a><span class="co"># Point estimate</span></span>
<span id="cb18-543"><a href="#cb18-543" aria-hidden="true" tabindex="-1"></a>median_est <span class="ot">&lt;-</span> <span class="fu">median</span>(data)</span>
<span id="cb18-544"><a href="#cb18-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-545"><a href="#cb18-545" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap standard error</span></span>
<span id="cb18-546"><a href="#cb18-546" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">bootstrap_se</span>(data, median, <span class="at">B =</span> <span class="dv">2000</span>)</span>
<span id="cb18-547"><a href="#cb18-547" aria-hidden="true" tabindex="-1"></a>se_boot <span class="ot">&lt;-</span> result<span class="sc">$</span>se</span>
<span id="cb18-548"><a href="#cb18-548" aria-hidden="true" tabindex="-1"></a>boot_medians <span class="ot">&lt;-</span> result<span class="sc">$</span>boot_samples</span>
<span id="cb18-549"><a href="#cb18-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-550"><a href="#cb18-550" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Sample median: %.3f</span><span class="sc">\n</span><span class="st">"</span>, median_est))</span>
<span id="cb18-551"><a href="#cb18-551" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Bootstrap SE: %.3f</span><span class="sc">\n</span><span class="st">"</span>, se_boot))</span>
<span id="cb18-552"><a href="#cb18-552" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Approximate 95%% CI: (%.3f, %.3f)</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb18-553"><a href="#cb18-553" aria-hidden="true" tabindex="-1"></a>            median_est <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>se_boot, median_est <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>se_boot))</span>
<span id="cb18-554"><a href="#cb18-554" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-555"><a href="#cb18-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-556"><a href="#cb18-556" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-557"><a href="#cb18-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-558"><a href="#cb18-558" aria-hidden="true" tabindex="-1"></a>Let's visualize the bootstrap distribution:</span>
<span id="cb18-559"><a href="#cb18-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-562"><a href="#cb18-562" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-563"><a href="#cb18-563" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb18-564"><a href="#cb18-564" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb18-565"><a href="#cb18-565" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb18-566"><a href="#cb18-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-567"><a href="#cb18-567" aria-hidden="true" tabindex="-1"></a><span class="co"># Left panel: Original data</span></span>
<span id="cb18-568"><a href="#cb18-568" aria-hidden="true" tabindex="-1"></a>ax1.hist(data, bins<span class="op">=</span><span class="dv">20</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb18-569"><a href="#cb18-569" aria-hidden="true" tabindex="-1"></a>ax1.axvline(median_est, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'Median = </span><span class="sc">{</span>median_est<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb18-570"><a href="#cb18-570" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb18-571"><a href="#cb18-571" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-572"><a href="#cb18-572" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Original Data'</span>)</span>
<span id="cb18-573"><a href="#cb18-573" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb18-574"><a href="#cb18-574" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-575"><a href="#cb18-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-576"><a href="#cb18-576" aria-hidden="true" tabindex="-1"></a><span class="co"># Right panel: Bootstrap distribution</span></span>
<span id="cb18-577"><a href="#cb18-577" aria-hidden="true" tabindex="-1"></a>ax2.hist(boot_medians, bins<span class="op">=</span><span class="dv">30</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'green'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb18-578"><a href="#cb18-578" aria-hidden="true" tabindex="-1"></a>ax2.axvline(median_est, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb18-579"><a href="#cb18-579" aria-hidden="true" tabindex="-1"></a>ax2.axvline(median_est <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>se_boot, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb18-580"><a href="#cb18-580" aria-hidden="true" tabindex="-1"></a>ax2.axvline(median_est <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>se_boot, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-581"><a href="#cb18-581" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="st">'95% CI'</span>)</span>
<span id="cb18-582"><a href="#cb18-582" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Bootstrap median'</span>)</span>
<span id="cb18-583"><a href="#cb18-583" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-584"><a href="#cb18-584" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Bootstrap Distribution'</span>)</span>
<span id="cb18-585"><a href="#cb18-585" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb18-586"><a href="#cb18-586" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-587"><a href="#cb18-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-588"><a href="#cb18-588" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-589"><a href="#cb18-589" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-590"><a href="#cb18-590" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-591"><a href="#cb18-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-592"><a href="#cb18-592" aria-hidden="true" tabindex="-1"></a>The left panel shows our original data. The right panel shows the distribution of the median across 2000 bootstrap samples. This distribution tells us about the uncertainty in our median estimate.</span>
<span id="cb18-593"><a href="#cb18-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-594"><a href="#cb18-594" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb18-595"><a href="#cb18-595" aria-hidden="true" tabindex="-1"></a><span class="fu">## Two Sources of Error</span></span>
<span id="cb18-596"><a href="#cb18-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-597"><a href="#cb18-597" aria-hidden="true" tabindex="-1"></a>The bootstrap involves two approximations:</span>
<span id="cb18-598"><a href="#cb18-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-599"><a href="#cb18-599" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Statistical Approximation**: $\mathbb{V}_F(T_n) \approx \mathbb{V}_{\hat{F}_n}(T_n)$</span>
<span id="cb18-600"><a href="#cb18-600" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>This depends on how well $\hat{F}_n$ approximates $F$</span>
<span id="cb18-601"><a href="#cb18-601" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>We can't control this -- it depends on our sample size $n$</span>
<span id="cb18-602"><a href="#cb18-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-603"><a href="#cb18-603" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Monte Carlo Approximation**: $\mathbb{V}_{\hat{F}_n}(T_n) \approx v_{\text{boot}}$</span>
<span id="cb18-604"><a href="#cb18-604" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>This depends on the number of bootstrap samples $B$</span>
<span id="cb18-605"><a href="#cb18-605" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>We can make this arbitrarily small by increasing $B$</span>
<span id="cb18-606"><a href="#cb18-606" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Typically $B \geq 1000$ is sufficient</span>
<span id="cb18-607"><a href="#cb18-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-608"><a href="#cb18-608" aria-hidden="true" tabindex="-1"></a>In formulas: </span>
<span id="cb18-609"><a href="#cb18-609" aria-hidden="true" tabindex="-1"></a>$$\mathbb{V}_F(T_n) \underbrace{\approx}_{\text{not so small}} \mathbb{V}_{\hat{F}_n}(T_n) \underbrace{\approx}_{\text{small}} v_{\text{boot}}$$</span>
<span id="cb18-610"><a href="#cb18-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-611"><a href="#cb18-611" aria-hidden="true" tabindex="-1"></a>Remember: by increasing the bootstrap samples $B$ we can reduce the Monte Carlo error (due to simulation), but we cannot improve the statistical approximation error without obtaining more real data.</span>
<span id="cb18-612"><a href="#cb18-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-613"><a href="#cb18-613" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-614"><a href="#cb18-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-615"><a href="#cb18-615" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb18-616"><a href="#cb18-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-617"><a href="#cb18-617" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example: Monte Carlo Error Decreases With More Bootstrap Samples</span></span>
<span id="cb18-618"><a href="#cb18-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-619"><a href="#cb18-619" aria-hidden="true" tabindex="-1"></a>Let's verify that the Monte Carlo error decreases with $B$:</span>
<span id="cb18-620"><a href="#cb18-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-623"><a href="#cb18-623" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-624"><a href="#cb18-624" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb18-625"><a href="#cb18-625" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 4</span></span>
<span id="cb18-626"><a href="#cb18-626" aria-hidden="true" tabindex="-1"></a><span class="co"># Show convergence of bootstrap SE as B increases</span></span>
<span id="cb18-627"><a href="#cb18-627" aria-hidden="true" tabindex="-1"></a>B_values <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2000</span>, <span class="dv">5000</span>]</span>
<span id="cb18-628"><a href="#cb18-628" aria-hidden="true" tabindex="-1"></a>se_estimates <span class="op">=</span> []</span>
<span id="cb18-629"><a href="#cb18-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-630"><a href="#cb18-630" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> B <span class="kw">in</span> B_values:</span>
<span id="cb18-631"><a href="#cb18-631" aria-hidden="true" tabindex="-1"></a>    se, _ <span class="op">=</span> bootstrap_se(data, np.median, B<span class="op">=</span>B)</span>
<span id="cb18-632"><a href="#cb18-632" aria-hidden="true" tabindex="-1"></a>    se_estimates.append(se)</span>
<span id="cb18-633"><a href="#cb18-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-634"><a href="#cb18-634" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">4</span>))</span>
<span id="cb18-635"><a href="#cb18-635" aria-hidden="true" tabindex="-1"></a>plt.plot(B_values, se_estimates, <span class="st">'bo-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb18-636"><a href="#cb18-636" aria-hidden="true" tabindex="-1"></a>plt.axhline(se_estimates[<span class="op">-</span><span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, </span>
<span id="cb18-637"><a href="#cb18-637" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Converged value ≈ </span><span class="sc">{</span>se_estimates[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb18-638"><a href="#cb18-638" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of bootstrap samples (B)'</span>)</span>
<span id="cb18-639"><a href="#cb18-639" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Bootstrap SE estimate'</span>)</span>
<span id="cb18-640"><a href="#cb18-640" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Monte Carlo Error Decreases with B'</span>)</span>
<span id="cb18-641"><a href="#cb18-641" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb18-642"><a href="#cb18-642" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-643"><a href="#cb18-643" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-644"><a href="#cb18-644" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-645"><a href="#cb18-645" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-646"><a href="#cb18-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-647"><a href="#cb18-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-648"><a href="#cb18-648" aria-hidden="true" tabindex="-1"></a>The fluctuations for small $B$ are due to Monte Carlo variability.</span>
<span id="cb18-649"><a href="#cb18-649" aria-hidden="true" tabindex="-1"></a>As $B$ increases, the bootstrap standard error estimate stabilizes.</span>
<span id="cb18-650"><a href="#cb18-650" aria-hidden="true" tabindex="-1"></a>Still, this is only one component of the error -- to improve further we need additional real data.</span>
<span id="cb18-651"><a href="#cb18-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-652"><a href="#cb18-652" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-653"><a href="#cb18-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-654"><a href="#cb18-654" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bootstrap Confidence Intervals</span></span>
<span id="cb18-655"><a href="#cb18-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-656"><a href="#cb18-656" aria-hidden="true" tabindex="-1"></a><span class="fu">### Three Common Methods</span></span>
<span id="cb18-657"><a href="#cb18-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-658"><a href="#cb18-658" aria-hidden="true" tabindex="-1"></a>Now that we can estimate the sampling distribution of any statistic via the bootstrap, we can construct confidence intervals. But how exactly should we use the bootstrap distribution to form an interval? </span>
<span id="cb18-659"><a href="#cb18-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-660"><a href="#cb18-660" aria-hidden="true" tabindex="-1"></a>There are **three main approaches**, each with different strengths and weaknesses. We'll illustrate all three using a real example: estimating the correlation between a country's economic prosperity and the health of its population.</span>
<span id="cb18-661"><a href="#cb18-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-662"><a href="#cb18-662" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip icon=false}</span>
<span id="cb18-663"><a href="#cb18-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-664"><a href="#cb18-664" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example: European Health and Wealth Data</span></span>
<span id="cb18-665"><a href="#cb18-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-666"><a href="#cb18-666" aria-hidden="true" tabindex="-1"></a>This example explores the correlation between a country's wealth (GDP per capita) and the average lifespan of its citizens (life expectancy at birth). The data is for a subset of EU countries, with <span class="co">[</span><span class="ot">GDP per capita for 2025</span><span class="co">]</span>(https://en.wikipedia.org/wiki/List_of_sovereign_states_in_Europe_by_GDP_(nominal)_per_capita) and <span class="co">[</span><span class="ot">life expectancy from 2023</span><span class="co">](https://en.wikipedia.org/wiki/List_of_European_countries_by_life_expectancy)</span>.</span>
<span id="cb18-667"><a href="#cb18-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-670"><a href="#cb18-670" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-671"><a href="#cb18-671" aria-hidden="true" tabindex="-1"></a><span class="co"># European Health and Wealth Data</span></span>
<span id="cb18-672"><a href="#cb18-672" aria-hidden="true" tabindex="-1"></a><span class="co"># GDP per capita (2025 forecast), Life Expectancy at birth (2023) for a subset of EU countries.</span></span>
<span id="cb18-673"><a href="#cb18-673" aria-hidden="true" tabindex="-1"></a>countries <span class="op">=</span> [</span>
<span id="cb18-674"><a href="#cb18-674" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Germany'</span>, <span class="st">'France'</span>, <span class="st">'Italy'</span>, <span class="st">'Spain'</span>, <span class="st">'Netherlands'</span>, <span class="st">'Poland'</span>, </span>
<span id="cb18-675"><a href="#cb18-675" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Belgium'</span>, <span class="st">'Sweden'</span>, <span class="st">'Austria'</span>, <span class="st">'Ireland'</span>, <span class="st">'Denmark'</span>, <span class="st">'Finland'</span>, </span>
<span id="cb18-676"><a href="#cb18-676" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Portugal'</span>, <span class="st">'Greece'</span>, <span class="st">'Czech Republic'</span></span>
<span id="cb18-677"><a href="#cb18-677" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb18-678"><a href="#cb18-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-679"><a href="#cb18-679" aria-hidden="true" tabindex="-1"></a>gdp_per_capita <span class="op">=</span> np.array([</span>
<span id="cb18-680"><a href="#cb18-680" aria-hidden="true" tabindex="-1"></a>    <span class="dv">55911</span>, <span class="dv">46792</span>, <span class="dv">41091</span>, <span class="dv">36192</span>, <span class="dv">70480</span>, <span class="dv">26805</span>, <span class="dv">57772</span>, <span class="dv">58100</span>, <span class="dv">58192</span>, </span>
<span id="cb18-681"><a href="#cb18-681" aria-hidden="true" tabindex="-1"></a>    <span class="dv">108919</span>, <span class="dv">74969</span>, <span class="dv">54163</span>, <span class="dv">30002</span>, <span class="dv">25756</span>, <span class="dv">33039</span></span>
<span id="cb18-682"><a href="#cb18-682" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb18-683"><a href="#cb18-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-684"><a href="#cb18-684" aria-hidden="true" tabindex="-1"></a>life_expectancy <span class="op">=</span> np.array([</span>
<span id="cb18-685"><a href="#cb18-685" aria-hidden="true" tabindex="-1"></a>    <span class="fl">81.38</span>, <span class="fl">83.33</span>, <span class="fl">83.72</span>, <span class="fl">83.67</span>, <span class="fl">82.16</span>, <span class="fl">78.63</span>, <span class="fl">82.11</span>, <span class="fl">83.26</span>, <span class="fl">81.96</span>, </span>
<span id="cb18-686"><a href="#cb18-686" aria-hidden="true" tabindex="-1"></a>    <span class="fl">82.41</span>, <span class="fl">81.93</span>, <span class="fl">81.91</span>, <span class="fl">82.36</span>, <span class="fl">81.86</span>, <span class="fl">79.83</span></span>
<span id="cb18-687"><a href="#cb18-687" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb18-688"><a href="#cb18-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-689"><a href="#cb18-689" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine into a single dataset for resampling</span></span>
<span id="cb18-690"><a href="#cb18-690" aria-hidden="true" tabindex="-1"></a>data_combined <span class="op">=</span> np.column_stack((gdp_per_capita, life_expectancy))</span>
<span id="cb18-691"><a href="#cb18-691" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(life_expectancy)</span>
<span id="cb18-692"><a href="#cb18-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-693"><a href="#cb18-693" aria-hidden="true" tabindex="-1"></a><span class="co"># Define correlation function</span></span>
<span id="cb18-694"><a href="#cb18-694" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> correlation(data):</span>
<span id="cb18-695"><a href="#cb18-695" aria-hidden="true" tabindex="-1"></a>    x, y <span class="op">=</span> data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>]</span>
<span id="cb18-696"><a href="#cb18-696" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.corrcoef(x, y)[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb18-697"><a href="#cb18-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-698"><a href="#cb18-698" aria-hidden="true" tabindex="-1"></a><span class="co"># Original correlation</span></span>
<span id="cb18-699"><a href="#cb18-699" aria-hidden="true" tabindex="-1"></a>rho_hat <span class="op">=</span> correlation(data_combined)</span>
<span id="cb18-700"><a href="#cb18-700" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample correlation: </span><span class="sc">{</span>rho_hat<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-701"><a href="#cb18-701" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-702"><a href="#cb18-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-703"><a href="#cb18-703" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-704"><a href="#cb18-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-705"><a href="#cb18-705" aria-hidden="true" tabindex="-1"></a>Now let's generate bootstrap samples:</span>
<span id="cb18-706"><a href="#cb18-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-709"><a href="#cb18-709" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-710"><a href="#cb18-710" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap the correlation</span></span>
<span id="cb18-711"><a href="#cb18-711" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb18-712"><a href="#cb18-712" aria-hidden="true" tabindex="-1"></a>boot_correlations <span class="op">=</span> np.zeros(B)</span>
<span id="cb18-713"><a href="#cb18-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-714"><a href="#cb18-714" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-715"><a href="#cb18-715" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb18-716"><a href="#cb18-716" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resample pairs (important to maintain pairing!)</span></span>
<span id="cb18-717"><a href="#cb18-717" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(n, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-718"><a href="#cb18-718" aria-hidden="true" tabindex="-1"></a>    boot_sample <span class="op">=</span> data_combined[indices]</span>
<span id="cb18-719"><a href="#cb18-719" aria-hidden="true" tabindex="-1"></a>    boot_correlations[b] <span class="op">=</span> correlation(boot_sample)</span>
<span id="cb18-720"><a href="#cb18-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-721"><a href="#cb18-721" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap standard error</span></span>
<span id="cb18-722"><a href="#cb18-722" aria-hidden="true" tabindex="-1"></a>se_boot <span class="op">=</span> np.std(boot_correlations, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-723"><a href="#cb18-723" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Bootstrap SE: </span><span class="sc">{</span>se_boot<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-724"><a href="#cb18-724" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-725"><a href="#cb18-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-726"><a href="#cb18-726" aria-hidden="true" tabindex="-1"></a>Let's visualize the bootstrap distribution:</span>
<span id="cb18-727"><a href="#cb18-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-730"><a href="#cb18-730" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-731"><a href="#cb18-731" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb18-732"><a href="#cb18-732" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb18-733"><a href="#cb18-733" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb18-734"><a href="#cb18-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-735"><a href="#cb18-735" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of original data</span></span>
<span id="cb18-736"><a href="#cb18-736" aria-hidden="true" tabindex="-1"></a>ax1.scatter(gdp_per_capita, life_expectancy, alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb18-737"><a href="#cb18-737" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'GDP per Capita (US$)'</span>)</span>
<span id="cb18-738"><a href="#cb18-738" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Life Expectancy (Years)'</span>)</span>
<span id="cb18-739"><a href="#cb18-739" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="ss">f'European Countries (ρ = </span><span class="sc">{</span>rho_hat<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb18-740"><a href="#cb18-740" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-741"><a href="#cb18-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-742"><a href="#cb18-742" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb18-743"><a href="#cb18-743" aria-hidden="true" tabindex="-1"></a>ax2.hist(boot_correlations, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb18-744"><a href="#cb18-744" aria-hidden="true" tabindex="-1"></a>         color<span class="op">=</span><span class="st">'green'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb18-745"><a href="#cb18-745" aria-hidden="true" tabindex="-1"></a>ax2.axvline(rho_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-746"><a href="#cb18-746" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Original ρ = </span><span class="sc">{</span>rho_hat<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb18-747"><a href="#cb18-747" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Bootstrap Correlation'</span>)</span>
<span id="cb18-748"><a href="#cb18-748" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-749"><a href="#cb18-749" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Bootstrap Distribution'</span>)</span>
<span id="cb18-750"><a href="#cb18-750" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb18-751"><a href="#cb18-751" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-752"><a href="#cb18-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-753"><a href="#cb18-753" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-754"><a href="#cb18-754" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-755"><a href="#cb18-755" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-756"><a href="#cb18-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-757"><a href="#cb18-757" aria-hidden="true" tabindex="-1"></a>Notice that the bootstrap distribution is somewhat skewed. This skewness will affect our confidence intervals.</span>
<span id="cb18-758"><a href="#cb18-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-759"><a href="#cb18-759" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparing Bootstrap Confidence Intervals</span></span>
<span id="cb18-760"><a href="#cb18-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-761"><a href="#cb18-761" aria-hidden="true" tabindex="-1"></a>Let $\hat{T}_n = T_n(\hat{F}_n)$ be the statistic evaluated on the empirical distribution, and $T_n^*$ the bootstrap statistic.</span>
<span id="cb18-762"><a href="#cb18-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-763"><a href="#cb18-763" aria-hidden="true" tabindex="-1"></a>::: {.tabbed-content}</span>
<span id="cb18-764"><a href="#cb18-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-765"><a href="#cb18-765" aria-hidden="true" tabindex="-1"></a><span class="fu">## Method 1: Normal Interval</span></span>
<span id="cb18-766"><a href="#cb18-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-767"><a href="#cb18-767" aria-hidden="true" tabindex="-1"></a>**Formula**: $\hat{T}_n \pm z_{\alpha/2} \widehat{\text{se}}_{\text{boot}}$</span>
<span id="cb18-768"><a href="#cb18-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-769"><a href="#cb18-769" aria-hidden="true" tabindex="-1"></a>This is the simplest method -- we just use the bootstrap standard error in the usual normal-based formula.</span>
<span id="cb18-770"><a href="#cb18-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-773"><a href="#cb18-773" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-774"><a href="#cb18-774" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal interval</span></span>
<span id="cb18-775"><a href="#cb18-775" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb18-776"><a href="#cb18-776" aria-hidden="true" tabindex="-1"></a>z_alpha <span class="op">=</span> stats.norm.ppf(<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-777"><a href="#cb18-777" aria-hidden="true" tabindex="-1"></a>normal_lower <span class="op">=</span> rho_hat <span class="op">-</span> z_alpha <span class="op">*</span> se_boot</span>
<span id="cb18-778"><a href="#cb18-778" aria-hidden="true" tabindex="-1"></a>normal_upper <span class="op">=</span> rho_hat <span class="op">+</span> z_alpha <span class="op">*</span> se_boot</span>
<span id="cb18-779"><a href="#cb18-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-780"><a href="#cb18-780" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Normal interval: (</span><span class="sc">{</span>normal_lower<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>normal_upper<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb18-781"><a href="#cb18-781" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-782"><a href="#cb18-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-783"><a href="#cb18-783" aria-hidden="true" tabindex="-1"></a>**Pros**:</span>
<span id="cb18-784"><a href="#cb18-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-785"><a href="#cb18-785" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Simple and intuitive</span>
<span id="cb18-786"><a href="#cb18-786" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Only requires the standard error, not the full distribution</span>
<span id="cb18-787"><a href="#cb18-787" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Familiar to those who know basic statistics</span>
<span id="cb18-788"><a href="#cb18-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-789"><a href="#cb18-789" aria-hidden="true" tabindex="-1"></a>**Cons**:</span>
<span id="cb18-790"><a href="#cb18-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-791"><a href="#cb18-791" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Assumes the sampling distribution is approximately normal</span>
<span id="cb18-792"><a href="#cb18-792" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can give nonsensical intervals (e.g., correlation &gt; 1)</span>
<span id="cb18-793"><a href="#cb18-793" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ignores skewness in the bootstrap distribution</span>
<span id="cb18-794"><a href="#cb18-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-795"><a href="#cb18-795" aria-hidden="true" tabindex="-1"></a>Let's check if our interval makes sense:</span>
<span id="cb18-796"><a href="#cb18-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-799"><a href="#cb18-799" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-800"><a href="#cb18-800" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> normal_upper <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb18-801"><a href="#cb18-801" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Warning: Upper limit </span><span class="sc">{</span>normal_upper<span class="sc">:.3f}</span><span class="ss"> exceeds 1!"</span>)</span>
<span id="cb18-802"><a href="#cb18-802" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"This is impossible for a correlation!"</span>)</span>
<span id="cb18-803"><a href="#cb18-803" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-804"><a href="#cb18-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-805"><a href="#cb18-805" aria-hidden="true" tabindex="-1"></a><span class="fu">## Method 2: Percentile Interval  </span></span>
<span id="cb18-806"><a href="#cb18-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-807"><a href="#cb18-807" aria-hidden="true" tabindex="-1"></a>**Formula**: $\left(T^*_{n, \alpha/2}, T^*_{n, 1-\alpha/2}\right)$</span>
<span id="cb18-808"><a href="#cb18-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-809"><a href="#cb18-809" aria-hidden="true" tabindex="-1"></a>where $T^*_{n,\beta}$ denotes the $\beta$ sample quantile of the bootstrapped statistic values $T^*_n$.</span>
<span id="cb18-810"><a href="#cb18-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-811"><a href="#cb18-811" aria-hidden="true" tabindex="-1"></a>The percentile interval method uses the $\alpha/2$ and $1-\alpha/2$ quantiles of the bootstrap distribution directly.</span>
<span id="cb18-812"><a href="#cb18-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-815"><a href="#cb18-815" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-816"><a href="#cb18-816" aria-hidden="true" tabindex="-1"></a><span class="co"># Percentile interval</span></span>
<span id="cb18-817"><a href="#cb18-817" aria-hidden="true" tabindex="-1"></a>percentile_lower <span class="op">=</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-818"><a href="#cb18-818" aria-hidden="true" tabindex="-1"></a>percentile_upper <span class="op">=</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-819"><a href="#cb18-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-820"><a href="#cb18-820" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Percentile interval: (</span><span class="sc">{</span>percentile_lower<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>percentile_upper<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb18-821"><a href="#cb18-821" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-822"><a href="#cb18-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-823"><a href="#cb18-823" aria-hidden="true" tabindex="-1"></a>**Pros**:</span>
<span id="cb18-824"><a href="#cb18-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-825"><a href="#cb18-825" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Doesn't assume normality -- adapts to the actual shape</span>
<span id="cb18-826"><a href="#cb18-826" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Always respects parameter bounds (correlation stays in <span class="co">[</span><span class="ot">-1, 1</span><span class="co">]</span>)</span>
<span id="cb18-827"><a href="#cb18-827" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Simple to understand: "middle 95% of bootstrap values"</span>
<span id="cb18-828"><a href="#cb18-828" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Works well when the bootstrap distribution is approximately unbiased</span>
<span id="cb18-829"><a href="#cb18-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-830"><a href="#cb18-830" aria-hidden="true" tabindex="-1"></a>**Cons**:</span>
<span id="cb18-831"><a href="#cb18-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-832"><a href="#cb18-832" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can have poor coverage when there's bias</span>
<span id="cb18-833"><a href="#cb18-833" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Not transformation-invariant</span>
<span id="cb18-834"><a href="#cb18-834" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>May not be accurate for small samples</span>
<span id="cb18-835"><a href="#cb18-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-836"><a href="#cb18-836" aria-hidden="true" tabindex="-1"></a><span class="fu">## Method 3: Pivotal Interval</span></span>
<span id="cb18-837"><a href="#cb18-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-838"><a href="#cb18-838" aria-hidden="true" tabindex="-1"></a>**Formula**: $\left(2\hat{T}_n - T^*_{n, 1-\alpha/2}, 2\hat{T}_n - T^*_{n, \alpha/2}\right)$</span>
<span id="cb18-839"><a href="#cb18-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-840"><a href="#cb18-840" aria-hidden="true" tabindex="-1"></a>This method assumes that the distribution of $T_n - \theta$ is approximately the same as the distribution of $T_n^* - T_n$, where $\theta$ is the true parameter.</span>
<span id="cb18-841"><a href="#cb18-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-844"><a href="#cb18-844" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-845"><a href="#cb18-845" aria-hidden="true" tabindex="-1"></a><span class="co"># Pivotal interval  </span></span>
<span id="cb18-846"><a href="#cb18-846" aria-hidden="true" tabindex="-1"></a>pivotal_lower <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> rho_hat <span class="op">-</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-847"><a href="#cb18-847" aria-hidden="true" tabindex="-1"></a>pivotal_upper <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> rho_hat <span class="op">-</span> np.percentile(boot_correlations, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-848"><a href="#cb18-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-849"><a href="#cb18-849" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Pivotal interval: (</span><span class="sc">{</span>pivotal_lower<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>pivotal_upper<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb18-850"><a href="#cb18-850" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-851"><a href="#cb18-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-852"><a href="#cb18-852" aria-hidden="true" tabindex="-1"></a>**Pros**:</span>
<span id="cb18-853"><a href="#cb18-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-854"><a href="#cb18-854" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Often more accurate than the other two methods</span>
<span id="cb18-855"><a href="#cb18-855" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Corrects for bias in the estimator</span>
<span id="cb18-856"><a href="#cb18-856" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Transformation-respecting (invariant under monotone transformations)</span>
<span id="cb18-857"><a href="#cb18-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-858"><a href="#cb18-858" aria-hidden="true" tabindex="-1"></a>**Cons**:</span>
<span id="cb18-859"><a href="#cb18-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-860"><a href="#cb18-860" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Less intuitive -- the formula seems backwards at first</span>
<span id="cb18-861"><a href="#cb18-861" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Can occasionally give values outside parameter bounds</span>
<span id="cb18-862"><a href="#cb18-862" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Requires symmetric error distribution for best performance</span>
<span id="cb18-863"><a href="#cb18-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-864"><a href="#cb18-864" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-865"><a href="#cb18-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-866"><a href="#cb18-866" aria-hidden="true" tabindex="-1"></a>Let's compare all three intervals visually:</span>
<span id="cb18-867"><a href="#cb18-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-870"><a href="#cb18-870" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-871"><a href="#cb18-871" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb18-872"><a href="#cb18-872" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb18-873"><a href="#cb18-873" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb18-874"><a href="#cb18-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-875"><a href="#cb18-875" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot bootstrap distribution</span></span>
<span id="cb18-876"><a href="#cb18-876" aria-hidden="true" tabindex="-1"></a>histogram_data <span class="op">=</span> ax.hist(boot_correlations, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, </span>
<span id="cb18-877"><a href="#cb18-877" aria-hidden="true" tabindex="-1"></a>                        color<span class="op">=</span><span class="st">'gray'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap distribution'</span>)</span>
<span id="cb18-878"><a href="#cb18-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-879"><a href="#cb18-879" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the maximum height for positioning intervals</span></span>
<span id="cb18-880"><a href="#cb18-880" aria-hidden="true" tabindex="-1"></a>max_density <span class="op">=</span> <span class="bu">max</span>(histogram_data[<span class="dv">0</span>])</span>
<span id="cb18-881"><a href="#cb18-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-882"><a href="#cb18-882" aria-hidden="true" tabindex="-1"></a><span class="co"># Add vertical lines for original estimate</span></span>
<span id="cb18-883"><a href="#cb18-883" aria-hidden="true" tabindex="-1"></a>ax.axvline(rho_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Original estimate'</span>)</span>
<span id="cb18-884"><a href="#cb18-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-885"><a href="#cb18-885" aria-hidden="true" tabindex="-1"></a><span class="co"># Add confidence intervals overlaid on the histogram</span></span>
<span id="cb18-886"><a href="#cb18-886" aria-hidden="true" tabindex="-1"></a>methods <span class="op">=</span> [<span class="st">'Normal'</span>, <span class="st">'Percentile'</span>, <span class="st">'Pivotal'</span>]</span>
<span id="cb18-887"><a href="#cb18-887" aria-hidden="true" tabindex="-1"></a>intervals <span class="op">=</span> [(normal_lower, normal_upper), </span>
<span id="cb18-888"><a href="#cb18-888" aria-hidden="true" tabindex="-1"></a>             (percentile_lower, percentile_upper),</span>
<span id="cb18-889"><a href="#cb18-889" aria-hidden="true" tabindex="-1"></a>             (pivotal_lower, pivotal_upper)]</span>
<span id="cb18-890"><a href="#cb18-890" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>, <span class="st">'green'</span>, <span class="st">'orange'</span>]</span>
<span id="cb18-891"><a href="#cb18-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-892"><a href="#cb18-892" aria-hidden="true" tabindex="-1"></a><span class="co"># Position intervals at different heights on the histogram</span></span>
<span id="cb18-893"><a href="#cb18-893" aria-hidden="true" tabindex="-1"></a>y_positions <span class="op">=</span> [max_density <span class="op">*</span> <span class="fl">0.2</span>, max_density <span class="op">*</span> <span class="fl">0.15</span>, max_density <span class="op">*</span> <span class="fl">0.1</span>]</span>
<span id="cb18-894"><a href="#cb18-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-895"><a href="#cb18-895" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method, (lower, upper), color, y_pos <span class="kw">in</span> <span class="bu">zip</span>(methods, intervals, colors, y_positions):</span>
<span id="cb18-896"><a href="#cb18-896" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw the interval line</span></span>
<span id="cb18-897"><a href="#cb18-897" aria-hidden="true" tabindex="-1"></a>    ax.plot([lower, upper], [y_pos, y_pos], color<span class="op">=</span>color, linewidth<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb18-898"><a href="#cb18-898" aria-hidden="true" tabindex="-1"></a>            marker<span class="op">=</span><span class="st">'|'</span>, markersize<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>method<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-899"><a href="#cb18-899" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add vertical lines at interval endpoints</span></span>
<span id="cb18-900"><a href="#cb18-900" aria-hidden="true" tabindex="-1"></a>    ax.vlines([lower, upper], <span class="dv">0</span>, y_pos, color<span class="op">=</span>color, linestyle<span class="op">=</span><span class="st">':'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-901"><a href="#cb18-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-902"><a href="#cb18-902" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Correlation'</span>)</span>
<span id="cb18-903"><a href="#cb18-903" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-904"><a href="#cb18-904" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Bootstrap Distribution with Confidence Intervals'</span>)</span>
<span id="cb18-905"><a href="#cb18-905" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb18-906"><a href="#cb18-906" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-907"><a href="#cb18-907" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, max_density <span class="op">*</span> <span class="fl">1.1</span>)</span>
<span id="cb18-908"><a href="#cb18-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-909"><a href="#cb18-909" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-910"><a href="#cb18-910" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-911"><a href="#cb18-911" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-912"><a href="#cb18-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-913"><a href="#cb18-913" aria-hidden="true" tabindex="-1"></a>Let's summarize the confidence intervals in a table for easy comparison:</span>
<span id="cb18-914"><a href="#cb18-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-917"><a href="#cb18-917" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-918"><a href="#cb18-918" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb18-919"><a href="#cb18-919" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the table with actual values</span></span>
<span id="cb18-920"><a href="#cb18-920" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"| Method     | Lower Bound | Upper Bound | Width |"</span>)</span>
<span id="cb18-921"><a href="#cb18-921" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"|------------|-------------|-------------|-------|"</span>)</span>
<span id="cb18-922"><a href="#cb18-922" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"| Normal     |   </span><span class="sc">{</span>normal_lower<span class="sc">:.3f}</span><span class="ss">    |    </span><span class="sc">{</span>normal_upper<span class="sc">:.3f}</span><span class="ss">    | </span><span class="sc">{</span>normal_upper <span class="op">-</span> normal_lower<span class="sc">:.3f}</span><span class="ss"> |"</span>)</span>
<span id="cb18-923"><a href="#cb18-923" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"| Percentile |   </span><span class="sc">{</span>percentile_lower<span class="sc">:.3f}</span><span class="ss">    |    </span><span class="sc">{</span>percentile_upper<span class="sc">:.3f}</span><span class="ss">    | </span><span class="sc">{</span>percentile_upper <span class="op">-</span> percentile_lower<span class="sc">:.3f}</span><span class="ss"> |"</span>)</span>
<span id="cb18-924"><a href="#cb18-924" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"| Pivotal    |   </span><span class="sc">{</span>pivotal_lower<span class="sc">:.3f}</span><span class="ss">    |    </span><span class="sc">{</span>pivotal_upper<span class="sc">:.3f}</span><span class="ss">    | </span><span class="sc">{</span>pivotal_upper <span class="op">-</span> pivotal_lower<span class="sc">:.3f}</span><span class="ss"> |"</span>)</span>
<span id="cb18-925"><a href="#cb18-925" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-926"><a href="#cb18-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-927"><a href="#cb18-927" aria-hidden="true" tabindex="-1"></a>In this example:</span>
<span id="cb18-928"><a href="#cb18-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-929"><a href="#cb18-929" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **Normal interval** is symmetric around the point estimate, ignoring the skewness</span>
<span id="cb18-930"><a href="#cb18-930" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **Percentile interval** reflects the skewness of the bootstrap distribution  </span>
<span id="cb18-931"><a href="#cb18-931" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **Pivotal interval** adjusts for bias and is slightly shifted from the percentile interval</span>
<span id="cb18-932"><a href="#cb18-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-933"><a href="#cb18-933" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-934"><a href="#cb18-934" aria-hidden="true" tabindex="-1"></a><span class="fu">## Advanced: Justification for the Pivotal Interval</span></span>
<span id="cb18-935"><a href="#cb18-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-936"><a href="#cb18-936" aria-hidden="true" tabindex="-1"></a>The pivotal method seems counterintuitive at first. Why do we subtract the upper quantile from $2\hat{T}_n$ to get the lower bound? </span>
<span id="cb18-937"><a href="#cb18-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-938"><a href="#cb18-938" aria-hidden="true" tabindex="-1"></a>The key insight is that the pivotal interval assumes the error $\hat{T}_n - \theta$ (where $\theta = T(F)$ is the true value) behaves similarly to the bootstrap error $T_n^* - \hat{T}_n$.</span>
<span id="cb18-939"><a href="#cb18-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-940"><a href="#cb18-940" aria-hidden="true" tabindex="-1"></a>**Quick derivation**: Start with the bootstrap distribution:</span>
<span id="cb18-941"><a href="#cb18-941" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}( T^*_{n,\alpha/2} \leq T_n^* \leq T^*_{n,1-\alpha/2} ) = 1-\alpha$$</span>
<span id="cb18-942"><a href="#cb18-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-943"><a href="#cb18-943" aria-hidden="true" tabindex="-1"></a>Subtract $\hat{T}_n$ throughout:</span>
<span id="cb18-944"><a href="#cb18-944" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}( T^*_{n,\alpha/2} - \hat{T}_n \leq T_n^* - \hat{T}_n \leq T^*_{n,1-\alpha/2} - \hat{T}_n ) = 1-\alpha$$</span>
<span id="cb18-945"><a href="#cb18-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-946"><a href="#cb18-946" aria-hidden="true" tabindex="-1"></a>The key assumption: The bootstrap error $T_n^* - \hat{T}_n$ has approximately the same distribution as the real error $\hat{T}_n - \theta$. Therefore:</span>
<span id="cb18-947"><a href="#cb18-947" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}( T^*_{n,\alpha/2} - \hat{T}_n \leq \hat{T}_n - \theta \leq T^*_{n,1-\alpha/2} - \hat{T}_n ) \approx 1-\alpha$$</span>
<span id="cb18-948"><a href="#cb18-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-949"><a href="#cb18-949" aria-hidden="true" tabindex="-1"></a>Rearranging to isolate $\theta$:</span>
<span id="cb18-950"><a href="#cb18-950" aria-hidden="true" tabindex="-1"></a>$$\mathbb{P}( 2\hat{T}_n - T^*_{n,1-\alpha/2} \leq \theta \leq 2\hat{T}_n - T^*_{n,\alpha/2} ) \approx 1-\alpha$$</span>
<span id="cb18-951"><a href="#cb18-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-952"><a href="#cb18-952" aria-hidden="true" tabindex="-1"></a>This gives us the pivotal interval: $(2\hat{T}_n - T^*_{n,1-\alpha/2}, 2\hat{T}_n - T^*_{n,\alpha/2})$.</span>
<span id="cb18-953"><a href="#cb18-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-954"><a href="#cb18-954" aria-hidden="true" tabindex="-1"></a>**Intuition**: If bootstrap values tend to be above our estimate, then our estimate is probably below the truth by a similar amount. The "2×estimate minus bootstrap quantile" formula automatically corrects for this bias.</span>
<span id="cb18-955"><a href="#cb18-955" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-956"><a href="#cb18-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-957"><a href="#cb18-957" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bootstrap Application: Higher Moments</span></span>
<span id="cb18-958"><a href="#cb18-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-959"><a href="#cb18-959" aria-hidden="true" tabindex="-1"></a>The following example demonstrates both the power and limitations of the bootstrap.</span>
<span id="cb18-960"><a href="#cb18-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-961"><a href="#cb18-961" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip icon=false}</span>
<span id="cb18-962"><a href="#cb18-962" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example: Bootstrap for Higher Moments</span></span>
<span id="cb18-963"><a href="#cb18-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-964"><a href="#cb18-964" aria-hidden="true" tabindex="-1"></a>Consider a sample of $n = 20$ observations from a standard normal distribution $\mathcal{N}(0, 1)$. We'll use the bootstrap to estimate confidence intervals for two related statistics:</span>
<span id="cb18-965"><a href="#cb18-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-966"><a href="#cb18-966" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$T^{(1)}(F) = \mathbb{E}<span class="co">[</span><span class="ot">X^4</span><span class="co">]</span>$ - the fourth raw moment</span>
<span id="cb18-967"><a href="#cb18-967" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$T^{(2)}(F) = \mathbb{E}<span class="co">[</span><span class="ot">(X - \mu)^4</span><span class="co">]</span>$ - the fourth central moment</span>
<span id="cb18-968"><a href="#cb18-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-969"><a href="#cb18-969" aria-hidden="true" tabindex="-1"></a>For the standard normal, both have the same true value: $T^{(1)}(F) = T^{(2)}(F) = 3$.</span>
<span id="cb18-970"><a href="#cb18-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-971"><a href="#cb18-971" aria-hidden="true" tabindex="-1"></a>This example is valuable because:</span>
<span id="cb18-972"><a href="#cb18-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-973"><a href="#cb18-973" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We can compute the true sampling distribution via simulation</span>
<span id="cb18-974"><a href="#cb18-974" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>It shows how bootstrap performs for non-standard statistics</span>
<span id="cb18-975"><a href="#cb18-975" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>It reveals differences between seemingly similar estimators</span>
<span id="cb18-976"><a href="#cb18-976" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-977"><a href="#cb18-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-978"><a href="#cb18-978" aria-hidden="true" tabindex="-1"></a>Let's implement this comparison:</span>
<span id="cb18-979"><a href="#cb18-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-982"><a href="#cb18-982" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-983"><a href="#cb18-983" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb18-984"><a href="#cb18-984" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 10</span></span>
<span id="cb18-985"><a href="#cb18-985" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-986"><a href="#cb18-986" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-987"><a href="#cb18-987" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb18-988"><a href="#cb18-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-989"><a href="#cb18-989" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the experiment</span></span>
<span id="cb18-990"><a href="#cb18-990" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-991"><a href="#cb18-991" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb18-992"><a href="#cb18-992" aria-hidden="true" tabindex="-1"></a>true_value <span class="op">=</span> <span class="dv">3</span>  <span class="co"># True 4th moment for N(0,1)</span></span>
<span id="cb18-993"><a href="#cb18-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-994"><a href="#cb18-994" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate one sample</span></span>
<span id="cb18-995"><a href="#cb18-995" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb18-996"><a href="#cb18-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-997"><a href="#cb18-997" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute point estimates</span></span>
<span id="cb18-998"><a href="#cb18-998" aria-hidden="true" tabindex="-1"></a>T1_hat <span class="op">=</span> np.mean(sample<span class="op">**</span><span class="dv">4</span>)  <span class="co"># Raw 4th moment</span></span>
<span id="cb18-999"><a href="#cb18-999" aria-hidden="true" tabindex="-1"></a>T2_hat <span class="op">=</span> np.mean((sample <span class="op">-</span> np.mean(sample))<span class="op">**</span><span class="dv">4</span>)  <span class="co"># Central 4th moment</span></span>
<span id="cb18-1000"><a href="#cb18-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1001"><a href="#cb18-1001" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True value: </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-1002"><a href="#cb18-1002" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"T¹ (raw 4th moment): </span><span class="sc">{</span>T1_hat<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-1003"><a href="#cb18-1003" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"T² (central 4th moment): </span><span class="sc">{</span>T2_hat<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-1004"><a href="#cb18-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1005"><a href="#cb18-1005" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distributions</span></span>
<span id="cb18-1006"><a href="#cb18-1006" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb18-1007"><a href="#cb18-1007" aria-hidden="true" tabindex="-1"></a>boot_T1 <span class="op">=</span> np.zeros(B)</span>
<span id="cb18-1008"><a href="#cb18-1008" aria-hidden="true" tabindex="-1"></a>boot_T2 <span class="op">=</span> np.zeros(B)</span>
<span id="cb18-1009"><a href="#cb18-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1010"><a href="#cb18-1010" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb18-1011"><a href="#cb18-1011" aria-hidden="true" tabindex="-1"></a>    boot_sample <span class="op">=</span> np.random.choice(sample, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-1012"><a href="#cb18-1012" aria-hidden="true" tabindex="-1"></a>    boot_T1[b] <span class="op">=</span> np.mean(boot_sample<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb18-1013"><a href="#cb18-1013" aria-hidden="true" tabindex="-1"></a>    boot_T2[b] <span class="op">=</span> np.mean((boot_sample <span class="op">-</span> np.mean(boot_sample))<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb18-1014"><a href="#cb18-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1015"><a href="#cb18-1015" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distributions (via simulation)</span></span>
<span id="cb18-1016"><a href="#cb18-1016" aria-hidden="true" tabindex="-1"></a>n_true <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb18-1017"><a href="#cb18-1017" aria-hidden="true" tabindex="-1"></a>true_T1 <span class="op">=</span> np.zeros(n_true)</span>
<span id="cb18-1018"><a href="#cb18-1018" aria-hidden="true" tabindex="-1"></a>true_T2 <span class="op">=</span> np.zeros(n_true)</span>
<span id="cb18-1019"><a href="#cb18-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1020"><a href="#cb18-1020" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_true):</span>
<span id="cb18-1021"><a href="#cb18-1021" aria-hidden="true" tabindex="-1"></a>    true_sample <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb18-1022"><a href="#cb18-1022" aria-hidden="true" tabindex="-1"></a>    true_T1[i] <span class="op">=</span> np.mean(true_sample<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb18-1023"><a href="#cb18-1023" aria-hidden="true" tabindex="-1"></a>    true_T2[i] <span class="op">=</span> np.mean((true_sample <span class="op">-</span> np.mean(true_sample))<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb18-1024"><a href="#cb18-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1025"><a href="#cb18-1025" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine common x-axis range to show the dramatic difference</span></span>
<span id="cb18-1026"><a href="#cb18-1026" aria-hidden="true" tabindex="-1"></a>x_min <span class="op">=</span> <span class="bu">min</span>(np.<span class="bu">min</span>(boot_T1), np.<span class="bu">min</span>(boot_T2), np.<span class="bu">min</span>(true_T1), np.<span class="bu">min</span>(true_T2))</span>
<span id="cb18-1027"><a href="#cb18-1027" aria-hidden="true" tabindex="-1"></a>x_max <span class="op">=</span> <span class="bu">max</span>(np.<span class="bu">max</span>(boot_T1), np.<span class="bu">max</span>(boot_T2), np.<span class="bu">max</span>(true_T1), np.<span class="bu">max</span>(true_T2))</span>
<span id="cb18-1028"><a href="#cb18-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1029"><a href="#cb18-1029" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure with 4 subplots</span></span>
<span id="cb18-1030"><a href="#cb18-1030" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">10</span>))</span>
<span id="cb18-1031"><a href="#cb18-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1032"><a href="#cb18-1032" aria-hidden="true" tabindex="-1"></a><span class="co"># T1: Raw 4th moment</span></span>
<span id="cb18-1033"><a href="#cb18-1033" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb18-1034"><a href="#cb18-1034" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb18-1035"><a href="#cb18-1035" aria-hidden="true" tabindex="-1"></a>ax1.hist(boot_T1, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, </span>
<span id="cb18-1036"><a href="#cb18-1036" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap'</span>)</span>
<span id="cb18-1037"><a href="#cb18-1037" aria-hidden="true" tabindex="-1"></a>ax1.axvline(T1_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1038"><a href="#cb18-1038" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Estimate = </span><span class="sc">{</span>T1_hat<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb18-1039"><a href="#cb18-1039" aria-hidden="true" tabindex="-1"></a>ax1.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1040"><a href="#cb18-1040" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-1041"><a href="#cb18-1041" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'T¹: Bootstrap Distribution'</span>)</span>
<span id="cb18-1042"><a href="#cb18-1042" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb18-1043"><a href="#cb18-1043" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-1044"><a href="#cb18-1044" aria-hidden="true" tabindex="-1"></a>ax1.set_xlim(x_min, x_max)</span>
<span id="cb18-1045"><a href="#cb18-1045" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb18-1046"><a href="#cb18-1046" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-1047"><a href="#cb18-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1048"><a href="#cb18-1048" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distribution</span></span>
<span id="cb18-1049"><a href="#cb18-1049" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb18-1050"><a href="#cb18-1050" aria-hidden="true" tabindex="-1"></a>ax2.hist(true_T1, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'green'</span>, </span>
<span id="cb18-1051"><a href="#cb18-1051" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'True sampling dist'</span>)</span>
<span id="cb18-1052"><a href="#cb18-1052" aria-hidden="true" tabindex="-1"></a>ax2.axvline(np.mean(true_T1), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1053"><a href="#cb18-1053" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Mean = </span><span class="sc">{</span>np<span class="sc">.</span>mean(true_T1)<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb18-1054"><a href="#cb18-1054" aria-hidden="true" tabindex="-1"></a>ax2.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1055"><a href="#cb18-1055" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-1056"><a href="#cb18-1056" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'T¹: True Sampling Distribution'</span>)</span>
<span id="cb18-1057"><a href="#cb18-1057" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb18-1058"><a href="#cb18-1058" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-1059"><a href="#cb18-1059" aria-hidden="true" tabindex="-1"></a>ax2.set_xlim(x_min, x_max)</span>
<span id="cb18-1060"><a href="#cb18-1060" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb18-1061"><a href="#cb18-1061" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-1062"><a href="#cb18-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1063"><a href="#cb18-1063" aria-hidden="true" tabindex="-1"></a><span class="co"># T2: Central 4th moment</span></span>
<span id="cb18-1064"><a href="#cb18-1064" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb18-1065"><a href="#cb18-1065" aria-hidden="true" tabindex="-1"></a>ax3 <span class="op">=</span> axes[<span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb18-1066"><a href="#cb18-1066" aria-hidden="true" tabindex="-1"></a>ax3.hist(boot_T2, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>, </span>
<span id="cb18-1067"><a href="#cb18-1067" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap'</span>)</span>
<span id="cb18-1068"><a href="#cb18-1068" aria-hidden="true" tabindex="-1"></a>ax3.axvline(T2_hat, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1069"><a href="#cb18-1069" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Estimate = </span><span class="sc">{</span>T2_hat<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb18-1070"><a href="#cb18-1070" aria-hidden="true" tabindex="-1"></a>ax3.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1071"><a href="#cb18-1071" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-1072"><a href="#cb18-1072" aria-hidden="true" tabindex="-1"></a>ax3.set_title(<span class="st">'T²: Bootstrap Distribution'</span>)</span>
<span id="cb18-1073"><a href="#cb18-1073" aria-hidden="true" tabindex="-1"></a>ax3.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb18-1074"><a href="#cb18-1074" aria-hidden="true" tabindex="-1"></a>ax3.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-1075"><a href="#cb18-1075" aria-hidden="true" tabindex="-1"></a>ax3.set_xlim(x_min, x_max)</span>
<span id="cb18-1076"><a href="#cb18-1076" aria-hidden="true" tabindex="-1"></a>ax3.legend()</span>
<span id="cb18-1077"><a href="#cb18-1077" aria-hidden="true" tabindex="-1"></a>ax3.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-1078"><a href="#cb18-1078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1079"><a href="#cb18-1079" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distribution</span></span>
<span id="cb18-1080"><a href="#cb18-1080" aria-hidden="true" tabindex="-1"></a>ax4 <span class="op">=</span> axes[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb18-1081"><a href="#cb18-1081" aria-hidden="true" tabindex="-1"></a>ax4.hist(true_T2, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'green'</span>, </span>
<span id="cb18-1082"><a href="#cb18-1082" aria-hidden="true" tabindex="-1"></a>         edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'True sampling dist'</span>)</span>
<span id="cb18-1083"><a href="#cb18-1083" aria-hidden="true" tabindex="-1"></a>ax4.axvline(np.mean(true_T2), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1084"><a href="#cb18-1084" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'Mean = </span><span class="sc">{</span>np<span class="sc">.</span>mean(true_T2)<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb18-1085"><a href="#cb18-1085" aria-hidden="true" tabindex="-1"></a>ax4.axvline(true_value, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1086"><a href="#cb18-1086" aria-hidden="true" tabindex="-1"></a>            label<span class="op">=</span><span class="ss">f'True = </span><span class="sc">{</span>true_value<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-1087"><a href="#cb18-1087" aria-hidden="true" tabindex="-1"></a>ax4.set_title(<span class="st">'T²: True Sampling Distribution'</span>)</span>
<span id="cb18-1088"><a href="#cb18-1088" aria-hidden="true" tabindex="-1"></a>ax4.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb18-1089"><a href="#cb18-1089" aria-hidden="true" tabindex="-1"></a>ax4.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-1090"><a href="#cb18-1090" aria-hidden="true" tabindex="-1"></a>ax4.set_xlim(x_min, x_max)</span>
<span id="cb18-1091"><a href="#cb18-1091" aria-hidden="true" tabindex="-1"></a>ax4.legend()</span>
<span id="cb18-1092"><a href="#cb18-1092" aria-hidden="true" tabindex="-1"></a>ax4.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-1093"><a href="#cb18-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1094"><a href="#cb18-1094" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Bootstrap vs True Sampling Distributions'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb18-1095"><a href="#cb18-1095" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-1096"><a href="#cb18-1096" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-1097"><a href="#cb18-1097" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1098"><a href="#cb18-1098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1099"><a href="#cb18-1099" aria-hidden="true" tabindex="-1"></a>Now let's compare the confidence intervals:</span>
<span id="cb18-1100"><a href="#cb18-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1103"><a href="#cb18-1103" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-1104"><a href="#cb18-1104" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb18-1105"><a href="#cb18-1105" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute confidence intervals</span></span>
<span id="cb18-1106"><a href="#cb18-1106" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb18-1107"><a href="#cb18-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1108"><a href="#cb18-1108" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap intervals</span></span>
<span id="cb18-1109"><a href="#cb18-1109" aria-hidden="true" tabindex="-1"></a>boot_T1_lower_norm <span class="op">=</span> T1_hat <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> np.std(boot_T1)</span>
<span id="cb18-1110"><a href="#cb18-1110" aria-hidden="true" tabindex="-1"></a>boot_T1_upper_norm <span class="op">=</span> T1_hat <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> np.std(boot_T1)</span>
<span id="cb18-1111"><a href="#cb18-1111" aria-hidden="true" tabindex="-1"></a>boot_T1_lower_perc <span class="op">=</span> np.percentile(boot_T1, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-1112"><a href="#cb18-1112" aria-hidden="true" tabindex="-1"></a>boot_T1_upper_perc <span class="op">=</span> np.percentile(boot_T1, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-1113"><a href="#cb18-1113" aria-hidden="true" tabindex="-1"></a>boot_T1_lower_piv <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>T1_hat <span class="op">-</span> np.percentile(boot_T1, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-1114"><a href="#cb18-1114" aria-hidden="true" tabindex="-1"></a>boot_T1_upper_piv <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>T1_hat <span class="op">-</span> np.percentile(boot_T1, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-1115"><a href="#cb18-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1116"><a href="#cb18-1116" aria-hidden="true" tabindex="-1"></a>boot_T2_lower_norm <span class="op">=</span> T2_hat <span class="op">-</span> <span class="fl">1.96</span> <span class="op">*</span> np.std(boot_T2)</span>
<span id="cb18-1117"><a href="#cb18-1117" aria-hidden="true" tabindex="-1"></a>boot_T2_upper_norm <span class="op">=</span> T2_hat <span class="op">+</span> <span class="fl">1.96</span> <span class="op">*</span> np.std(boot_T2)</span>
<span id="cb18-1118"><a href="#cb18-1118" aria-hidden="true" tabindex="-1"></a>boot_T2_lower_perc <span class="op">=</span> np.percentile(boot_T2, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-1119"><a href="#cb18-1119" aria-hidden="true" tabindex="-1"></a>boot_T2_upper_perc <span class="op">=</span> np.percentile(boot_T2, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-1120"><a href="#cb18-1120" aria-hidden="true" tabindex="-1"></a>boot_T2_lower_piv <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>T2_hat <span class="op">-</span> np.percentile(boot_T2, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-1121"><a href="#cb18-1121" aria-hidden="true" tabindex="-1"></a>boot_T2_upper_piv <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>T2_hat <span class="op">-</span> np.percentile(boot_T2, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-1122"><a href="#cb18-1122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1123"><a href="#cb18-1123" aria-hidden="true" tabindex="-1"></a><span class="co"># True intervals (oracle)</span></span>
<span id="cb18-1124"><a href="#cb18-1124" aria-hidden="true" tabindex="-1"></a>true_T1_lower <span class="op">=</span> np.percentile(true_T1, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-1125"><a href="#cb18-1125" aria-hidden="true" tabindex="-1"></a>true_T1_upper <span class="op">=</span> np.percentile(true_T1, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-1126"><a href="#cb18-1126" aria-hidden="true" tabindex="-1"></a>true_T2_lower <span class="op">=</span> np.percentile(true_T2, <span class="dv">100</span> <span class="op">*</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-1127"><a href="#cb18-1127" aria-hidden="true" tabindex="-1"></a>true_T2_upper <span class="op">=</span> np.percentile(true_T2, <span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-1128"><a href="#cb18-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1129"><a href="#cb18-1129" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confidence Intervals for T¹ (Raw 4th Moment):"</span>)</span>
<span id="cb18-1130"><a href="#cb18-1130" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  True 95% CI:        (</span><span class="sc">{</span>true_T1_lower<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>true_T1_upper<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1131"><a href="#cb18-1131" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bootstrap Normal:   (</span><span class="sc">{</span>boot_T1_lower_norm<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>boot_T1_upper_norm<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1132"><a href="#cb18-1132" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bootstrap Percent:  (</span><span class="sc">{</span>boot_T1_lower_perc<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>boot_T1_upper_perc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1133"><a href="#cb18-1133" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bootstrap Pivotal:  (</span><span class="sc">{</span>boot_T1_lower_piv<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>boot_T1_upper_piv<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1134"><a href="#cb18-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1135"><a href="#cb18-1135" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Confidence Intervals for T² (Central 4th Moment):"</span>)</span>
<span id="cb18-1136"><a href="#cb18-1136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  True 95% CI:        (</span><span class="sc">{</span>true_T2_lower<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>true_T2_upper<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1137"><a href="#cb18-1137" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bootstrap Normal:   (</span><span class="sc">{</span>boot_T2_lower_norm<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>boot_T2_upper_norm<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1138"><a href="#cb18-1138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bootstrap Percent:  (</span><span class="sc">{</span>boot_T2_lower_perc<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>boot_T2_upper_perc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1139"><a href="#cb18-1139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bootstrap Pivotal:  (</span><span class="sc">{</span>boot_T2_lower_piv<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>boot_T2_upper_piv<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1140"><a href="#cb18-1140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1141"><a href="#cb18-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1142"><a href="#cb18-1142" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb18-1143"><a href="#cb18-1143" aria-hidden="true" tabindex="-1"></a><span class="fu">## What Went Wrong?</span></span>
<span id="cb18-1144"><a href="#cb18-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1145"><a href="#cb18-1145" aria-hidden="true" tabindex="-1"></a>The bootstrap catastrophically fails here -- all methods estimate upper confidence bounds of ~3.4-3.8, while the true bounds are ~8-9 (more than double!). </span>
<span id="cb18-1146"><a href="#cb18-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1147"><a href="#cb18-1147" aria-hidden="true" tabindex="-1"></a>Why? Fourth moments have heavy-tailed sampling distributions. With only n=20 observations, we likely missed the rare extreme values that drive the true variability. The bootstrap can only resample what it sees, so it fundamentally cannot capture the full range of uncertainty.</span>
<span id="cb18-1148"><a href="#cb18-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1149"><a href="#cb18-1149" aria-hidden="true" tabindex="-1"></a>This isn't just a small sample problem -- it's a fundamental limitation when statistics depend heavily on extreme values. Let's explore when else the bootstrap fails...</span>
<span id="cb18-1150"><a href="#cb18-1150" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1151"><a href="#cb18-1151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1152"><a href="#cb18-1152" aria-hidden="true" tabindex="-1"></a><span class="fu">## When The Bootstrap Fails</span></span>
<span id="cb18-1153"><a href="#cb18-1153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1154"><a href="#cb18-1154" aria-hidden="true" tabindex="-1"></a>The bootstrap is remarkably general, but it's not foolproof. It relies on the sample being a good representation of the population. When this assumption breaks down, so does the bootstrap.</span>
<span id="cb18-1155"><a href="#cb18-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1156"><a href="#cb18-1156" aria-hidden="true" tabindex="-1"></a>The bootstrap may fail or perform poorly when:</span>
<span id="cb18-1157"><a href="#cb18-1157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1158"><a href="#cb18-1158" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Sample size is too small** (typically n &lt; 20-30)</span>
<span id="cb18-1159"><a href="#cb18-1159" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Estimating extreme order statistics** (min, max, extreme quantiles)</span>
<span id="cb18-1160"><a href="#cb18-1160" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Heavy-tailed distributions** without finite moments</span>
<span id="cb18-1161"><a href="#cb18-1161" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Non-smooth statistics** (e.g., number of modes)</span>
<span id="cb18-1162"><a href="#cb18-1162" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Dependent data** (unless using specialized methods like block bootstrap)</span>
<span id="cb18-1163"><a href="#cb18-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1164"><a href="#cb18-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1165"><a href="#cb18-1165" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip icon=false}</span>
<span id="cb18-1166"><a href="#cb18-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1167"><a href="#cb18-1167" aria-hidden="true" tabindex="-1"></a><span class="fu">## Example: Estimators at the Boundary</span></span>
<span id="cb18-1168"><a href="#cb18-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1169"><a href="#cb18-1169" aria-hidden="true" tabindex="-1"></a>The bootstrap performs poorly for statistics at the edge of the parameter space. The classic example is estimating the maximum of a uniform distribution:</span>
<span id="cb18-1170"><a href="#cb18-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1173"><a href="#cb18-1173" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-1174"><a href="#cb18-1174" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb18-1175"><a href="#cb18-1175" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb18-1176"><a href="#cb18-1176" aria-hidden="true" tabindex="-1"></a><span class="co"># Uniform distribution example</span></span>
<span id="cb18-1177"><a href="#cb18-1177" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-1178"><a href="#cb18-1178" aria-hidden="true" tabindex="-1"></a>true_max <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb18-1179"><a href="#cb18-1179" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb18-1180"><a href="#cb18-1180" aria-hidden="true" tabindex="-1"></a>uniform_sample <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, true_max, n)</span>
<span id="cb18-1181"><a href="#cb18-1181" aria-hidden="true" tabindex="-1"></a>sample_max <span class="op">=</span> np.<span class="bu">max</span>(uniform_sample)</span>
<span id="cb18-1182"><a href="#cb18-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1183"><a href="#cb18-1183" aria-hidden="true" tabindex="-1"></a><span class="co"># True sampling distribution of the maximum</span></span>
<span id="cb18-1184"><a href="#cb18-1184" aria-hidden="true" tabindex="-1"></a><span class="co"># For Uniform(0, θ), the maximum has CDF F(x) = (x/θ)^n</span></span>
<span id="cb18-1185"><a href="#cb18-1185" aria-hidden="true" tabindex="-1"></a>x_theory <span class="op">=</span> np.linspace(sample_max <span class="op">*</span> <span class="fl">0.8</span>, true_max, <span class="dv">1000</span>)</span>
<span id="cb18-1186"><a href="#cb18-1186" aria-hidden="true" tabindex="-1"></a>pdf_theory <span class="op">=</span> n <span class="op">*</span> (x_theory<span class="op">/</span>true_max)<span class="op">**</span>(n<span class="op">-</span><span class="dv">1</span>) <span class="op">/</span> true_max</span>
<span id="cb18-1187"><a href="#cb18-1187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1188"><a href="#cb18-1188" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap distribution</span></span>
<span id="cb18-1189"><a href="#cb18-1189" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb18-1190"><a href="#cb18-1190" aria-hidden="true" tabindex="-1"></a>boot_max_uniform <span class="op">=</span> np.zeros(B)</span>
<span id="cb18-1191"><a href="#cb18-1191" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb18-1192"><a href="#cb18-1192" aria-hidden="true" tabindex="-1"></a>    boot_sample <span class="op">=</span> np.random.choice(uniform_sample, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-1193"><a href="#cb18-1193" aria-hidden="true" tabindex="-1"></a>    boot_max_uniform[b] <span class="op">=</span> np.<span class="bu">max</span>(boot_sample)</span>
<span id="cb18-1194"><a href="#cb18-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1195"><a href="#cb18-1195" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb18-1196"><a href="#cb18-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1197"><a href="#cb18-1197" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap histogram</span></span>
<span id="cb18-1198"><a href="#cb18-1198" aria-hidden="true" tabindex="-1"></a>ax.hist(boot_max_uniform, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb18-1199"><a href="#cb18-1199" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Bootstrap distribution'</span>)</span>
<span id="cb18-1200"><a href="#cb18-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1201"><a href="#cb18-1201" aria-hidden="true" tabindex="-1"></a><span class="co"># True distribution</span></span>
<span id="cb18-1202"><a href="#cb18-1202" aria-hidden="true" tabindex="-1"></a>ax.plot(x_theory, pdf_theory, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'True distribution'</span>)</span>
<span id="cb18-1203"><a href="#cb18-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1204"><a href="#cb18-1204" aria-hidden="true" tabindex="-1"></a><span class="co"># Key values</span></span>
<span id="cb18-1205"><a href="#cb18-1205" aria-hidden="true" tabindex="-1"></a>ax.axvline(sample_max, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1206"><a href="#cb18-1206" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Sample max = </span><span class="sc">{</span>sample_max<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb18-1207"><a href="#cb18-1207" aria-hidden="true" tabindex="-1"></a>ax.axvline(true_max, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb18-1208"><a href="#cb18-1208" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'True θ = </span><span class="sc">{</span>true_max<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-1209"><a href="#cb18-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1210"><a href="#cb18-1210" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb18-1211"><a href="#cb18-1211" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Density'</span>)</span>
<span id="cb18-1212"><a href="#cb18-1212" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Bootstrap Fails for Uniform Maximum'</span>)</span>
<span id="cb18-1213"><a href="#cb18-1213" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb18-1214"><a href="#cb18-1214" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-1215"><a href="#cb18-1215" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">8</span>, <span class="fl">10.5</span>)</span>
<span id="cb18-1216"><a href="#cb18-1216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1217"><a href="#cb18-1217" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-1218"><a href="#cb18-1218" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-1219"><a href="#cb18-1219" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1220"><a href="#cb18-1220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1221"><a href="#cb18-1221" aria-hidden="true" tabindex="-1"></a>**Why it fails**: </span>
<span id="cb18-1222"><a href="#cb18-1222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1223"><a href="#cb18-1223" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The true maximum ($\theta = 10$) is always ≥ the sample maximum</span>
<span id="cb18-1224"><a href="#cb18-1224" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The true sampling distribution has support on $<span class="co">[</span><span class="ot">\text{sample max}, \theta</span><span class="co">]</span>$</span>
<span id="cb18-1225"><a href="#cb18-1225" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>But bootstrap samples can never exceed the original sample maximum!</span>
<span id="cb18-1226"><a href="#cb18-1226" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The bootstrap distribution is entirely to the left of where it should be</span>
<span id="cb18-1227"><a href="#cb18-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1228"><a href="#cb18-1228" aria-hidden="true" tabindex="-1"></a>**Note:** Similar biases arise when estimating extreme statistics (e.g., very small or very large quantiles) of any distribution.</span>
<span id="cb18-1229"><a href="#cb18-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1230"><a href="#cb18-1230" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1231"><a href="#cb18-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1232"><a href="#cb18-1232" aria-hidden="true" tabindex="-1"></a>Despite these limitations, the bootstrap remains one of the most useful tools in modern statistics. Just remember: it's a powerful method, not a magical one.</span>
<span id="cb18-1233"><a href="#cb18-1233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1234"><a href="#cb18-1234" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chapter Summary and Connections</span></span>
<span id="cb18-1235"><a href="#cb18-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1236"><a href="#cb18-1236" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Concepts Review</span></span>
<span id="cb18-1237"><a href="#cb18-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1238"><a href="#cb18-1238" aria-hidden="true" tabindex="-1"></a>We've covered two fundamental ideas that revolutionized statistical practice:</span>
<span id="cb18-1239"><a href="#cb18-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1240"><a href="#cb18-1240" aria-hidden="true" tabindex="-1"></a>**The Plug-In Principle**:</span>
<span id="cb18-1241"><a href="#cb18-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1242"><a href="#cb18-1242" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Estimate the distribution with the empirical distribution function (EDF)</span>
<span id="cb18-1243"><a href="#cb18-1243" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Estimate any functional $T(F)$ by computing $T(\hat{F}_n)$</span>
<span id="cb18-1244"><a href="#cb18-1244" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Simple, intuitive, and widely applicable</span>
<span id="cb18-1245"><a href="#cb18-1245" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gives us point estimates for any statistic</span>
<span id="cb18-1246"><a href="#cb18-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1247"><a href="#cb18-1247" aria-hidden="true" tabindex="-1"></a>**The Bootstrap**:</span>
<span id="cb18-1248"><a href="#cb18-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1249"><a href="#cb18-1249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Assess uncertainty by resampling from the data</span>
<span id="cb18-1250"><a href="#cb18-1250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Create the "bootstrap world" that mimics the real world</span>
<span id="cb18-1251"><a href="#cb18-1251" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Estimate standard errors and confidence intervals for any statistic</span>
<span id="cb18-1252"><a href="#cb18-1252" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Three types of confidence intervals: Normal, Percentile, Pivotal</span>
<span id="cb18-1253"><a href="#cb18-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1254"><a href="#cb18-1254" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why These Concepts Matter</span></span>
<span id="cb18-1255"><a href="#cb18-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1256"><a href="#cb18-1256" aria-hidden="true" tabindex="-1"></a>**For Statistical Practice**:</span>
<span id="cb18-1257"><a href="#cb18-1257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1258"><a href="#cb18-1258" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>No need to derive complex formulas for standard errors</span>
<span id="cb18-1259"><a href="#cb18-1259" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Works for statistics where theory is intractable (median, correlation, etc.)</span>
<span id="cb18-1260"><a href="#cb18-1260" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Provides a unified approach to uncertainty quantification</span>
<span id="cb18-1261"><a href="#cb18-1261" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Democratizes statistics -- complex inference becomes accessible</span>
<span id="cb18-1262"><a href="#cb18-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1263"><a href="#cb18-1263" aria-hidden="true" tabindex="-1"></a>**For Data Science**:</span>
<span id="cb18-1264"><a href="#cb18-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1265"><a href="#cb18-1265" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Computational approach aligns with modern computing power</span>
<span id="cb18-1266"><a href="#cb18-1266" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Easy to implement and parallelize</span>
<span id="cb18-1267"><a href="#cb18-1267" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Works with complex models and machine learning algorithms</span>
<span id="cb18-1268"><a href="#cb18-1268" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Provides uncertainty estimates crucial for decision-making</span>
<span id="cb18-1269"><a href="#cb18-1269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1270"><a href="#cb18-1270" aria-hidden="true" tabindex="-1"></a>**For Understanding**:</span>
<span id="cb18-1271"><a href="#cb18-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1272"><a href="#cb18-1272" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Makes abstract concepts concrete through simulation</span>
<span id="cb18-1273"><a href="#cb18-1273" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reveals the sampling distribution visually</span>
<span id="cb18-1274"><a href="#cb18-1274" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Helps build intuition about statistical variability</span>
<span id="cb18-1275"><a href="#cb18-1275" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Connects theoretical statistics to computational practice</span>
<span id="cb18-1276"><a href="#cb18-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1277"><a href="#cb18-1277" aria-hidden="true" tabindex="-1"></a><span class="fu">### Common Pitfalls to Avoid</span></span>
<span id="cb18-1278"><a href="#cb18-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1279"><a href="#cb18-1279" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Forgetting to sample with replacement**</span>
<span id="cb18-1280"><a href="#cb18-1280" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Bootstrap samples must be the same size as original</span>
<span id="cb18-1281"><a href="#cb18-1281" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Sampling without replacement gives wrong answers</span>
<span id="cb18-1282"><a href="#cb18-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1283"><a href="#cb18-1283" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Using too few bootstrap samples**</span>
<span id="cb18-1284"><a href="#cb18-1284" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Use at least $B = 1,000$ for standard errors</span>
<span id="cb18-1285"><a href="#cb18-1285" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Use $B = 10,000$ or more for confidence intervals</span>
<span id="cb18-1286"><a href="#cb18-1286" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Monte Carlo error decreases with $\sqrt{B}$</span>
<span id="cb18-1287"><a href="#cb18-1287" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>In practice, use as many as you can given your available compute</span>
<span id="cb18-1288"><a href="#cb18-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1289"><a href="#cb18-1289" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Misinterpreting confidence intervals**</span>
<span id="cb18-1290"><a href="#cb18-1290" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>They quantify uncertainty in the estimate</span>
<span id="cb18-1291"><a href="#cb18-1291" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>They are not probability statements about parameters</span>
<span id="cb18-1292"><a href="#cb18-1292" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Different methods can give different intervals</span>
<span id="cb18-1293"><a href="#cb18-1293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1294"><a href="#cb18-1294" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Applying bootstrap blindly**</span>
<span id="cb18-1295"><a href="#cb18-1295" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Check if your statistic is smooth</span>
<span id="cb18-1296"><a href="#cb18-1296" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Be cautious with very small samples</span>
<span id="cb18-1297"><a href="#cb18-1297" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Watch out for boundary cases</span>
<span id="cb18-1298"><a href="#cb18-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1299"><a href="#cb18-1299" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Ignoring the assumptions**</span>
<span id="cb18-1300"><a href="#cb18-1300" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Bootstrap assumes the sample represents the population</span>
<span id="cb18-1301"><a href="#cb18-1301" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>It can't fix biased sampling or systematic errors</span>
<span id="cb18-1302"><a href="#cb18-1302" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>It's not magic -- just clever resampling</span>
<span id="cb18-1303"><a href="#cb18-1303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1304"><a href="#cb18-1304" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chapter Connections</span></span>
<span id="cb18-1305"><a href="#cb18-1305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1306"><a href="#cb18-1306" aria-hidden="true" tabindex="-1"></a>The bootstrap builds on our theoretical foundations and provides a computational path forward:</span>
<span id="cb18-1307"><a href="#cb18-1307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1308"><a href="#cb18-1308" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**From Previous Chapters**: We've applied the plug-in principle to the empirical distribution (Chapter 1's probability concepts), used Chapter 2's variance formulas for bootstrap standard errors, and provided an alternative to Chapter 3's CLT-based confidence intervals when theoretical distributions are intractable</span>
<span id="cb18-1309"><a href="#cb18-1309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1310"><a href="#cb18-1310" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Next - Hypothesis Testing (Chapter 5)**: Bootstrap will create null distributions for complex test statistics, complemented by permutation tests as another resampling approach</span>
<span id="cb18-1311"><a href="#cb18-1311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1312"><a href="#cb18-1312" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Parametric Methods (Chapters 6-7)**: Compare bootstrap to theoretical approaches, use it to validate assumptions, and construct confidence intervals for maximum likelihood estimates when standard theory is difficult</span>
<span id="cb18-1313"><a href="#cb18-1313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1314"><a href="#cb18-1314" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Machine Learning Applications**: Bootstrap underpins ensemble methods (bagging), provides uncertainty quantification for predictions, and helps with model selection—making it essential for modern data science</span>
<span id="cb18-1315"><a href="#cb18-1315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1316"><a href="#cb18-1316" aria-hidden="true" tabindex="-1"></a><span class="fu">### Rejoinder: Coming Full Circle</span></span>
<span id="cb18-1317"><a href="#cb18-1317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1318"><a href="#cb18-1318" aria-hidden="true" tabindex="-1"></a>Recall our opening example: the healthcare administrator planning hospital capacity during an epidemic. We began by asking how to quantify the uncertainty in our estimates, not just provide point predictions.</span>
<span id="cb18-1319"><a href="#cb18-1319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1320"><a href="#cb18-1320" aria-hidden="true" tabindex="-1"></a>Through this chapter, we've answered that question with two powerful tools:</span>
<span id="cb18-1321"><a href="#cb18-1321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1322"><a href="#cb18-1322" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**The plug-in principle** gave us a way to estimate any property of a distribution</span>
<span id="cb18-1323"><a href="#cb18-1323" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**The bootstrap** gave us a way to quantify the uncertainty of those estimates</span>
<span id="cb18-1324"><a href="#cb18-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1325"><a href="#cb18-1325" aria-hidden="true" tabindex="-1"></a>These tools enable data-driven decision making by providing not just estimates, but confidence intervals that capture the range of plausible values. Whether you're estimating hospital capacity, financial risk, or any other critical quantity, you now have the tools to say not just "we expect 500 patients" but "we're 95% confident it will be between 300 and 700 patients."</span>
<span id="cb18-1326"><a href="#cb18-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1327"><a href="#cb18-1327" aria-hidden="true" tabindex="-1"></a>This transformation from point estimates to uncertainty quantification is what makes statistics invaluable for real-world decision making.</span>
<span id="cb18-1328"><a href="#cb18-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1329"><a href="#cb18-1329" aria-hidden="true" tabindex="-1"></a><span class="fu">### Practical Advice</span></span>
<span id="cb18-1330"><a href="#cb18-1330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1331"><a href="#cb18-1331" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Start simple**: Use percentile intervals as your default</span>
<span id="cb18-1332"><a href="#cb18-1332" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Visualize**: Always plot the bootstrap distribution</span>
<span id="cb18-1333"><a href="#cb18-1333" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Compare methods**: Try different CI methods to check robustness</span>
<span id="cb18-1334"><a href="#cb18-1334" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Think about assumptions**: Is your sample representative?</span>
<span id="cb18-1335"><a href="#cb18-1335" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Use modern tools**: Most software has built-in bootstrap functions</span>
<span id="cb18-1336"><a href="#cb18-1336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1337"><a href="#cb18-1337" aria-hidden="true" tabindex="-1"></a>The bootstrap exemplifies the shift from mathematical to computational statistics. Master it, and you'll have a powerful tool for almost any statistical problem you encounter.</span>
<span id="cb18-1338"><a href="#cb18-1338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1339"><a href="#cb18-1339" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quick Self-Check</span></span>
<span id="cb18-1340"><a href="#cb18-1340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1341"><a href="#cb18-1341" aria-hidden="true" tabindex="-1"></a>Before moving on, test your understanding with these questions:</span>
<span id="cb18-1342"><a href="#cb18-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1343"><a href="#cb18-1343" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**What is bootstrap sampling used for?**</span>
<span id="cb18-1344"><a href="#cb18-1344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1345"><a href="#cb18-1345" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-1346"><a href="#cb18-1346" aria-hidden="true" tabindex="-1"></a><span class="fu">## Answer</span></span>
<span id="cb18-1347"><a href="#cb18-1347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1348"><a href="#cb18-1348" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Estimating the sampling distribution of a statistic</span>
<span id="cb18-1349"><a href="#cb18-1349" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Computing standard errors and confidence intervals  </span>
<span id="cb18-1350"><a href="#cb18-1350" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Assessing uncertainty when no formula exists</span>
<span id="cb18-1351"><a href="#cb18-1351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1352"><a href="#cb18-1352" aria-hidden="true" tabindex="-1"></a>The bootstrap is particularly valuable when theoretical formulas are intractable or don't exist, such as for the median, correlation coefficient, or complex machine learning predictions.</span>
<span id="cb18-1353"><a href="#cb18-1353" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1354"><a href="#cb18-1354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1355"><a href="#cb18-1355" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**What approximations does the method make?**</span>
<span id="cb18-1356"><a href="#cb18-1356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1357"><a href="#cb18-1357" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-1358"><a href="#cb18-1358" aria-hidden="true" tabindex="-1"></a><span class="fu">## Answer</span></span>
<span id="cb18-1359"><a href="#cb18-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1360"><a href="#cb18-1360" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Statistical approximation**: Assumes $\hat{F}_n$ approximates $F$ well</span>
<span id="cb18-1361"><a href="#cb18-1361" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>This depends on sample size $n$ and cannot be improved without more data</span>
<span id="cb18-1362"><a href="#cb18-1362" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Monte Carlo approximation**: Finite $B$ approximates infinite resampling</span>
<span id="cb18-1363"><a href="#cb18-1363" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>This can be made arbitrarily small by increasing $B$ (typically $B \geq 1,000$)</span>
<span id="cb18-1364"><a href="#cb18-1364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1365"><a href="#cb18-1365" aria-hidden="true" tabindex="-1"></a>Remember: $\mathbb{V}_F(T_n) \underbrace{\approx}_{\text{statistical error}} \mathbb{V}_{\hat{F}_n}(T_n) \underbrace{\approx}_{\text{Monte Carlo error}} v_{\text{boot}}$</span>
<span id="cb18-1366"><a href="#cb18-1366" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1367"><a href="#cb18-1367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1368"><a href="#cb18-1368" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**What are its limitations?**</span>
<span id="cb18-1369"><a href="#cb18-1369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1370"><a href="#cb18-1370" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-1371"><a href="#cb18-1371" aria-hidden="true" tabindex="-1"></a><span class="fu">## Answer</span></span>
<span id="cb18-1372"><a href="#cb18-1372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1373"><a href="#cb18-1373" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Small samples** (typically $n &lt; 20-30$): The empirical distribution poorly represents the population</span>
<span id="cb18-1374"><a href="#cb18-1374" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Extreme order statistics**: Cannot extrapolate beyond observed data range (e.g., max of uniform distribution)</span>
<span id="cb18-1375"><a href="#cb18-1375" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Heavy-tailed distributions**: May miss rare extreme values that drive variability (as we saw with 4th moments)</span>
<span id="cb18-1376"><a href="#cb18-1376" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Non-smooth statistics**: Discontinuous functions like the number of modes</span>
<span id="cb18-1377"><a href="#cb18-1377" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dependent data**: Requires specialized methods like block bootstrap for time series</span>
<span id="cb18-1378"><a href="#cb18-1378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1379"><a href="#cb18-1379" aria-hidden="true" tabindex="-1"></a>The key limitation: bootstrap cannot see what's not in your sample!</span>
<span id="cb18-1380"><a href="#cb18-1380" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1381"><a href="#cb18-1381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1382"><a href="#cb18-1382" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**How can bootstrap be used to construct confidence intervals?**</span>
<span id="cb18-1383"><a href="#cb18-1383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1384"><a href="#cb18-1384" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-1385"><a href="#cb18-1385" aria-hidden="true" tabindex="-1"></a><span class="fu">## Answer</span></span>
<span id="cb18-1386"><a href="#cb18-1386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1387"><a href="#cb18-1387" aria-hidden="true" tabindex="-1"></a>Three main methods, each with different strengths:</span>
<span id="cb18-1388"><a href="#cb18-1388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1389"><a href="#cb18-1389" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Normal interval**: $\hat{T}_n \pm z_{\alpha/2} \cdot \widehat{\text{se}}_{\text{boot}}$</span>
<span id="cb18-1390"><a href="#cb18-1390" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Simplest, but assumes normality</span>
<span id="cb18-1391"><a href="#cb18-1391" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Can give impossible values (e.g., correlation &gt; 1)</span>
<span id="cb18-1392"><a href="#cb18-1392" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1393"><a href="#cb18-1393" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Percentile interval**: $(T^*_{n,\alpha/2}, T^*_{n,1-\alpha/2})$</span>
<span id="cb18-1394"><a href="#cb18-1394" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Uses bootstrap quantiles directly</span>
<span id="cb18-1395"><a href="#cb18-1395" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Respects parameter bounds, good default choice</span>
<span id="cb18-1396"><a href="#cb18-1396" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1397"><a href="#cb18-1397" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Pivotal interval**: $(2\hat{T}_n - T^*_{n,1-\alpha/2}, 2\hat{T}_n - T^*_{n,\alpha/2})$</span>
<span id="cb18-1398"><a href="#cb18-1398" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Corrects for bias, often most accurate</span>
<span id="cb18-1399"><a href="#cb18-1399" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Can occasionally exceed parameter bounds</span>
<span id="cb18-1400"><a href="#cb18-1400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1401"><a href="#cb18-1401" aria-hidden="true" tabindex="-1"></a>Choose based on your specific problem and always visualize the bootstrap distribution!</span>
<span id="cb18-1402"><a href="#cb18-1402" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1403"><a href="#cb18-1403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1404"><a href="#cb18-1404" aria-hidden="true" tabindex="-1"></a><span class="fu">### Self-Test Problems</span></span>
<span id="cb18-1405"><a href="#cb18-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1406"><a href="#cb18-1406" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Implementing Bootstrap**: Write a function to bootstrap the trimmed mean (removing top and bottom 10% before averaging). Compare its standard error to the regular mean for normal and heavy-tailed data.</span>
<span id="cb18-1407"><a href="#cb18-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1408"><a href="#cb18-1408" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Correlation CI**: Using the European Health and Wealth data from the chapter, compute bootstrap confidence intervals for $\rho^2$ (squared correlation). How do the three methods compare? What happens to the intervals when you transform from $\rho$ to $\rho^2$?</span>
<span id="cb18-1409"><a href="#cb18-1409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1410"><a href="#cb18-1410" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Ratio Statistics**: Given paired data $(X_i, Y_i)$, bootstrap the ratio $\bar{Y}/\bar{X}$. Why might this be challenging? Compare the three CI methods.</span>
<span id="cb18-1411"><a href="#cb18-1411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1412"><a href="#cb18-1412" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Bootstrap Failure - Range Statistic**: Generate $n=30$ observations from a standard normal distribution and bootstrap the range (max - min). Compare the bootstrap distribution to the true sampling distribution (via simulation). Why does the bootstrap underestimate the variability? How does this relate to our discussion of extreme order statistics?</span>
<span id="cb18-1413"><a href="#cb18-1413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1414"><a href="#cb18-1414" aria-hidden="true" tabindex="-1"></a><span class="fu">### Connections to Source Material</span></span>
<span id="cb18-1415"><a href="#cb18-1415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1416"><a href="#cb18-1416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1417"><a href="#cb18-1417" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb18-1418"><a href="#cb18-1418" aria-hidden="true" tabindex="-1"></a><span class="fu">## Mapping to "All of Statistics"</span></span>
<span id="cb18-1419"><a href="#cb18-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1420"><a href="#cb18-1420" aria-hidden="true" tabindex="-1"></a>This table maps sections in these lecture notes to the corresponding sections in @wasserman2013all ("All of Statistics" or AoS).</span>
<span id="cb18-1421"><a href="#cb18-1421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1422"><a href="#cb18-1422" aria-hidden="true" tabindex="-1"></a>| Lecture Note Section | Corresponding AoS Section(s) |</span>
<span id="cb18-1423"><a href="#cb18-1423" aria-hidden="true" tabindex="-1"></a>| :--- | :--- |</span>
<span id="cb18-1424"><a href="#cb18-1424" aria-hidden="true" tabindex="-1"></a>| **Introduction and Motivation** | Expanded material from the slides, providing context for nonparametric estimation and the bootstrap. |</span>
<span id="cb18-1425"><a href="#cb18-1425" aria-hidden="true" tabindex="-1"></a>| **Confidence Sets: The Foundation** | |</span>
<span id="cb18-1426"><a href="#cb18-1426" aria-hidden="true" tabindex="-1"></a>| ↳ Definition and Interpretation of Confidence Intervals | AoS §6.3.2 |</span>
<span id="cb18-1427"><a href="#cb18-1427" aria-hidden="true" tabindex="-1"></a>| ↳ Normal-Based Confidence Intervals | AoS §6.3.2 (Theorem 6.16) |</span>
<span id="cb18-1428"><a href="#cb18-1428" aria-hidden="true" tabindex="-1"></a>| **The Plug-In Principle: A General Method for Estimation** | |</span>
<span id="cb18-1429"><a href="#cb18-1429" aria-hidden="true" tabindex="-1"></a>| ↳ The Empirical Distribution Function (EDF) | AoS §7.1 (Definition 7.1) |</span>
<span id="cb18-1430"><a href="#cb18-1430" aria-hidden="true" tabindex="-1"></a>| ↳ Properties of the EDF (Glivenko-Cantelli) | AoS §7.1 (Theorems 7.3, 7.4) |</span>
<span id="cb18-1431"><a href="#cb18-1431" aria-hidden="true" tabindex="-1"></a>| ↳ Confidence Bands for the CDF (DKW Inequality) | AoS §7.1 (Theorem 7.5) |</span>
<span id="cb18-1432"><a href="#cb18-1432" aria-hidden="true" tabindex="-1"></a>| ↳ The Plug-In Estimator for Statistical Functionals | AoS §7.2 (Definition 7.7) |</span>
<span id="cb18-1433"><a href="#cb18-1433" aria-hidden="true" tabindex="-1"></a>| ↳ Plug-in Examples (Mean, Variance, etc.) | AoS §7.2 (Examples 7.10, 7.11, etc.) |</span>
<span id="cb18-1434"><a href="#cb18-1434" aria-hidden="true" tabindex="-1"></a>| **The Bootstrap: Simulating Uncertainty** | |</span>
<span id="cb18-1435"><a href="#cb18-1435" aria-hidden="true" tabindex="-1"></a>| ↳ The Core Idea and Bootstrap World | AoS §8 (Introduction), §8.2 |</span>
<span id="cb18-1436"><a href="#cb18-1436" aria-hidden="true" tabindex="-1"></a>| ↳ Bootstrap Variance and Standard Error Estimation | AoS §8.2 |</span>
<span id="cb18-1437"><a href="#cb18-1437" aria-hidden="true" tabindex="-1"></a>| **Bootstrap Confidence Intervals** | |</span>
<span id="cb18-1438"><a href="#cb18-1438" aria-hidden="true" tabindex="-1"></a>| ↳ Three Common Methods (Normal, Percentile, Pivotal) | AoS §8.3 |</span>
<span id="cb18-1439"><a href="#cb18-1439" aria-hidden="true" tabindex="-1"></a>| ↳ Comparing Bootstrap CIs (Health and Wealth Example) | New example, applies concepts from AoS §8.3. |</span>
<span id="cb18-1440"><a href="#cb18-1440" aria-hidden="true" tabindex="-1"></a>| **Bootstrap Application: Higher Moments** | New example from the slides. |</span>
<span id="cb18-1441"><a href="#cb18-1441" aria-hidden="true" tabindex="-1"></a>| **When The Bootstrap Fails** | New material, summarizing common failure modes. Examples inspired by AoS exercises (e.g., §8.6 Q7 for Uniform max). |</span>
<span id="cb18-1442"><a href="#cb18-1442" aria-hidden="true" tabindex="-1"></a>| **Chapter Summary and Connections** | New summary material. |</span>
<span id="cb18-1443"><a href="#cb18-1443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1444"><a href="#cb18-1444" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1445"><a href="#cb18-1445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1446"><a href="#cb18-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1447"><a href="#cb18-1447" aria-hidden="true" tabindex="-1"></a><span class="fu">### Python and R Reference</span></span>
<span id="cb18-1448"><a href="#cb18-1448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1449"><a href="#cb18-1449" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format="html"}</span>
<span id="cb18-1450"><a href="#cb18-1450" aria-hidden="true" tabindex="-1"></a>::: {.tabbed-content}</span>
<span id="cb18-1451"><a href="#cb18-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1452"><a href="#cb18-1452" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python</span></span>
<span id="cb18-1453"><a href="#cb18-1453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1456"><a href="#cb18-1456" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-1457"><a href="#cb18-1457" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb18-1458"><a href="#cb18-1458" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb18-1459"><a href="#cb18-1459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1460"><a href="#cb18-1460" aria-hidden="true" tabindex="-1"></a><span class="co"># Essential bootstrap code template</span></span>
<span id="cb18-1461"><a href="#cb18-1461" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-1462"><a href="#cb18-1462" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb18-1463"><a href="#cb18-1463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1464"><a href="#cb18-1464" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bootstrap(data, statistic, B<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.05</span>):</span>
<span id="cb18-1465"><a href="#cb18-1465" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-1466"><a href="#cb18-1466" aria-hidden="true" tabindex="-1"></a><span class="co">    Generic bootstrap function for any statistic.</span></span>
<span id="cb18-1467"><a href="#cb18-1467" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb18-1468"><a href="#cb18-1468" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb18-1469"><a href="#cb18-1469" aria-hidden="true" tabindex="-1"></a><span class="co">    - point_estimate: Original statistic value</span></span>
<span id="cb18-1470"><a href="#cb18-1470" aria-hidden="true" tabindex="-1"></a><span class="co">    - se: Bootstrap standard error  </span></span>
<span id="cb18-1471"><a href="#cb18-1471" aria-hidden="true" tabindex="-1"></a><span class="co">    - ci_normal: Normal-based CI</span></span>
<span id="cb18-1472"><a href="#cb18-1472" aria-hidden="true" tabindex="-1"></a><span class="co">    - ci_percentile: Percentile CI</span></span>
<span id="cb18-1473"><a href="#cb18-1473" aria-hidden="true" tabindex="-1"></a><span class="co">    - ci_pivotal: Pivotal CI</span></span>
<span id="cb18-1474"><a href="#cb18-1474" aria-hidden="true" tabindex="-1"></a><span class="co">    - boot_dist: Bootstrap distribution</span></span>
<span id="cb18-1475"><a href="#cb18-1475" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-1476"><a href="#cb18-1476" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb18-1477"><a href="#cb18-1477" aria-hidden="true" tabindex="-1"></a>    boot_samples <span class="op">=</span> np.zeros(B)</span>
<span id="cb18-1478"><a href="#cb18-1478" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1479"><a href="#cb18-1479" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original estimate</span></span>
<span id="cb18-1480"><a href="#cb18-1480" aria-hidden="true" tabindex="-1"></a>    point_estimate <span class="op">=</span> statistic(data)</span>
<span id="cb18-1481"><a href="#cb18-1481" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1482"><a href="#cb18-1482" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Bootstrap</span></span>
<span id="cb18-1483"><a href="#cb18-1483" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb18-1484"><a href="#cb18-1484" aria-hidden="true" tabindex="-1"></a>        boot_data <span class="op">=</span> np.random.choice(data, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-1485"><a href="#cb18-1485" aria-hidden="true" tabindex="-1"></a>        boot_samples[b] <span class="op">=</span> statistic(boot_data)</span>
<span id="cb18-1486"><a href="#cb18-1486" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1487"><a href="#cb18-1487" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Standard error</span></span>
<span id="cb18-1488"><a href="#cb18-1488" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> np.std(boot_samples, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-1489"><a href="#cb18-1489" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1490"><a href="#cb18-1490" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Confidence intervals</span></span>
<span id="cb18-1491"><a href="#cb18-1491" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> stats.norm.ppf(<span class="dv">1</span> <span class="op">-</span> alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb18-1492"><a href="#cb18-1492" aria-hidden="true" tabindex="-1"></a>    ci_normal <span class="op">=</span> (point_estimate <span class="op">-</span> z<span class="op">*</span>se, point_estimate <span class="op">+</span> z<span class="op">*</span>se)</span>
<span id="cb18-1493"><a href="#cb18-1493" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1494"><a href="#cb18-1494" aria-hidden="true" tabindex="-1"></a>    ci_percentile <span class="op">=</span> (np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>alpha<span class="op">/</span><span class="dv">2</span>),</span>
<span id="cb18-1495"><a href="#cb18-1495" aria-hidden="true" tabindex="-1"></a>                     np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>)))</span>
<span id="cb18-1496"><a href="#cb18-1496" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1497"><a href="#cb18-1497" aria-hidden="true" tabindex="-1"></a>    ci_pivotal <span class="op">=</span> (<span class="dv">2</span><span class="op">*</span>point_estimate <span class="op">-</span> np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>)),</span>
<span id="cb18-1498"><a href="#cb18-1498" aria-hidden="true" tabindex="-1"></a>                  <span class="dv">2</span><span class="op">*</span>point_estimate <span class="op">-</span> np.percentile(boot_samples, <span class="dv">100</span><span class="op">*</span>alpha<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb18-1499"><a href="#cb18-1499" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-1500"><a href="#cb18-1500" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb18-1501"><a href="#cb18-1501" aria-hidden="true" tabindex="-1"></a>        <span class="st">'estimate'</span>: point_estimate,</span>
<span id="cb18-1502"><a href="#cb18-1502" aria-hidden="true" tabindex="-1"></a>        <span class="st">'se'</span>: se,</span>
<span id="cb18-1503"><a href="#cb18-1503" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ci_normal'</span>: ci_normal,</span>
<span id="cb18-1504"><a href="#cb18-1504" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ci_percentile'</span>: ci_percentile,</span>
<span id="cb18-1505"><a href="#cb18-1505" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ci_pivotal'</span>: ci_pivotal,</span>
<span id="cb18-1506"><a href="#cb18-1506" aria-hidden="true" tabindex="-1"></a>        <span class="st">'boot_dist'</span>: boot_samples</span>
<span id="cb18-1507"><a href="#cb18-1507" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-1508"><a href="#cb18-1508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1509"><a href="#cb18-1509" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb18-1510"><a href="#cb18-1510" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.exponential(<span class="dv">2</span>, <span class="dv">50</span>)</span>
<span id="cb18-1511"><a href="#cb18-1511" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> bootstrap(data, np.median, B<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb18-1512"><a href="#cb18-1512" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Median: </span><span class="sc">{</span>results[<span class="st">'estimate'</span>]<span class="sc">:.3f}</span><span class="ss"> (SE: </span><span class="sc">{</span>results[<span class="st">'se'</span>]<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb18-1513"><a href="#cb18-1513" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95% Percentile CI: </span><span class="sc">{</span>results[<span class="st">'ci_percentile'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-1514"><a href="#cb18-1514" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1515"><a href="#cb18-1515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1516"><a href="#cb18-1516" aria-hidden="true" tabindex="-1"></a><span class="fu">## R</span></span>
<span id="cb18-1517"><a href="#cb18-1517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1518"><a href="#cb18-1518" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb18-1519"><a href="#cb18-1519" aria-hidden="true" tabindex="-1"></a><span class="co"># Essential bootstrap code template</span></span>
<span id="cb18-1520"><a href="#cb18-1520" aria-hidden="true" tabindex="-1"></a>bootstrap <span class="ot">&lt;-</span> <span class="cf">function</span>(data, statistic, <span class="at">B =</span> <span class="dv">1000</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>) {</span>
<span id="cb18-1521"><a href="#cb18-1521" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb18-1522"><a href="#cb18-1522" aria-hidden="true" tabindex="-1"></a>  boot_samples <span class="ot">&lt;-</span> <span class="fu">numeric</span>(B)</span>
<span id="cb18-1523"><a href="#cb18-1523" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1524"><a href="#cb18-1524" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Original estimate</span></span>
<span id="cb18-1525"><a href="#cb18-1525" aria-hidden="true" tabindex="-1"></a>  point_estimate <span class="ot">&lt;-</span> <span class="fu">statistic</span>(data)</span>
<span id="cb18-1526"><a href="#cb18-1526" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1527"><a href="#cb18-1527" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Bootstrap</span></span>
<span id="cb18-1528"><a href="#cb18-1528" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B) {</span>
<span id="cb18-1529"><a href="#cb18-1529" aria-hidden="true" tabindex="-1"></a>    boot_data <span class="ot">&lt;-</span> <span class="fu">sample</span>(data, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb18-1530"><a href="#cb18-1530" aria-hidden="true" tabindex="-1"></a>    boot_samples[b] <span class="ot">&lt;-</span> <span class="fu">statistic</span>(boot_data)</span>
<span id="cb18-1531"><a href="#cb18-1531" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb18-1532"><a href="#cb18-1532" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1533"><a href="#cb18-1533" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Standard error</span></span>
<span id="cb18-1534"><a href="#cb18-1534" aria-hidden="true" tabindex="-1"></a>  se <span class="ot">&lt;-</span> <span class="fu">sd</span>(boot_samples)</span>
<span id="cb18-1535"><a href="#cb18-1535" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1536"><a href="#cb18-1536" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Confidence intervals</span></span>
<span id="cb18-1537"><a href="#cb18-1537" aria-hidden="true" tabindex="-1"></a>  z <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="dv">1</span> <span class="sc">-</span> alpha<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb18-1538"><a href="#cb18-1538" aria-hidden="true" tabindex="-1"></a>  ci_normal <span class="ot">&lt;-</span> <span class="fu">c</span>(point_estimate <span class="sc">-</span> z<span class="sc">*</span>se, point_estimate <span class="sc">+</span> z<span class="sc">*</span>se)</span>
<span id="cb18-1539"><a href="#cb18-1539" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1540"><a href="#cb18-1540" aria-hidden="true" tabindex="-1"></a>  ci_percentile <span class="ot">&lt;-</span> <span class="fu">quantile</span>(boot_samples, <span class="fu">c</span>(alpha<span class="sc">/</span><span class="dv">2</span>, <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb18-1541"><a href="#cb18-1541" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1542"><a href="#cb18-1542" aria-hidden="true" tabindex="-1"></a>  ci_pivotal <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span><span class="sc">*</span>point_estimate <span class="sc">-</span> <span class="fu">quantile</span>(boot_samples, <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>),</span>
<span id="cb18-1543"><a href="#cb18-1543" aria-hidden="true" tabindex="-1"></a>                  <span class="dv">2</span><span class="sc">*</span>point_estimate <span class="sc">-</span> <span class="fu">quantile</span>(boot_samples, alpha<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb18-1544"><a href="#cb18-1544" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-1545"><a href="#cb18-1545" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb18-1546"><a href="#cb18-1546" aria-hidden="true" tabindex="-1"></a>    <span class="at">estimate =</span> point_estimate,</span>
<span id="cb18-1547"><a href="#cb18-1547" aria-hidden="true" tabindex="-1"></a>    <span class="at">se =</span> se,</span>
<span id="cb18-1548"><a href="#cb18-1548" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_normal =</span> ci_normal,</span>
<span id="cb18-1549"><a href="#cb18-1549" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_percentile =</span> ci_percentile,</span>
<span id="cb18-1550"><a href="#cb18-1550" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci_pivotal =</span> ci_pivotal,</span>
<span id="cb18-1551"><a href="#cb18-1551" aria-hidden="true" tabindex="-1"></a>    <span class="at">boot_dist =</span> boot_samples</span>
<span id="cb18-1552"><a href="#cb18-1552" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb18-1553"><a href="#cb18-1553" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-1554"><a href="#cb18-1554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1555"><a href="#cb18-1555" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb18-1556"><a href="#cb18-1556" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb18-1557"><a href="#cb18-1557" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">50</span>, <span class="at">rate =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb18-1558"><a href="#cb18-1558" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">bootstrap</span>(data, median, <span class="at">B =</span> <span class="dv">2000</span>)</span>
<span id="cb18-1559"><a href="#cb18-1559" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Median: %.3f (SE: %.3f)</span><span class="sc">\n</span><span class="st">"</span>, results<span class="sc">$</span>estimate, results<span class="sc">$</span>se))</span>
<span id="cb18-1560"><a href="#cb18-1560" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"95%% Percentile CI: (%.3f, %.3f)</span><span class="sc">\n</span><span class="st">"</span>, </span>
<span id="cb18-1561"><a href="#cb18-1561" aria-hidden="true" tabindex="-1"></a>            results<span class="sc">$</span>ci_percentile[<span class="dv">1</span>], results<span class="sc">$</span>ci_percentile[<span class="dv">2</span>]))</span>
<span id="cb18-1562"><a href="#cb18-1562" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-1563"><a href="#cb18-1563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1564"><a href="#cb18-1564" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1565"><a href="#cb18-1565" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1566"><a href="#cb18-1566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1567"><a href="#cb18-1567" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format="pdf"}</span>
<span id="cb18-1568"><a href="#cb18-1568" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb18-1569"><a href="#cb18-1569" aria-hidden="true" tabindex="-1"></a><span class="fu">## Python and R Reference Code</span></span>
<span id="cb18-1570"><a href="#cb18-1570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1571"><a href="#cb18-1571" aria-hidden="true" tabindex="-1"></a>Python and R code examples for this chapter can be found in the HTML version of these notes.</span>
<span id="cb18-1572"><a href="#cb18-1572" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1573"><a href="#cb18-1573" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-1574"><a href="#cb18-1574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1575"><a href="#cb18-1575" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb18-1576"><a href="#cb18-1576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-1577"><a href="#cb18-1577" aria-hidden="true" tabindex="-1"></a>*Remember: The bootstrap transforms the abstract problem of understanding sampling distributions into the concrete task of resampling from your data. It's statistics made tangible through computation. When in doubt, bootstrap it!*</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
<script>
// Function to render math in an element
function renderMath(element) {
  if (typeof renderMathInElement !== 'undefined') {
    renderMathInElement(element, {
      delimiters: [
        {left: '$$', right: '$$', display: true},
        {left: '$', right: '$', display: false},
        {left: '\\[', right: '\\]', display: true},
        {left: '\\(', right: '\\)', display: false}
      ],
      throwOnError: false
    });
  }
}

// Wait for page to fully load
window.addEventListener('load', function() {
  // Render math in all tabs initially
  document.querySelectorAll('.tab-pane').forEach(pane => renderMath(pane));
  
  // Re-render when tabs are shown
  document.addEventListener('shown.bs.tab', function(e) {
    const tabPane = document.querySelector(e.target.getAttribute('data-bs-target'));
    if (tabPane) renderMath(tabPane);
  });
});
</script>




</body></html>